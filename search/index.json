[{"content":"可以的话还是网上找份答案照做省事，老老实实按剧本来的同学没有不是一遍过的。如果要自己做的话，最主要是两点吧\n  最重要的是前后一致，有多个选项同意度类似就会被要求进行区分，保持一致是最关键的\n 什么说明都没有就把几个正面选项放到面前，让你按同意度排个序，还是比较怪异的，最好避免同意度出现太多重合现象\n   其次，不要选得太极端，像我平均每页两个非常强烈同意基本是不行的\n 不过这个真不怪我啊，没有语境要问我同不同意我肯定只能想象到最合适的场景，何况问卷里几乎没有特别负面的问题，如果没有上下文根本选不出几个不同意来\n    然后今天是第三方机构视频进行了澄清。华为这测评名字起的也是毫不避讳，一副要你自证清白的架势，而且测试麦克风时候发现录音还是那种司法取证时候的消音处理，很有种公安问话叫你去问话的感觉。问题内容大致如下：\n  两次测评期间有没有受到干扰\n  个人成长经历；爸妈做啥的；除了学习课外都干什么\n  朋友圈子是怎样的；有没有出现和朋友有很大分歧的情况\n  近几年有没有压力特别大的事情；怎么缓解压力\n  导师给予了怎样的指导；大老板帮到了多少；小老板是什么样的人；为什么觉得小老板很好\n  你觉得什么样的领导比较符合你的期望；你希望被给予什么样的任务；那简单的和有挑战的你选哪个呢\n （棒读）“任务？只要是领导交给我的，那肯定什么样的都行”\n   在实验室主要做什么；自己担任什么角色；平常怎样进行沟通\n  小组里有没有拖进度的人，怎么对待这种人\n 合着真当自己是公安查户口啊，问来问去就暗示——朋友搞你、导师帮不了你、同学拖进度，到这里我真的已经很无语要开始绷太阳穴了\n   最近有没有什么特别生气的事\n 我一时除了这次澄清测评都想不太出来什么能算得上生气的事情了，最后随便编了一个\n   遇到这种事（令我生气的事）怎么处理呢\n  有没有什么特别自豪的事情；讲讲细节；再具体一点\n  近三到五年职业上有什么规划；具体一点\n  手上有哪些 offer\n  可能有一两个问题顺序有出入。总共问话了大概二十五分钟，感觉上却比哪次面试都漫长，人的忍耐是有限的，希望不要再碰到这种鬼事。\n","date":"2021-10-20T00:00:00Z","permalink":"https://winterorch.github.io/p/suisuinian_1/","title":"华为综合测评澄清"},{"content":"10月4日 - 色达 - 稻城  \n IMG_20201004_124459 \n IMG_20201004_124635 \n IMG_20201004_124724 \n IMG_20201004_124950 \n IMG_20201004_125102 \n IMG_20201004_131734 \n IMG_20201004_132010 \n IMG_20201004_132131 \n IMG_20201004_134637 \n IMG_20201004_142444 \n IMG_20201004_143704 \n IMG_20201004_182529 \n IMG_20201004_182539 \n IMG_20201005_085313 \n IMG_20201005_091633 \n 10月5日 - 稻城亚丁  \n IMG_20201005_112304 \n IMG_20201005_113151 \n IMG_20201005_113157 \n IMG_20201005_113246 \n IMG_20201005_113634 \n IMG_20201005_120109 \n IMG_20201005_120143 \n IMG_20201005_122240 \n IMG_20201005_122336 \n IMG_20201005_133634 \n IMG_20201005_162850 \n IMG_20201005_181650 \n IMG_20201005_184720 \n 10月6日 - (G318国道) 稻城 - 理塘 - 雅江  \n IMG_20201006_115540 \n IMG_20201006_120304 \n IMG_20201006_120443 \n IMG_20201006_120613 \n IMG_20201006_121014 \n IMG_20201006_121315 \n IMG_20201006_123624 \n IMG_20201006_123631 \n IMG_20201006_124316 \n IMG_20201006_125022 \n IMG_20201006_125153 \n IMG_20201006_130035 \n IMG_20201006_132310 \n IMG_20201006_155142 \n IMG_20201006_155208 \n IMG_20201006_155408 \n IMG_20201006_160518 \n IMG_20201006_160605 \n IMG_20201006_161048 \n IMG_20201006_163625 \n IMG_20201006_163753 \n IMG_20201006_165117 \n IMG_20201006_172708 \n IMG_20201006_180452 \n 10月7日 - (G318国道) 雅江 - 康定 - 雅安  \n IMG_20201007_091859 \n IMG_20201007_092344 \n IMG_20201007_092514 \n IMG_20201007_092520 \n IMG_20201007_092524 \n IMG_20201007_104521 \n IMG_20201007_105949 \n IMG_20201007_110453 \n IMG_20201007_111707 \n IMG_20201007_111828 \n IMG_20201007_113131 \n IMG_20201007_113251 \n IMG_20201007_113936 \n IMG_20201007_114850 \n IMG_20201007_115016 \n IMG_20201007_121724 \n IMG_20201007_121736 \n","date":"2021-10-02T00:00:00Z","image":"https://winterorch.github.io/images/feature/ArseniXC/HanFangYi_2.jpg","permalink":"https://winterorch.github.io/p/tourism_chuanxi_2/","title":"相册 - 川西 (下)"},{"content":"10月2日 - 映秀镇  \n IMG_20201002_123735 \n IMG_20201002_150452 \n 10月2日 - 映秀 - 观音桥  \n IMG_20201002_191617 \n 10月2日 - 观音桥一家藏族餐馆  \n IMG_20201002_213351 \n IMG_20201002_213458 \n 10月3日 - 观音桥镇  \n IMG_20201003_083415 \n IMG_20201003_094241 \n IMG_20201003_094249 \n IMG_20201003_094937 \n 10月3日 - 观音庙  \n IMG_20201003_100357 \n IMG_20201003_100427 \n IMG_20201003_100732 \n IMG_20201003_100836 \n IMG_20201003_100920 \n IMG_20201003_102920 \n IMG_20201003_102943 \n IMG_20201003_103729 \n IMG_20201003_103746 \n IMG_20201003_103921 \n IMG_20201003_104427 \n IMG_20201003_105120 \n IMG_20201003_105133 \n IMG_20201003_112725 \n IMG_20201003_112746 \n 10月3日 - 观音桥镇 - 色达 观音桥海拔2000米左右，而色达海拔在4000米\n \n IMG_20201003_115249 \n IMG_20201003_121941 \n IMG_20201003_123836 \n IMG_20201003_123855 \n IMG_20201003_145158_1 \n IMG_20201003_145203 \n IMG_20201003_145210 \n IMG_20201003_151344 \n IMG_20201003_155809 \n IMG_20201003_155829 \n IMG_20201003_160233 \n IMG_20201003_160312 \n IMG_20201003_161010 \n IMG_20201003_161119 \n IMG_20201003_162143 \n IMG_20201003_162838 \n IMG_20201003_163631 \n IMG_20201003_164237 \n IMG_20201003_164520 \n IMG_20201003_164734 \n 10月3日 - 色达 4000米这个海拔上没有茂密的树林\n \n IMG_20201003_165216 \n IMG_20201003_165312 \n IMG_20201003_165805 \n IMG_20201003_165851 \n IMG_20201003_170009 \n IMG_20201003_170221 \n IMG_20201003_170226 \n IMG_20201003_170516 \n IMG_20201003_182625 \n 10月3日 - 色达佛学院 早上五点天没亮爬山进的，出的时候是八点\n \n IMG_20201004_054359 \n IMG_20201004_054620 \n IMG_20201004_060313 \n IMG_20201004_060625 \n IMG_20201004_072243 \n IMG_20201004_074237 \n IMG_20201004_074448 \n IMG_20201004_074646 \n IMG_20201004_074651 \n IMG_20201004_082229 \n下接 相册 - 川西 (下)\n","date":"2021-10-01T00:00:00Z","image":"https://winterorch.github.io/images/feature/ArseniXC/HanFangYi_1.jpg","permalink":"https://winterorch.github.io/p/tourism_chuanxi_1/","title":"相册 - 川西 (上)"},{"content":"数组中的双指针解法，链表中快慢指针的解法放到链表专题。\n 双指针滑动窗口问题 N-Sum问题的双指针解法     题目 描述     Leet 11 盛最多水的容器 壁高序列注水问题   Leet 3 无重复字符的最长子串 经典的双指针滑动窗口问题   Leet 16 最接近的三数之和 三数和问题   Leet 992 K 个不同整数的子数组 含有 K 个不同元素的窗口     双指针滑动窗口  Leet 3 无重复字符的最长子串，Leet 424 替换后的最长重复字符, Leet 978 最长湍流子数组, Leet 992 K 个不同整数的子数组, Leet 1004 最大连续1的个数 III, Leet 1040 移动石子直到连续 II\n 常见形式： 右指针不断右移，直到窗口不符合要求，然后开始调整左指针，释放部分窗口左边界以使窗口满足要求，继续移动右指针。\n例题、\nLeet 3. 无重复字符的最长子串 题目： 给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度。\n示例 1:\n输入: s = \u0026quot;abcabcbb\u0026quot;\r输出: 3 解释: 因为无重复字符的最长子串是 \u0026quot;abc\u0026quot;，所以其长度为 3。\r**题解： ** 我们要求的是滑动窗口的最大长度，通过左右两个指针表示。而窗口内出现的字符也需要一个数据结构进行维护，比较容易想到的是 Set ，但是直觉告诉我们 Set 肯定没有数组高效，除非输入的是 String 之类否则应当尽量减少 Set 和 Map 的使用。加之这道题里只有 char ，至多也就 256 种情况，完全可以用一个数组表示。\n如果用 boolean[] 表示，我们发现在右指针发现重复字符，左指针还要继续在右指针搜索过的字符串上进行搜索，显然可以进一步优化。我们不用 boolean 数组，而是 在右指针搜索过程中直接将 字符索引 存到一个 int 数组里，然后在一开始将数组初始化为 -1 ，这样当右指针发现重复字符（数组中该位置不为 -1），直接将左指针移到数组该位置记录的索引处就可以了，每个字符只搜索一遍，时间复杂度 O(n) 。\npublic int lengthOfLongestSubstring(String s) { int[] set = new int[256]; Arrays.fill(set, -1); int res = 0, left = -1; char[] arr = s.toCharArray(); for (int i = 0; i \u0026lt; arr.length; ++i) { left = Math.max(left, set[arr[i]]); set[arr[i]] = -1; res = Math.max(res, i - left); } return res; } Leet 424. 替换后的最长重复字符 题目： 给你一个仅由大写英文字母组成的字符串，你可以将任意位置上的字符替换成另外的字符，总共可最多替换 k 次。在执行上述操作后，找到包含重复字母的最长子串的长度。\n输入：s = \u0026quot;AABABBA\u0026quot;, k = 1\r输出：4\r解释：\r将中间的一个'A'替换为'B',字符串变为 \u0026quot;AABBBBA\u0026quot;。\r子串 \u0026quot;BBBB\u0026quot; 有最长重复字母, 答案为 4。\r题解： 还是滑动窗口的思路，要维护的是其中每个字符出现的次数。我们有个出现最多的字符，需要关注除它以外所有其它字符个数，这只需要做个减法就能得到，这个数字一旦超过了k，左指针就需要移动了。\n出现最多的字符有可能发生变化，但也最多只会变成右指针新找到的字符。\npublic int characterReplacement(String s, int k) { int[] set = new int[26]; int res = 0, maxCnt = 0; int left = 0; char[] arr = s.toCharArray(); for (int i = 0; i \u0026lt; arr.length; ++i) { // 值得注意的是，随着右指针新取到一个字符c，窗口中出现最多的字符  // 要么不变，要么变成新字符  maxCnt = Math.max(maxCnt, ++set[arr[i] - \u0026#39;A\u0026#39;]); while (i - left + 1 - maxCnt \u0026gt; k) { --set[arr[left++] - \u0026#39;A\u0026#39;]; } res = Math.max(res, i - left + 1); } return res; } Leet 978 最长湍流子数组 题目： 当 A 的子数组 A[i], A[i+1], \u0026hellip;, A[j] 满足下列条件时，我们称其为湍流子数组：\n若 i \u0026lt;= k \u0026lt; j，当 k 为奇数时， A[k] \u0026gt; A[k+1]，且当 k 为偶数时，A[k] \u0026lt; A[k+1]； 或 若 i \u0026lt;= k \u0026lt; j，当 k 为偶数时，A[k] \u0026gt; A[k+1] ，且当 k 为奇数时， A[k] \u0026lt; A[k+1]。 也就是说，如果比较符号在子数组中的每个相邻元素对之间翻转，则该子数组是湍流子数组。\n返回 A 的最大湍流子数组的长度。\n输入：[9,4,2,10,7,8,8,1,9]\r输出：5\r解释：(A[1] \u0026gt; A[2] \u0026lt; A[3] \u0026gt; A[4] \u0026lt; A[5])\r题解： 就是求锯齿数组最长长度，发现锯齿断了其实很简单，只需要当前浪和前一浪方向一样（都上升或都下降），最大的问题是前后两个数一样的情况，按题意是不能出现平浪的，因此相等时我们直接让左指针把这个平浪跳过，跳到两个相等数靠右的这个来。\n如果 left 就在 right 左边一位（在右指针刚开始走，和出现平浪之后都会发生这种情况），那只要不相等，都是可以取的，顺便更新一下浪的方向。\npublic int maxTurbulenceSize(int[] arr) { if (arr.length == 1) { return 1; } else if (arr.length == 2) { return (arr[0] == arr[1]) ? 1 : 2; } int left = 0, right = 1; int res = 0; boolean goingUp; for (; right \u0026lt; arr.length; ++right) { if (left == right - 1) { goingUp = arr[right] \u0026gt; arr[right - 1]; } if (goingUp == arr[right] \u0026gt; arr[right - 1] || arr[right] == arr[right - 1]) { res = Math.max(res, right - left); left = (arr[right] == arr[right - 1]) ? right : right - 1; } else { goingUp = !goingUp; } } res = Math.max(res, right - left); return res; } Leet 930 和相同的二元子数组 题目： 给你一个二元数组 nums ，和一个整数 goal ，请你统计并返回有多少个和为 goal 的 非空 子数组。子数组 是数组的一段连续部分。\nExample 1:\nInput: A = [1,0,1,0,1], S = 2\rOutput: 4\rExplanation:\rThe 4 subarrays are bolded below:\r[1,0,1]\r[1,0,1,0]\r[0,1,0,1]\r[1,0,1]\rNote:\n A.length \u0026lt;= 30000 0 \u0026lt;= S \u0026lt;= A.length A[i] is either 0 or 1.  题解： 首先，这道题是可以通过前缀和来做的。这道题有一个特性，是没有负权值，因此前缀和数组是不严格单调递增的，右指针前进，左指针也必然不会后退。\n可以使用两个左端点，代表在给定右端点前提下满足要求的左端点集合。什么要求呢？两个指针到右指针间的和，分别为刚好小于目标和的最左端端点和刚好不大于目标和的最左端点，两点之间的就是满足要求的刚好等于目标的位置。\npublic int numSubarraysWithSum(int[] nums, int t) { int n = nums.length; int ans = 0; for (int r = 0, l1 = 0, l2 = 0, s1 = 0, s2 = 0; r \u0026lt; n; r++) { s1 += nums[r]; s2 += nums[r]; while (l1 \u0026lt;= r \u0026amp;\u0026amp; s1 \u0026gt; t) s1 -= nums[l1++]; while (l2 \u0026lt;= r \u0026amp;\u0026amp; s2 \u0026gt;= t) s2 -= nums[l2++]; ans += l2 - l1; } return ans; } 这道题更通用的做法是用前缀和+Map记忆。因为这道题没有负值，可以直接用数组替代Map，每次找从当前位置前缀和中扣掉后等于目标和的位置，找到的都是可选的左指针位置。\npublic int numWithSum(int[] nums, int t) { int n = nums.length; int[] sum = new int[n + 1]; for (int i = 1; i \u0026lt;= n; ++i) { sum[i] = sum[i - 1] + nums[i - 1]; } int[] map = new int[n + 1]; map[0] = 1; int ans = 0; for (int i = 0; i \u0026lt; n; ++i) { int r = sum[i + 1], l = r - t; if (l \u0026gt;= 0) { ans += map[l]; } ++map[r]; } return ans; } Leet 992 K 个不同整数的子数组 题目： 给定一个正整数数组 A，如果 A 的某个子数组中不同整数的个数恰好为 K，则称 A 的这个连续、不一定不同的子数组为好子数组。\n（例如，[1,2,3,1,2] 中有 3 个不同的整数：1，2，以及 3。）\n返回 A 中好子数组的数目。\n输入：A = [1,2,1,2,3], K = 2\r输出：7\r解释：恰好由 2 个不同整数组成的子数组：[1,2], [2,1], [1,2], [2,3], [1,2,1], [2,1,2], [1,2,1,2].\r题解： 第一眼看有，求子数组个数，稍微有点像动态规划。用滑动窗口求稍微有点困难，因为要求刚好有k个不同整数的子数组并不是那么方便——问题出在左指针上，左指针我们一般会右移直到满足条件，然而满足条件并不意味着其左侧没有满足条件的子数组了。相反，如果让我们求包含了k个以下整数的子数组，会非常方便——左指针满足条件后，左右指针之间都是满足条件的左指针位置，可以一次性全算上。\n因此，我们换个法子，通过一个helper函数求k个以下整数子数组的个数，然后再算一个k-1以下的，相减就是刚好k的了。\n如何统计每个整数出现的次数呢？正常应当用Map，这里整数的范围已经给定了，那直接用数组快一些。\npublic int subarraysWithKDistinct(int[] nums, int k) { return helper(nums, k) - helper(nums, k - 1); } private int helper(int[] nums, int k) { int n = nums.length, res = 0, left = 0; int[] numCnt = new int[nums.length]; for (int i = 0; i \u0026lt; n; ++i) { if (numCnt[nums[i] - 1]++ == 0) { --k; } while (k \u0026lt; 0) { if (--numCnt[nums[left] - 1] == 0) { ++k; } ++left; } res += i - left + 1; } return res; } Leet 1040 移动石子直到连续 II 题目： 在一个长度 无限 的数轴上，第 i 颗石子的位置为 stones[i]。如果一颗石子的位置最小/最大，那么该石子被称作 端点石子 。\n每个回合，你可以将一颗端点石子拿起并移动到一个未占用的位置，使得该石子不再是一颗端点石子。\n值得注意的是，如果石子像 stones = [1,2,5] 这样，你将 无法 移动位于位置 5 的端点石子，因为无论将它移动到任何位置（例如 0 或 3），该石子都仍然会是端点石子。\n当你无法进行任何移动时，即，这些石子的位置连续时，游戏结束。\n要使游戏结束，你可以执行的最小和最大移动次数分别是多少？ 以长度为 2 的数组形式返回答案：answer = [minimum_moves, maximum_moves] 。\n输入：[6,5,4,3,10]\r输出：[2,3]\r解释：\r我们可以移动 3 -\u0026gt; 8，接着是 10 -\u0026gt; 7，游戏结束。\r或者，我们可以移动 3 -\u0026gt; 7, 4 -\u0026gt; 8, 5 -\u0026gt; 9，游戏结束。\r注意，我们无法进行 10 -\u0026gt; 2 这样的移动来结束游戏，因为这是不合要求的移动。\r**题解： ** 这道题实际上需要找到一个固定长度为n的滑动窗口，计算处当前窗口中已有数字个数，总个数减去就是最小步数。窗口的左右边界分别是两块任意石头，如果距离超过n则跳过，不超过，就可以看窗口中已有数字个数。\n如果窗口内正好有n-1个数字，窗口大小也是n-1则已经连续了，窗外数字无法直接加到两侧，只能移动两次绕一圈来连续，因此要和2比较取小值。其它情况则跟窗口中空位个数进行比较。\npublic int[] numMovesStonesII(int[] stones) { Arrays.sort(stones); int n = stones.length, low = n, i = 0; for (int j = 0; j \u0026lt; n; ++j) { while (stones[j] - stones[i] + 1 \u0026gt; n) ++i; int al_store = j - i + 1; if (al_store == n - 1 \u0026amp;\u0026amp; stones[j] - stones[i] + 1 == n - 1) { low = Math.min(low, 2); } else { low = Math.min(low, n - al_store); } } return new int[]{low, Math.max(stones[n - 1] - stones[1] - n + 2, stones[n - 2] - stones[0] - n + 2)}; }  N-Sum问题的双指针解法  Leet 15 三数之和, Leet 16 最接近的三数之和, Leet 18 四数之和\n Leet 15 三数之和 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有和为 0 且不重复的三元组。\n注意：答案中不可以包含重复的三元组。示例 1：\n输入：nums = [-1,0,1,2,-1,-4]\r输出：[[-1,-1,2],[-1,0,1]]\r提示：\n 0 \u0026lt;= nums.length \u0026lt;= 3000 -105 \u0026lt;= nums[i] \u0026lt;= 105  题解： 因为要用双指针来求解，因此先固定一个最小点i，然后在它的右区间上使用双指针法。\n首先进行一个O(nlogn)的排序，也方便跳过重复元素。因为目标是 0 ，所以双指针搜索的目标是 -num[i]。将左右指针分别放到区间的两个端点，根据和与搜索目标 -num[i] 的大小关系，平移左右指针。这个过程中要跳过重复元素。\npublic List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; threeSum(int[] nums) { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); if (nums.length \u0026lt; 3) { return res; } Arrays.sort(nums); for (int i = 0; i \u0026lt; nums.length - 2; ++i) { if (nums[i] \u0026gt; 0) break; if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) continue; int l = i + 1, r = nums.length - 1; int target = -nums[i]; while (l \u0026lt; r) { if (nums[l] + nums[r] == target) { res.add(Arrays.asList(nums[i], nums[l], nums[r])); ++l; while (l \u0026lt; r \u0026amp;\u0026amp; nums[l] == nums[l - 1]) { ++l; } --r; while (l \u0026lt; r \u0026amp;\u0026amp; nums[r] == nums[r + 1]) { --r; } } else if (nums[l] + nums[r] \u0026lt; target) { ++l; } else { --r; } } } return res; }  Leet 16 最接近的三数之和 给定一个包括 n 个整数的数组 nums 和 一个目标值 target。找出 nums 中的三个整数，使得它们的和与 target 最接近。返回这三个数的和。假定每组输入只存在唯一答案。\n示例：\n输入：nums = [-1,2,1,-4], target = 1\r输出：2\r解释：与 target 最接近的和是 2 (-1 + 2 + 1 = 2) 。\r提示：\n 3 \u0026lt;= nums.length \u0026lt;= 10^3 -10^3 \u0026lt;= nums[i] \u0026lt;= 10^3 -10^4 \u0026lt;= target \u0026lt;= 10^4  题解： 和上面一题唯一区别是目标和不一定能被满足，取而代之要求最近的三数和。那么只要在三数和基础上维护一个最近距离，每次指针移动前进行一次判定就行了。\npublic int threeSumClosest(int[] nums, int target) { Arrays.sort(nums); int res = nums[0] + nums[1] + nums[2], dis = Math.abs(res - target); for (int i = 0; i \u0026lt; nums.length; ++i) { if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) continue; int t = target - nums[i]; int l = i + 1, r = nums.length - 1; while (l \u0026lt; r) { int temp = nums[l] + nums[r]; if (temp == t) { return target; } else if (temp \u0026lt; t) { if (t - temp \u0026lt; dis) { dis = t - temp; res = temp + nums[i]; } ++l; } else { if (temp - t \u0026lt; dis) { dis = temp - t; res = temp +nums[i]; } --r; } } } return res; }  Leet 18 四数之和 给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。\n注意：答案中不可以包含重复的四元组。示例 1：\n输入：nums = [1,0,-1,0,-2,2], target = 0\r输出：[[-2,-1,1,2],[-2,0,0,2],[-1,0,0,1]]\r示例 2：\n输入：nums = [], target = 0\r输出：[]\r提示：\n 0 \u0026lt;= nums.length \u0026lt;= 200 -109 \u0026lt;= nums[i] \u0026lt;= 109 -109 \u0026lt;= target \u0026lt;= 109  题解： 先确定前两个位置，再在后半段通过平移确定后两个点的位置。后两个点跟据总和与目标和的大小关系进行移动，先从距离最远的点——j+1 和 length-1 开始，偏大则右指针左移，偏小则左指针右移。\npublic List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; fourSum(int[] nums, int target) { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); if (nums == null || nums.length \u0026lt; 4) return res; Arrays.sort(nums); for (int i = 0; i \u0026lt; nums.length - 3; ++i) { if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) continue; for (int j = i + 1; j \u0026lt; nums.length - 2; ++j) { if (j \u0026gt; i + 1 \u0026amp;\u0026amp; nums[j] == nums[j - 1]) continue; int l = j + 1, r = nums.length - 1; while (l \u0026lt; r) { int sum = nums[i] + nums[j] + nums[l] + nums[r]; if (sum == target) { res.add(Arrays.asList(nums[i], nums[j], nums[l], nums[r])); while (l \u0026lt; r \u0026amp;\u0026amp; nums[l] == nums[l + 1]) ++l; while (l \u0026lt; r \u0026amp;\u0026amp; nums[r] == nums[r - 1]) --r; ++l; --r; } else if (sum \u0026lt; target) { ++l; } else { --r; } } } } return res; } ","date":"2021-07-12T00:00:00Z","image":"https://winterorch.github.io/images/category/leetcode/TeaParty.jpg","permalink":"https://winterorch.github.io/p/leetcode-%E5%8F%8C%E6%8C%87%E9%92%88%E8%A7%A3%E6%B3%95%E5%9C%A8%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/","title":"LeetCode - 双指针解法在数组中的应用"},{"content":" 大部分内容来源这篇美团的文章：https://tech.meituan.com/2014/03/06/in-depth-understanding-string-intern.html，原文非常有深度，这里只捡了一些比较浅的东西出来\nJDK6到7的字符串常量池出现了很大变化，为了防止绕晕，这里只拿了7以后的情况出来\n   直接用双引号声明的 String 对象直接存到常量池\n  用 intern 方法会从字符串常量池查询当前字符串是否存在，若不存在则将当前字符串放入常量池\n  new 一个字符串出来最多会生成两个对象\n 字符串常量池中的引用对象 Java Heap 中的String对象  当然，如果常量池中原本已经存在了被引用对象，则只会多生成一个对象\n  字符串常量池 字符串常量池的主体是一个 StringTable 。\nHotSpot VM中使用全局表StringTable记录interned string，StringTable 的 intern 方法类似 HashMap ，本质是HashSet\u0026lt;String\u0026gt;，但不能自动扩容，（JDK6）默认大小 1009，（JDK7）通过-XX:StringTableSize=99991参数指定，默认大小 60013。StringTable只存储对String实例的引用。\n 加载字节码文件时，常量（\u0026quot;\u0026quot;圈起来的就是字符串常量）会被加载到运行时常量池 (Runtime Constant Pool) 中，字符串此时只有 CONSTANT_Utf8 ，采用 Lazy-Init ，因此未成为 Java 对象，运行到对应位置再进行对象加载。  类加载阶段\nHotSpot VM 在类加载阶段，JVM会创建常量池中的字符串对象实例，但这一过程是惰性的，加载时仅将字面量放入类的运行时常量池，即 CONSTANT_Utf8，而 CONSTANT_String 还没有，也不会进入字符串常量池。（当然静态变量会直接被指定初始值，也就会创建字符串对象，同时保存引用到字符串常量池）\nintern() JDK7中，intern() 方法将在字符串池中保存堆中的引用并返回（如果已经有则直接返回该引用）。对执行方法的对象本身不会造成任何影响，该指哪指哪。以下为例：\nString s3 = new String(\u0026#34;1\u0026#34;) + new String(\u0026#34;1\u0026#34;); s3.intern(); String s4 = \u0026#34;11\u0026#34;; System.out.println(s3 == s4);//true s3 实际上在 Heap 上 new 出了一个\u0026quot;11\u0026quot;，且不会保存到常量池中。s3.intern()将这一对象直接保存到了字符串常量池中，s3仍指向这一对象，只是对象本身被保存到了常量池，因此s4显式创建\u0026quot;11\u0026quot;会直接拿常量池中的对象（引用）来用，也就是s3。\nString s = new String(\u0026#34;1\u0026#34;); s.intern(); String s2 = \u0026#34;1\u0026#34;; System.out.println(s == s2);//false 这一段则有很大不同，new String(\u0026quot;1\u0026quot;) 进行了两步操作——在字符串常量池建了\u0026quot;1\u0026quot;，并且还在 Heap 上建了一个额外的 String 对象并赋给 s ，所以s.intern()不会造成任何改变——常量池已经有\u0026quot;1\u0026quot;，而s也还是指向 Heap 上的 String 。因此s2 直接指向常量池中的\u0026quot;1\u0026quot;，s间接指向1,两者自然不是一个引用。\n 综合案例 class NewTest1{ public static String s1=\u0026#34;static\u0026#34;; // 第一句  public static void main(String[] args) { String s1=new String(\u0026#34;he\u0026#34;)+new String(\u0026#34;llo\u0026#34;); //第二句  s1.intern(); // 第三句  String s2=\u0026#34;hello\u0026#34;; //第四句  System.out.println(s1==s2);//第五句，输出是true。  } } 如图，类初始阶段会初始化 s1 ，所以在 main() 运行之前字符串常量池里已经有 \u0026quot;static\u0026quot; 。局部变量 s1 由两个字符串拼接而成，拼接过程实际是 StringBuilder 的 append，最后会通过 toString() 方法new一个 String 对象，且不会放入字符串常量池。在intern()时才会被放入字符串常量池。s2显式创建，发现字符串常量池中已有，因此直接使用，两者就是同一对象，s1==s2。\n Oracle JDK 8u20 后的新特性 Oracle JDK 8u20 后出现了 StringDuplication 特性，默认关闭。允许 G1 GC 下的字符串排重，在 JVM 底层允许相同数据的字符串指向同一数据。这一功能下，G1 会在垃圾收集过程中会把新创建的字符串对象放入队列中，在 Young GC 后，并发地将内部数据（JDK 9 以后就是 byte[]）一致地字符串进行排重。虽然可以节省内存空间，但也会占用额外 CPU，拖慢 Young GC 的作用。\n","date":"2021-07-11T00:00:00Z","image":"https://winterorch.github.io/images/feature/scenes/Sea.jpg","permalink":"https://winterorch.github.io/p/java-jvm-string_pool/","title":"Java - JVM 字符串"},{"content":"内存、对象、JVM优化相关问题 指令重排序与 happens-before 原则  https://www.jianshu.com/p/b9186dbebe8e\n 问题的起因还是指令重排序，重排序之所以存在是因为有多级缓存，线程所作变更先在寄存器或本地缓存完成，然后拷贝到主存以跨越内存栅栏（即完成工作内存到主存间的拷贝动作），跨越序列或顺序称为happens-before。仅当写操作线程先跨越内存栅栏，读线程后跨越内存栅栏，写操作线程所作变更才对其它线程可见。\n 程序次序规则： 在一个单独的线程中，按照程序代码的执行流顺序，（时间上）先执行的操作happen—before（时间上）后执行的操作 （同一个线程中前面的所有写操作对后面的操作可见） 管理锁定规则：一个unlock操作happen—before后面（时间上的先后顺序）对同一个锁的lock操作。 （如果线程1解锁了monitor a，接着线程2锁定了a，那么，线程1解锁a之前的写操作都对线程2可见（线程1和线程2可以是同一个线程）） volatile变量规则：对一个volatile变量的写操作happen—before后面（时间上）对该变量的读操作。 （如果线程1写入了volatile变量v（临界资源），接着线程2读取了v，那么，线程1写入v及之前的写操作都对线程2可见（线程1和线程2可以是同一个线程）） 线程启动规则：Thread.start()方法happen—before调用用start的线程前的每一个操作。 （假定线程A在执行过程中，通过执行ThreadB.start()来启动线程B，那么线程A对共享变量的修改在接下来线程B开始执行前对线程B可见。注意：线程B启动之后，线程A在对变量修改线程B未必可见。） 线程终止规则：线程的所有操作都happen—before对此线程的终止检测，可以通过Thread.join（）方法结束、Thread.isAlive（）的返回值等手段检测到线程已经终止执行。 (线程t1写入的所有变量，在任意其它线程t2调用t1.join()，或者t1.isAlive() 成功返回后，都对t2可见。) 线程中断规则：对线程interrupt()的调用 happen—before 发生于被中断线程的代码检测到中断时事件的发生。 (线程t1写入的所有变量，调用Thread.interrupt()，被打断的线程t2，可以看到t1的全部操作) 对象终结规则：一个对象的初始化完成（构造函数执行结束）happen—before它的finalize（）方法的开始。 (对象调用finalize()方法时，对象初始化完成的任意操作，同步到全部主存同步到全部cache。) 传递性：如果操作A happen—before操作B，操作B happen—before操作C，那么可以得出A happen—before操作C。   内存泄漏 JVM通过引用计数法和可达性分析算法来判断对象是否可以被GC，对象长时间没有被GC一般是JVM误以为对象还在引用中，无法回收，即长期存活对象引用短期存活对象，常见的情况包括：\n 静态集合类（短生命周期对象）被长生命周期持有引用 各种连接（数据库、网络连接、IO）没有线性关闭，造成对象无法被回收 变量定义作用范围过大 内部类持有外部类，内部类长期被持有，导致外部类对象无法被回收 哈希表中，如果对象哈希值与最初存入时不同，则会导致找不到对象结果，造成泄漏 一些数据结构，如手写栈，在栈不断增长、收缩后，如果不手工清空（引用置null），弹出对象有可能不被GC，造成隐蔽的内存泄漏 缓存结构中，有些对象写入后很可能就再也没有被删除或使用，造成缓存泄漏。WeakHashMap 就是为此诞生的，没有除自身外其它引用的值会被丢弃 监听器和回调，如果注册后没有显示取消就会积聚起来，比较简单的解决方法也是使用弱引用  因此总结下来，防止内存泄漏的办法包括：避免长期存活对象持有不必要的短期对象引用；不使用资源即时回收，尤其是连接、手工数据结构中；难以判断是否可以回收的缓存资源，可以通过弱引用防止内存泄漏。\n Java 中的四种引用类型 不同引用类型体现为对象不同的可达性状态和对垃圾收集的影响。\n 强引用就是最常见引用，垃圾收集器不会处理强引用指向的对象，但只要超过了引用的作用域，或显式地赋值为null就可以被回收 软引用相对强引用弱化一些，只有JVM认为内存不足（由JVM进行判定，不同JVM不同模式下对剩余空间的考量不同）时才会取试图回收软引用指向对象，因此可以用于缓存 弱引用指向对象完全不能从GC豁免，仅提供访问在弱引用状态下对象的途径，可以用来维护非强制的映射关系，如果还在就获取，否则重现实例化，也可以用于缓存 虚引用不能被用来访问对象，仅提供确保对象被finalize后做某些事的机制，比如 Post-Mortem 清理机制，Cleaner，监控对象的创建和销毁  引用的可达性可以进行流转，除了虚引用外的引用都可以通过get方法获取原有对象，从而重新指向强引用，人为改变对象的可达性状态。\n但是如果错误地保持了强引用，那对象就没有机会变回弱引用可达性状态了，就会产生内存泄露。\n Native 关键字 用于告诉 JVM 调用的是本地 C/C++ 方法，因此不能 abstract。使用 JNI 加载动态或静态库时会需要用到这个方法。常见的如 hashCode() 、NIO 中 epoll 相关的内核操作都需要调用本地方法。\n Unsafe 类 可以被用来分配直接内存、获取内存偏移地址、根据偏移地址修改属性（无视对象的可访问等级）、操作数组元素、线程挂起恢复、CAS ……\n访问直接内存、调用直接内存都通过这个类来实现，记住这个名字 sun.misc.Unsafe 。\n Object o = new Object() 占几个字节 对象头里的 Mark Word, Class Pointer, 数组 Length 都是必须长度\n Mark Word包括所的信息、GC标记信息、哈希码，总共8字节 Class Pointer，对于64位系统就是8字节 Length，数组特有结构，4字节  所以，普通对象就是 8+8 ，一共16字节；数组对象就是 8+8+4，对其8的整数倍，所以24字节\n 对象大小为什么是8字节的整数倍 数据结构对齐，为了允许以一些空间为代价加快内存访问，这和C中结构体是一样的。同时，这也是最方便垃圾回收的大小。\n 对象是如何定位的 查了一下《深入理解Java虚拟机》，首先JVM规范没有规定引用应该怎样定位对象、访问堆上的具体位置，因此取决于具体实现，主流方法是句柄、直接指针：\n 如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息 如果使用直接指针访问，那么Java堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference中存储的直接就是对象地址  句柄访问，则引用中地址很稳定，即使GC过程中，对象被移动，只有句柄被改变，引用不用变；直接指针好处当然就是快，HotSpot 用的也是直接指针。\n 如何实现对象克隆 Object.clone() 方法返回的就是 Object 的拷贝，不过必须实现Cloneable接口，这是个没有方法的标志性接口。\n值得注意的是，clone()得到的是浅拷贝。浅拷贝是指拷贝对象时仅仅拷贝对象本身（包括对象中的基本变量），而不拷贝对象包含的引用指向的对象。深拷贝不仅拷贝对象本身，而且拷贝对象包含的引用指向的所有对象。\n简单的深拷贝方法是将对象序列化，会将引用对象也一并保存下来，代价是耗时长。\n 对象不再使用时是否需要写null 《Effective Java》中讨论过这个问题，结论是，清空对象引用是一种例外，不是规范行为，Java 本身具有 GC，不需要所有对象手动写null。\n例外是自己管理内存的情况，前文也提到过，手工栈，从栈中弹出对象即使不被引用也会受栈维护，不被作为GC对象，必须手动删除。需要写null的情况有：\n  自己管理内存\n就是以上的情况。\n  缓存对象的引用\n对这种情况，当缓存项由对应键的外部引用决定生命周期，可以使用 WeakHashMap 进行缓存；LinkedHashMap 利用 removeEldestEntry 可以在定时清除缓存时使用。\n  监听器和其它回调\n客户端在 API 中注册回调，却没有显式取消，则最好通过只保存回调的弱引用（weak reference）来防止泄露。\n  其实这也和之前内存泄漏问题耦合度很高。\n 个人认为，Java 中的null是一个比较一言难尽的设计，尽量减少向代码中人为引入null的做法。\n  JVM 调优命令和问题定位工具 调优命令太多了，参考这篇\n https://www.cnblogs.com/xifengxiaoma/p/9415357.html\n强调几个常用的：jstack用于定位线程异常，包括死锁、死循环；jmap用于分析内存问题，如溢出、频繁Full GC；jstat用于监控GC相关信息；jps查看系统Java进程\n 问题定位工具，除了调优命令，还有JDB、VisualVM、JConsole、JProfiler、BTrace等等\n 宏变量与宏替换 用final定义的变量，编译器会尝试对其进行宏替换，如以下程序片段：\nfinal String a = \u0026#34;hello\u0026#34;; final String b = a; final String c = getHello(); a 会在编译期间被全部替换成\u0026quot;hello\u0026quot;，而b、c不行，因此 a 是宏变量，bc 不是。\n有这样一段程序：\npublic static void main(String[] args) { String hw = \u0026#34;hello world\u0026#34;; String hello = \u0026#34;hello\u0026#34;; final String finalWorld2 = \u0026#34;hello\u0026#34;; final String finalWorld3 = hello; final String finalWorld4 = \u0026#34;he\u0026#34; + \u0026#34;llo\u0026#34;; String hw1 = hello + \u0026#34; world\u0026#34;; String hw2 = finalWorld2 + \u0026#34; world\u0026#34;; String hw3 = finalWorld3 + \u0026#34; world\u0026#34;; String hw4 = finalWorld4 + \u0026#34; world\u0026#34;; System.out.println(hw == hw1); System.out.println(hw == hw2); System.out.println(hw == hw3); System.out.println(hw == hw4); } 原文链接：https://blog.csdn.net/youanyyou/article/details/78990305 finalWorld2 finalWorld4 就是宏变量，最终结果它们会和 hw 相等，因为就是指向同一块字符串常量池。而 finalWorld1 finalWorld3 就不会了，这在字符串篇会提到，StringBuilder 的合并是个比较例外的操作，会新建一个对象，两者都和 hw 不等。\n所以结果是：false true false true\n 怎样查看字节码 JDK 提供了 javap ；IDEA 提供了 View -\u0026gt; Show bytecode；Eclipse 也有类似工具；还有一些第三方工具，都可以。\n JVM 对频繁调用方法进行哪些优化 如果代码需要经常被调用，那么即时编译就比解释运行要高效，因此编译器找出被调用最频繁的代码作为“热点代码”进行编译，并进行最大程度优化，即时编译器负责进行这个任务。\nJVM的即使编译器（JIT）采用的优化手段包括：方法内联、逃逸分析、投机性优化等等；运行时优化常用手段包括：内存分配、动态绑定、偏斜锁等等。\nHotSpot 基于计数器进行热点探测，对于热点代码进行即时编译、栈上替换。\n Java 中什么是伪共享，怎么解决  https://www.cnblogs.com/javastack/p/9117134.html\n CPU 缓存系统中是以缓存行（cache line）为单位存储的。目前主流的 CPU Cache 的 Cache Line 大小都是 64 Bytes。在多线程情况下，如果需要修改“共享同一个缓存行的变量”，就会无意中影响彼此的性能，这就是伪共享（False Sharing）。\n由于共享变量在 CPU 缓存中的存储是以缓存行为单位，一个缓存行可以存储多个变量（存满当前缓存行的字节数）；而CPU对缓存的修改又是以缓存行为最小单位的，那么就会出现上诉的伪共享问题。直接带来的问题就是性能下降。\n解决方法就是——独占缓存行，以空间换效率。\nJava 8 中已经提供了官方的解决方案，Java 8 中新增了一个注解：@sun.misc.Contended。加上这个注解的类会自动补齐缓存行，需要注意的是此注解默认是无效的，需要在 jvm 启动时设置 -XX:-RestrictContended 才会生效。\n@sun.misc.Contended public final static class VolatileLong { public volatile long value = 0L; //public long p1, p2, p3, p4, p5, p6; ","date":"2021-07-10T00:00:00Z","image":"https://winterorch.github.io/images/feature/ArseniXC/Library.jpg","permalink":"https://winterorch.github.io/p/java-jvm-questions_2/","title":"Java - JVM 问题集合 (下)"},{"content":"JVM 内存结构、类加载相关问题 HotSpot 是什么 使用最广泛的 JVM，OpenJDK SunJDK 的 JVM。最早不是 Java 的虚拟机，在 JIT 方面具有一些先进的理念，被 SUN 收购。\n 堆和栈区别是什么 个人理解，不一定全面：\n   堆 栈     公有 线程私有   存放绝大多数对象实例、数组 存放局部变量表、操作数栈、动态链接、方法出口等   GC的主要场所 不需要GC，栈帧随方法调用结束而被弹出   生老病死与JVM紧密相关 生老病死与线程、函数调用紧密相关   不能动态扩容 可以通过配置动态扩容     哪块内存区不会OOM 公有部分： 堆，会OOM；方法区，虽然搬到了原生内存上，但还是有可能OOM的；JVM外的直接内存，肯定是可能OOM的。因此公有区全部有可能OOM。\n线程私有部分： 本地方法栈，为 Native 方法服务，也有OOM可能；虚拟机栈，OOM常客，允许动态扩容时会OOM，不允许则会 OverFlow，因此是会OOM的；程序寄存器，唯一不会出现OOM的区域，就是它。\n 一个线程OOM后，其它线程能否运行 无论哪种OOM，一个线程OOM后，所占据内存资源会被GC全部释放。无论是线程共享的堆内存，还是不共享的栈内存。\n因此，一个线程的OOM不会影响到其它线程运行，即使主线程抛异常退出，子线程仍能继续，除非子线程是主线程的守护线程。\n 对象一定是在堆上分配的吗 不一定。JVM通过逃逸分析，能够分析新对象的适用范围，以此确定是否要将对象分配到堆上，对于没有逃逸出方法的对象，很可能会被优先在栈上进行分配。\n 其实就像我们平常用Spring，有必要将所有对象都注册成Bean吗？肯定没必要，JVM也不傻，并非所有对象都会分配到堆上，毕竟GC也是有开销的。\n  为什么说一次编译，处处执行 两次编译机制，第一次由编译器编译成字节码，第二次由JVM转换到机器码，实际上是解释执行机制，解释工作由本地JVM完成，JVM担任了本地向导的责任，因此不是“处处执行”，是有本地向导，装了JVM的地方执行。\n 如何动态生成一个类   操作字节码\n这个在 Spring AOP ，尤其是 AspectJ 中有应用，主要通过 CGLIB 和 Javassist 两种库实现。理论可行，实际操作……非常麻烦，首先要研究清楚JVM的字节码规范，详细了解class结构，难度S++。\n  使用第三方Jar包\ncom.itranswarp.compiler 可以用来编写自己的工具类，从而实现动态生成类。\n  一些脚本语言\n最典型的是 Groovy，它原生支持动态生成对象；还有在大数据领域用的很多的 Scala；谷歌的 Aviator 。这些支持动态生成类。\n   Class.forName() 和 ClassLoader.loadClass 的区别 Class.forName() 除了将.class文件加载到JVM中，会对类进行解释，通过参数决定是否对加载的类进行初始化，从而是否执行类中的静态块，是否对静态变量进行赋值。\nClassLoader使用双亲委派模型只干一件事——将.class文件加载到JVM中，不执行静态块，在newInstance时才会执行静态块。Class.forName() 类加载也是通过 ClassLoader 实现。\n 字符串相关  包括new String(\u0026quot;xx\u0026quot;)创建多少个对象，两个字符串是否相等，intern()之后相不相等，这些会有一篇专门讲字符串常量池的笔记，放在这里太多了。\n  Java 8 内存结构的变化 最重要的就是元空间取代了永久代成为方法区的新实现，这一改变是为了减少永久代OOM的概率，因为永久代位于堆上，而它的GC机制又十分复杂，很容易造成性能劣化或OOM。\n GC相关、JVM 内存结构  GC之前有过了，内存结构也会单独整理。\n  双亲委派机制  https://www.jianshu.com/p/1e4011617650\n 当某个类加载器需要加载.class文件，首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此如果一个类确实没有被加载过，所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求(它的搜索范围中没有找到所需的类)时，子加载器才会尝试自己去完成加载。\nprotected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // 首先检查这个classsh是否已经加载过了  Class\u0026lt;?\u0026gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { // c==null表示没有加载，如果有父类的加载器则让父类加载器加载  if (parent != null) { c = parent.loadClass(name, false); } else { //如果父类的加载器为空 则说明递归到bootStrapClassloader了  //bootStrapClassloader比较特殊无法通过get获取  c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) {} if (c == null) { //如果bootstrapClassLoader 仍然没有加载过，则递归回来，尝试自己去加载class  long t1 = System.nanoTime(); c = findClass(name); sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } 源码显示，直到递归到bootStrapClassloader，如果仍没有加载过，就尝试自己去加载class。\n这一机制的作用是防止重复加载同一.class，同时保证核心.class不能被篡改。通过委托方式，即使篡改也不会去加载，即使加载也不会是同一个.class对象了。不同的加载器加载同一个.class也不是同一个Class对象。这样保证了Class执行安全。\n类加载器的类别\nBootstrapClassLoader 是顶层类加载器，唯一使用C++编写的类加载器，是JVM的一部分，加载核心库java.*（准确的说是负责加载存放在\u0026lt;JAVA_HOME\u0026gt;\\lib目录，或者被-Xbootclasspath参数指定的路径中存放的，且是JVM能够识别的类库），同时构造ExtClassLoader和AppClassLoader。涉及虚拟机本地实现细节，开发者无法直接获取启动类加载器引用。\n除BootstrapClassLoader外的其它类加载器都由Java语言实现，独立存在于JVM外部，且都继承于java.lang.Classloader抽象类。\nExtClassLoader 标准扩展类加载器，加载扩展库（\u0026lt;JAVA_HOME\u0026gt;\\home\\ext目录中，或者被java.ext.dirs系统变量所指定的路径中所有的类库），如classpath中的jre, javax.*或java.ext.dir指定位置中的类，可以直接使用。\nAppClassLoader 系统类加载器，加载程序所在目录，如user.dir所在位置class。开发者同样可以直接使用此类加载器，如果没有指定，则默认使用此类加载器。\n 为什么打破双亲委派机制 双亲委派机制解决了基础类统一问题（越基础的类由越上级的加载器加载），但是如果需要启动类加载器加载用户代码，需要调用独立厂商实现的ClassPath下SPI代码，则无法解决，因为启动类不认识这些代码。为此，大部分SPI都通过增加一个线程上下文加载器加载所需的SPI代码，造成了父类加载器请求子类加载器完成类加载，从而打破了双亲委派机制。\nTomcat 也违背了双亲委托机制，因为默认类加载器无法加载两个相同类库不同版本，做不到隔离，无法对JDP做到热修改，因为JSP也是class文件，类名不会变。双亲委派机制绑死了类名。\n为此，Tomcat的做法是每一个Web应用程序对应一个WebApp类加载器，每一个JSP文件对应一个Jsp类加载器。\n","date":"2021-07-09T00:00:00Z","image":"https://winterorch.github.io/images/feature/ArseniXC/Bunker.jpg","permalink":"https://winterorch.github.io/p/java-jvm-questions_1/","title":"Java - JVM 问题集合 (上)"},{"content":"生产者通过指定 RoutingKey (路由键) 指定消息路由规则。示例为 Spring AMQP 中 RabbitMQ 的使用。\n Spring AMQP 文档：https://docs.spring.io/spring-amqp/docs/current/reference/html/\n Exchange Types （交换器类型）   fanout\n最快的路由规则，Exchange 将所有接收到消息发送导与其绑定的所有队列中，不做任何判断操作，即使绑了路由键也会直接无视，常用来广播消息/** * Fanout */ @Bean public FanoutExchange fanoutExc() { return new FanoutExchange(FANOUT_EXCHANGE); } @Bean public Binding fanoutBinding1(Queue topicQueue1, FanoutExchange fanoutExc) { return BindingBuilder.bind(topicQueue1).to(fanoutExc); } @Bean public Binding fanoutBinding2(Queue topicQueue2, FanoutExchange fanoutExc) { return BindingBuilder.bind(topicQueue2).to(fanoutExc); }   direct\n将消息路由到 BindingKey 与 RoutingKey 完全匹配的队列中，常用来将有优先级的任务发到对应队列，得到更多处理资源  topic\n将消息路由到 BindingKey 和 RoutingKey 相匹配的队列中，但这里的匹配规则有些不同，它约定：\n RoutingKey 为一个点号 . 分隔的字符串（被点号 . 分隔开的每一段独立的字符串称为一个单词），如 com.rabbitmq.client、java.util.concurrent、com.hidden.client BindingKey 和 RoutingKey 一样也是点号 ．分隔的字符串 BindingKey 中可以存在两种特殊字符串 * 和 #，用于做模糊匹配，其中 * 用于匹配一个单词，# 用于匹配多个单词(可以是零个)  所以，如果当一个队列的绑定键为 # 的时候，这个队列将会无视消息的路由键，接收所有的消息。 当 * (星号) 和 # (井号) 这两个特殊字符都未在绑定键中出现的时候，此时主题交换机也就相当于直连交换机。\n  headers （不推荐）\n不依赖路由键而是 headers 属性进行完全匹配，性能很差因而不实用\n@Bean public static HeadersExchange headersExc() { return new HeadersExchange(HEADERS_EXCHANGE); } public Queue headerQueue() { return new Queue(HEADER_QUEUE, true); } @Bean public Binding headerBinding() { Map\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;header1\u0026#34;, \u0026#34;value1\u0026#34;); map.put(\u0026#34;header2\u0026#34;, \u0026#34;value2\u0026#34;); return BindingBuilder.bind(headerQueue()).to(headersExc()).whereAll(map).match(); }    可以如何使用 简单来讲，消息队列可以用来解耦模块、充当工作缓存、流量削峰\n  （简单模式）单生产者对应单消费者\n相当于工作缓存，如邮件服务从队列中取件进行发送\n  （工作队列模式）单生产者对应多消费者\n资源密集型任务中，多个消费者并行处理\n  （订阅模式）单生产者发到多消费者\n如库存更新后需要通知多个缓存和多个数据库，则通过 fanout 交换器分出两个消息队列，分别对应缓存和数据库\n  （路由模式）有选择地发送和接收\n指定路由 key\n  （主题模式）将队列需求绑定在特定模式上\n  （远程过程调用）在远程计算机上运行功能并等待结果\n通过RPC在远程计算机上运行功能并等待结果\n  （发布者确认）异步确认发送者发布消息\n用于实现可靠地分布，如扣款\n   如何解决消息丢失 消息丢失可能出现在生产者至MQ、消息队列本身、消费者三处。\n生产者导致的消息丢失\nRabbitMQ 事务机制为了避免消息丢失，可以在发送消息前，先开启执行 txSelect 方法开启一个事务，接着发送消息，如果消息投递失败，执行 txRollback 回滚事务，再执行重试操作重新发送，如果消息投递成功，执行 txCommit 方法提交事务。\n但是，RabbitMQ事务同步阻塞，因此一般不会这样做。更常用的方法是 Confirm 模式。RabbitMQ Confirm 模式 通过异步回调的方式，接收成功回调生产者ack接口，不成功回调nack接口。\n**注意：**Spring AMPQ 默认 publisher-confirm 为 false，需要手动设 true，此处可见下文关于 Spring AMQP publisher 参数内容。\n 因此，生产者与 broker 间消息可靠性保证思路就是\n 当消息发送到broker的时候，执行监听的回调函数。 在生产端要维护一个消息发送的表，消息发送的时候记录消息id，在消息成功落地broker磁盘并且进行回调确认（ack）的时候，根据本地消息表和回调确认的消息id进行对比，这样可以确保生产端的消息表中的没有进行回调确认（或者回调确认时网络问题）的消息进行补救式的重发，当然不可避免的就会在消息端可能会造成消息的重复消息。针对消费端重复消息，在消费端进行幂等处理。   RabbitMQ 导致消息丢失\nRabbitMQ 没有对消息进行持久化，消息就可能随 RabbitMQ 宕机而丢失。解决方法就是调整 Confirm 模式，让 RabbitMQ 在完成消息持久化，消息到了硬盘上，再返回ack接口。\n消费者导致消息丢失\nRabbitMQ 在默认的自动提交ack配置下，如果消息处理完之前消费者挂了，消息会丢失。将自动提交ack关闭后，如果消费者处理完消息前挂了，RabbitMQ 会认为没有处理成功，再次推送给消费者处理。\n 我们可以顺便来看一下 Kafka 和 RocketMQ 的处理\nKafka\n生产者导致消息丢失\n对于 Kafka 来说，生产者基本不会弄丢消息，因为生产者发送消息会等待 Kafka 响应成功，如果响应失败，生产者会自动不断地重试。\nBroker端弄丢了数据\nKafka 通常会一台 leader + 两台 follower，当生产者消息刚写入 leader 成功，但是还没同步到 follower 时，leader 宕机了，此时会重新选举 leader，新的 leader 由于还未同步到这条数据，导致该条消息丢失。\n解决办法是做一些配置，当有其他 follower 同步到了消息后才通知生产者消息接收成功了。配置如下：\n 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。 在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower。 在 producer 端设置 acks=all ：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。  按上面的配置配置后，就可以保证在 Kafka Broker 端就算 leader 故障了，进行新 leader 选举切换时，也不会丢失数据。\n消费者导致消息丢失\nKafka 消费端弄丢数据原因跟 RabbitMQ 类似，Kafka 消费者会在接收到消息的时候，会自动提交一个 offset 给 Kafka，告诉 Kafka 消息已经处理了。处理方法也跟 RabbitMQ 类似，关闭 offset 的自动提交即可。\n RocketMQ\nRocketMQ 导致数据丢失的原因与前面的 RabbitMQ 和 Kafka 都很类似。生产者就是因为网络抖动等原因消息投递失败，或者 RocketMQ 自身的 Master 节点故障，主备切换故障之类的，消费者则有可能是异步处理导致还未处理成功就给 RocketMQ 提交了 offset 标识消息已处理了。\n在 RocketMQ 中，事务消息可以保证消息零丢失。RocketMQ 的事务消息基于这三个业务流程：生产者向RocketMQ发送 half 消息 -\u0026gt; RocketMQ 对 half 消息响应 -\u0026gt; commit/rollback。\n 如果生产者发送 half 失败，则作重试或对消息作持久化，给用户返回失败 如果RocketMQ处理失败，则生产者回滚该条消息，请求失败 如果 half 发送成功，但 RocketMQ 响应没能够传回，则会通过补偿机制回调接口，决定 commit 还是 rollback 包括 commit 或 rollback 时发生的失败都是用补偿机制处理    Spring AMQP 一般 Producer Consumer 设置 Producer\n写一个 Config 类来进行 Binding\n@Configuration public class BindingConfig { public final static String first=\u0026#34;direct.first\u0026#34;; public final static String Exchange_NAME=\u0026#34;directExchange\u0026#34;; public final static String RoutingKey1=\u0026#34;directKey1\u0026#34;; @Bean public Queue queueFirst(){ return new Queue(first); } @Bean public DirectExchange directExchange(){ return new DirectExchange(Exchange_NAME); } //利用BindingBuilder绑定Direct与queueFirst  @Bean public Binding bindingExchangeFirst(Queue queueFirst, DirectExchange directExchange){ return BindingBuilder.bind(queueFirst).to(directExchange).with(RoutingKey1); } } 为消息套一个 UUID，方便在ack或nack时回调处理。\nprivate CorrelationData getCorrelationData() { return new CorrelationData(UUID.randomUUID().toString()); } ConfirmCallBack 只返回标识值，因此作为 Publisher，可以维护一个 CorrelationID 到 发送信息 的 K-V 关系，从而在发送失败时再做处理，或者删除绑定关系。\nConsumer\nConsumer 侧的 ConnectionFactory 配置和 Producer 侧是完全一样的。BindingConfig 也完全一致：\n@Configuration public class BindingConfig { public final static String first=\u0026#34;direct.first\u0026#34;; public final static String Exchange_NAME=\u0026#34;directExchange\u0026#34;; public final static String RoutingKey1=\u0026#34;directKey1\u0026#34;; @Bean public Queue queueFirst(){ return new Queue(first); } @Bean public DirectExchange directExchange(){ return new DirectExchange(Exchange_NAME); } //利用BindingBuilder绑定Direct与queueFirst  @Bean public Binding bindingExchangeFirst(Queue queueFirst, DirectExchange directExchange){ return BindingBuilder.bind(queueFirst).to(directExchange).with(RoutingKey1); } } 然后通过 @RabbitListener 定义响应函数：\n@Configuration @RabbitListener(queues=\u0026#34;direct.first\u0026#34;) public class RabbitMqListener { @RabbitHandler public void handler(String message) { System.out.println(message); } } Binding 过程也可以在 RabbitMqListener 中完成：\n@Configuration @RabbitListener(bindings=@QueueBinding( exchange=@Exchange(value=\u0026#34;directExchange\u0026#34;), value=@Queue(value=\u0026#34;direct.second\u0026#34;), key=\u0026#34;directKey2\u0026#34;)) public class RabbitListener { @RabbitHandler public void handler(String message) { System.out.println(message); } }  回调配置 AMQP 有三个相关参数：publisher-confirms publisher-returns 和 mandatory 。\n其中 mandatory 主要管的是消息投到 Exchange 之后，Exchange 无法将其路由到任何队列之后的操作，true 则把消息还给生产者，false 则丢弃。不过，按照 Spring 源码的逻辑，不开启 publisher-returns 就不会进行消息回调，因此要 mandatory publisher-returns 必须都开才能起作用。另外，returnCallback 回调时返回的直接是经过封装的 byte[]，需要进行反序列化来还原原消息。\n值得注意的一个小点是，Spring 中的 mandatory 是 template 的参数而不是 rabbitmq 的。\npublisher-confirms 是针对消息没有被成功放入Exchange的情况，无论成功失败都会调用回调函数，通过 ConfirmCallback 进行回调。\n","date":"2021-07-07T00:00:00Z","image":"https://winterorch.github.io/images/feature/ArseniXC/Harbor.jpg","permalink":"https://winterorch.github.io/p/rabbitmq-basic/","title":"RabbitMQ - 基本概念和 SpringBoot 下的使用"},{"content":"Redis 提供事务(Transaction)和管道(Pipeline)，两个概念都不复杂，可以对比来看，管道可以广泛用于提升 Redis 读写效率。\nRedis Transactions Redis 原本通过 multi exec 和 discard 指令执行事务。RedisTemplate\u0026lt;\u0026gt; 本身提供三个同名方法来支持事务，但是 RedisTemplate 本身封装程度高，不能保证这种事务定义下的所有操作在同一次 Redis 连接中被执行。\n因此，作为一种封装度更低的替代，Spring Data Redis 提供 SessionCallback 来确保多个操作在同一次 Redis 链接中进行。\n//execute a transaction List\u0026lt;Object\u0026gt; txResults = redisTemplate.execute(new SessionCallback\u0026lt;List\u0026lt;Object\u0026gt;\u0026gt;() { public List\u0026lt;Object\u0026gt; execute(RedisOperations operations) throws DataAccessException { operations.multi(); operations.opsForSet().add(\u0026#34;key\u0026#34;, \u0026#34;value1\u0026#34;); // This will contain the results of all operations in the transaction  return operations.exec(); } }); System.out.println(\u0026#34;Number of items added to set: \u0026#34; + txResults.get(0)); SessionCallback 的 execute 返回值仍会经过 RedisTemplate 的反序列化操作 ，然后作为 RedisTemplate 的 execute 结果返回。\n 1.1 后对于连接返回值的转换与否发生了变化\nAs of version 1.1, an important change has been made to the exec methods of RedisConnection and RedisTemplate. Previously, these methods returned the results of transactions directly from the connectors. This means that the data types often differed from those returned from the methods of RedisConnection. For example, zAdd returns a boolean indicating whether the element has been added to the sorted set. Most connectors return this value as a long, and Spring Data Redis performs the conversion. Another common difference is that most connectors return a status reply (usually the string, OK) for operations such as set. These replies are typically discarded by Spring Data Redis. Prior to 1.1, these conversions were not performed on the results of exec. Also, results were not deserialized in RedisTemplate, so they often included raw byte arrays. If this change breaks your application, set convertPipelineAndTxResults to false on your RedisConnectionFactory to disable this behavior.\n @Transactional RedisTemplate 默认不能加 @Transactional 标签，但可以通过 template.setEnableTransactionSupport(true) 来开启。\n Enabling transaction support binds RedisConnection to the current transaction backed by a ThreadLocal. If the transaction finishes without errors, the Redis transaction gets commited with EXEC, otherwise rolled back with DISCARD.\n 但这样做存在一些限制\n// must be performed on thread-bound connection template.opsForValue().set(\u0026#34;thing1\u0026#34;, \u0026#34;thing2\u0026#34;); // read operation must be run on a free (not transaction-aware) connection template.keys(\u0026#34;*\u0026#34;); // returns null as values set within a transaction are not visible template.opsForValue().get(\u0026#34;thing1\u0026#34;); Redis Pipelining Redis 管道允许一次性发送多条指令而不单独等待每条的回复（即不用等待 RTT），所有恢复将在最后一次性读取。这样做会提升指令发送速度，尤其在向一个 List 中添加大量元素时。\n如果完全不关注返回结果，可以使用 RedisTemplate 的 execute 方法，传递 true 的 pipeline 参数。executePipelined 方法以 RedisCallback 或 SessionCallback 为输入，在一个 pipeline 中完成运行并返回所有结果。\n以下是一个通过 pipeline 从队列右端 pop 出一堆元素的方法：\nList\u0026lt;Object\u0026gt; results = stringRedisTemplate.executePipelined( new RedisCallback\u0026lt;Object\u0026gt;() { public Object doInRedis(RedisConnection connection) throws DataAccessException { StringRedisConnection stringRedisConn = (StringRedisConnection)connection; for(int i=0; i\u0026lt; batchSize; i++) { stringRedisConn.rPop(\u0026#34;myqueue\u0026#34;); } return null; } }); 两者区别 首先，Pipline 和 Transaction 是完全不同的两种机制，互相不能够替代——\n  Pipeline 本质是客户端对指令进行打包发送的行为，服务端是透明的；Transaction 本质是服务端执行指令时进行的打包，由客户端指令指挥\n因此，Pipeline 最终要的作用是减少客户端等待时间，从而提升客户端程序性能，不能保证原子性（服务端只会看作一系列普通指令，当然不会保证原子性的）。而 Transaction 因为使用 MULTI/EXEC 事务机制，虽然从 SQL 事务 ACID 角度来看不满足原子性，但如果全部指令都能被正确执行，程序上是满足原子性的，执行过程中不会被打断。\n  Pipeline 不会阻塞服务端，但 Transaction 会阻塞服务端\n实际应用中使用 LUA 脚本来满足原子性要比 Transaction 高效得多。考虑网络吞吐问题，需要高频执行的脚本甚至可以预加载到服务端，需要调用时直接传脚本 SHA1（在预加载时会由服务端发回） + 参数 来进行调用。\n  LUA 值得注意的一点是启动程序时可以将 LUA 脚本预加载到 Redis 服务器\n@PostConstruct public void loadScript() { String execute = strRedisTemplate.execute((RedisCallback\u0026lt;String\u0026gt;) connection -\u0026gt; connection.scriptLoad(flashSaleIfExistScript.getScriptAsString().getBytes())); } scriptLoad 的返回结果是脚本对应的 SHA1，但是我们其实并不需要保存，因为RedisScript 本身在加载脚本时会计算一次 SHA1 ，可以直接通过 getSha1() 获得。\n需要调用时直接传脚本 SHA1（在预加载时会由服务端发回） + 参数 来进行调用。Redis 支持的脚本执行指令包括 eval 和 evalsha 两个，Redis Template 将这两条指令都封装在了 org.springframework.data.redis.connection 包中 RedisScriptingCommands 接口下。\n ScriptExecutor 在执行时会首先通过 evalsha 来执行脚本，如果 Redis 脚本缓存中没有对应脚本再退回到 eval 方法。\n 根据以上官方文档的描述，我们不需要主动调用 evalsha ，ScriptExecutor 会自动替我们完成。那我们来看看 Spring Data Redis 源码怎么写的，先找到 DefaultScriptExecutor 。\npublic \u0026lt;T\u0026gt; T execute(RedisScript\u0026lt;T\u0026gt; script, List\u0026lt;K\u0026gt; keys, Object... args) { return this.execute(script, this.template.getValueSerializer(), this.template.getValueSerializer(), keys, args); } public \u0026lt;T\u0026gt; T execute(RedisScript\u0026lt;T\u0026gt; script, RedisSerializer\u0026lt;?\u0026gt; argsSerializer, RedisSerializer\u0026lt;T\u0026gt; resultSerializer, List\u0026lt;K\u0026gt; keys, Object... args) { return this.template.execute((connection) -\u0026gt; { ReturnType returnType = ReturnType.fromJavaType(script.getResultType()); byte[][] keysAndArgs = this.keysAndArgs(argsSerializer, keys, args); int keySize = keys != null ? keys.size() : 0; if (!connection.isPipelined() \u0026amp;\u0026amp; !connection.isQueueing()) { return this.eval(connection, script, returnType, keySize, keysAndArgs, resultSerializer); } else { connection.eval(this.scriptBytes(script), returnType, keySize, keysAndArgs); return null; } }); } 可以看到，除非在管道或队列操作中，否则所有的 execute 最终都会落到 eval 这个方法上。\nprotected \u0026lt;T\u0026gt; T eval(RedisConnection connection, RedisScript\u0026lt;T\u0026gt; script, ReturnType returnType, int numKeys, byte[][] keysAndArgs, RedisSerializer\u0026lt;T\u0026gt; resultSerializer) { Object result; try { result = connection.evalSha(script.getSha1(), returnType, numKeys, keysAndArgs); } catch (Exception var9) { if (!ScriptUtils.exceptionContainsNoScriptError(var9)) { throw var9 instanceof RuntimeException ? (RuntimeException)var9 : new RedisSystemException(var9.getMessage(), var9); } result = connection.eval(this.scriptBytes(script), returnType, numKeys, keysAndArgs); } return script.getResultType() == null ? null : this.deserializeResult(resultSerializer, result); } 确实，evalSha 如果不能得到正确结果就会抛异常，转而用 eval 方法了。这对于不预载脚本的场景是不是低效了点？\n","date":"2021-07-06T00:00:00Z","image":"https://winterorch.github.io/images/feature/ArseniXC/Village.jpg","permalink":"https://winterorch.github.io/p/redis-spring_trans-pipeline/","title":"Redis - Spring Data Redis 中的 Transaction 与 Pipeline"},{"content":"LeetCode 347. Top K Frequent Elements Given a non-empty array of integers, return the k most frequent elements.\nExample 1:\nInput: nums = [1,1,1,2,2,3], k = 2\rOutput: [1,2]\rExample 2:\nInput: nums = [1], k = 1\rOutput: [1]\rNote:\n You may assume k is always valid, 1 ≤ k ≤ number of unique elements. Your algorithm\u0026rsquo;s time complexity must be better than O( n log n ), where n is the array\u0026rsquo;s size.   分析\n要统计数组中出现频率前k高的数字。从数字到频率，考虑用HashMap来建立映射。然后再处理前k高的问题。\n题解\n首先遍历一遍数组，统计各数字出现次数，确定使用HashMap几乎没什么争议。\nMap\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for(int num : nums) { if(map.containsKey(num)) { map.compute(num, (key, v) -\u0026gt; { ++v; return v; }); }else { map.put(num, 1); } } 要取其中出现次数（value）前k高的元素，一定需要进行排序，有两种方法可供选择\n 题解、堆排序 看到第k大\\小马上想到的方法，Java实现起来也非常方便。因为前面已经用了Map，这里不需要再引入新的数据结构，直接用Map.Entry建堆就可以了。前k大，所以建一个大顶堆，全部加进去之后poll出k个来就行了。\n时间复杂度$O(n\\log n)$\nint[] res = new int[k]; //统计出现次数 Map\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for(int num : nums) { if(map.containsKey(num)) { map.compute(num, (key, v) -\u0026gt; { ++v; return v; }); }else { map.put(num, 1); } } //建堆 PriorityQueue\u0026lt;Map.Entry\u0026lt;Integer, Integer\u0026gt;\u0026gt; maxHeap = new PriorityQueue\u0026lt;\u0026gt;(Comparator.comparingInt(o -\u0026gt; -o.getValue())); maxHeap.addAll(map.entrySet()); //输出 for(int i = 0; i \u0026lt; k; ++i) res[i] = maxHeap.poll().getKey(); return res;  题解、计数（桶）排序 我们知道桶排序时间复杂度是$O(n)$，要能派上用场肯定比堆排序好，那用什么建桶呢？用输入数组中的数字不适合直接建桶，因为我们并不关心其大小，需要关心的是出现次数。\n长度为nums.length的数组，那出现次数最多也就是nums.length，我们可以跟据出现次数来建桶，每个桶中的数出现次数都相同，这其实就像考生排名次，分数（出现次数）越大的名词数越低（在输出数组中下标越小），那这其实就是一种特殊的桶排序——计数排序，按出现次数进行计数。\nint[] res = new int[k]; int resIdx = 0; //统计出现次数 Map\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for(int num : nums) { if(map.containsKey(num)) { map.compute(num, (key, v) -\u0026gt; { ++v; return v; }); }else { map.put(num, 1); } } //统计每个桶中数据量，即出现次数相同的数字个数，按出现次数存入reference[]中 //顺便统计一下最大的出现次数 Set\u0026lt;Map.Entry\u0026lt;Integer, Integer\u0026gt;\u0026gt; entrySet = map.entrySet(); int maxOccurrence = 1; int[] reference = new int[nums.length + 1]; for(Map.Entry\u0026lt;Integer, Integer\u0026gt; entry : entrySet) { reference[entry.getValue()]++; if(maxOccurrence \u0026lt; entry.getValue()) maxOccurrence = entry.getValue(); } //将数组每一元素更新为包括自身在内之前所有元素之和，形成索引数组 for(int i = 1; i \u0026lt;= maxOccurrence; ++i) { reference[i] += reference[i - 1]; } //计数排序不可避免的是从小开始，我们要找的是前k大， //也就是在最终排序输出数组中位置大于(entrySet.size()-k-1)的部分 k = entrySet.size() - k - 1; for(Map.Entry\u0026lt;Integer, Integer\u0026gt; entry : entrySet) { //同一次数，出现多次的，递减以防止重叠  reference[entry.getValue()]--; if(reference[entry.getValue()] \u0026gt; k) res[resIdx++] = entry.getKey(); } return res; Entry\u0026lt;Integer, Integer\u0026gt;中的键(Key)是我们最终要输出的原数字，而值(Value)是我们关心的出现次数，如果我们有建立一个从出现次数到原数字的“反向映射”，那也可以对出现次数数组（valueSet）进行进行遍历排序，然后输出对应的键。\n但是实际上，Java提供的Entry已经足够好用，建立反向映射需要大量额外空间，但却不能保证带来时间效率的提升，所以直接对Map.EntrySet进行遍历，输出排序结果就行了，这一部分的时间复杂度实际已经低于$O(n)$，是$O(j)$（$j$为nums[]中不同元素个数）。\n总而言之，桶排序的时间复杂度为$O(n)$\n最后，我们知道由于伪泛型设计，Java中的HashMap既没有STL中的Map效率高，用起来也不方便，因此，大部分情况下可以考虑一下用数组代替。然而这道题数字没有给范围，从负数到最大10^5都有可能，用数组不方便，因此作罢。\n","date":"2021-07-03T00:00:00Z","image":"https://winterorch.github.io/images/category/leetcode/TeaParty.jpg","permalink":"https://winterorch.github.io/p/leetcode-347-%E5%89%8D-k-%E4%B8%AA%E9%AB%98%E9%A2%91%E5%85%83%E7%B4%A0/","title":"LeetCode 347 - 前 K 个高频元素"},{"content":"[LeetCode] 451. Sort Characters By Frequency 题目： 给定一个字符串，请将字符串里的字符按照出现的频率降序排列。\n示例 1:\n 输入: \u0026ldquo;tree\u0026rdquo;\n输出: \u0026ldquo;eert\u0026rdquo;\n解释: \u0026lsquo;e\u0026rsquo;出现两次，\u0026lsquo;r\u0026rsquo;和\u0026rsquo;t\u0026rsquo;都只出现一次。 因此\u0026rsquo;e\u0026rsquo;必须出现在\u0026rsquo;r\u0026rsquo;和\u0026rsquo;t\u0026rsquo;之前。此外，\u0026ldquo;eetr\u0026quot;也是一个有效的答案。\n 示例2：\n 输入: \u0026ldquo;cccaaa\u0026rdquo;\n输出: \u0026ldquo;cccaaa\u0026rdquo;\n解释: \u0026lsquo;c\u0026rsquo;和\u0026rsquo;a\u0026rsquo;都出现三次。此外，\u0026ldquo;aaaccc\u0026quot;也是有效的答案。 注意\u0026quot;cacaca\u0026quot;是不正确的，因为相同的字母必须放在一起。\n 示例3：\n 输入: \u0026ldquo;Aabb\u0026rdquo;\n输出: \u0026ldquo;bbAa\u0026rdquo;\n解释: 此外，\u0026ldquo;bbaA\u0026quot;也是一个有效的答案，但\u0026quot;Aabb\u0026quot;是不正确的。 注意\u0026rsquo;A\u0026rsquo;和\u0026rsquo;a\u0026rsquo;被认为是两种不同的字符。\n  题解 思路1：HashMap计数+排序 字符串里的字符和出现频率形成一对K-V组合，解决按频率排序题目的第一思路是建一个HashMap统计出现频率，跟据一个从频率(Map的value)到原字符(Map的key)的反向映射，通过排序输出，主要步骤抽象如下：\n 使用HashMap记录字符出现的频率 将HashMap转化成List按value进行降序排序 遍历List，将字符按出现次数降序放入答案中  代码如下：\nclass Solution { public String frequencySort(String s) { StringBuilder sb = new StringBuilder(); // 1. 使用HashMap记录字符出现的频率  Map\u0026lt;Character, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for(int i = 0; i \u0026lt; s.length(); i++){ map.put(s.charAt(i), map.getOrDefault(s.charAt(i), 0) + 1); } // 2. 将HashMap转化成List按value进行排序  List\u0026lt;Map.Entry\u0026lt;Character, Integer\u0026gt;\u0026gt; l = new ArrayList\u0026lt;\u0026gt;(map.entrySet()); Collections.sort(l, (o1, o2) -\u0026gt; { return o2.getValue() - o1.getValue(); }); //3. 遍历List，将字符按出现次数放入答案中  for(Map.Entry\u0026lt;Character, Integer\u0026gt; entry : l){ char c = entry.getKey(); int time = entry.getValue(); while(time-- \u0026gt; 0){ sb.append(c); } } return sb.toString(); } } 时间复杂度：O(n+klogk) 空间复杂度：O(n+k)\n这是一个不错的解题手法，向面试官展示了出色的API调用技术——当然我们还可以对时间复杂度进行优化：如果我们以字符出现的最大频率作为长度声明一个数组，用于存放每个频率出现过的字符，那么排序的时间复杂度可以进一步降低至O(k)，下面将介绍这种被称作桶排序的排序方法。\n思路2：HashMap计数+桶排序 桶排序的思路网上比我讲解得更清楚，因此在此主要阐述针对该题的解题思路：\n 使用HashMap记录字符出现的频率，并记录字符出现的最大频率 创建桶，用于存放每个频率出现过的字符 遍历桶，将字符按出现次数降序放入答案中  class Solution { public String frequencySort(String s) { StringBuilder sb = new StringBuilder(); //1 使用HashMap记录字符出现的频率，并记录字符出现的最大频率  Map\u0026lt;Character, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); int max = 0; for(int i = 0; i \u0026lt; s.length(); i++){ int curFreq = map.getOrDefault(s.charAt(i), 0) + 1; map.put(s.charAt(i), curFreq); max = Math.max(max, curFreq); } //2.1 创建桶  List\u0026lt;Character\u0026gt;[] buckets = new ArrayList[max]; for(int i = 0; i \u0026lt; max; i++){ buckets[i] = new ArrayList\u0026lt;Character\u0026gt;(); } //2.2 存放每个频率出现过的字符  for(Map.Entry\u0026lt;Character, Integer\u0026gt; entry : map.entrySet()){ buckets[entry.getValue() - 1].add(entry.getKey()); } //3 遍历桶，将字符按出现次数降序放入答案中  for(int i = max - 1; i \u0026gt;= 0; i--){ for(char c : buckets[i]){ for(int j = 0; j \u0026lt;= i; j++){ sb.append(c); } } } return sb.toString(); } } 时间复杂度：O(n+k) 空间复杂度：O(n+k)\n和思路一主要的不同点是使用桶排序将排序的时间复杂度降到了k，做出了一些微小的贡献。但是在某些极端的面试官面前，我们的操作还是在库函数里边玩泥巴。我的室友就曾遇到过阿里的面试官死活不让调用HashMap的接口——“想要用哈希表就自己手写一个！”，对方如是说道。\n手撸HashMap的确是有难度，但是对于这种规整的数据（ASCII码字符），也可以使用数组模拟Map的方法实现：声明一个长度为256位的数组，将出现的频率按照ASCII值存入数组即可。\n思路2改进：数组模拟Map+桶排序 我们知道，HashMap效率并不高，加上Java的伪泛型设计，Map用起来并不如C++ STL那么方便，这道题统计频率的对象又是字符，最多不过0-256，完全可以用一个数组来进行统计。思路还是不变的。\n 使用Map数组记录字符出现的频率，并记录字符出现的最大频率 创建桶，用于存放每个频率出现过的字符 遍历桶，将字符按出现次数降序放入答案中  class Solution { public String frequencySort(String s) { if(s.length() \u0026lt; 3) return s; StringBuilder sb = new StringBuilder(); //1 使用Map数组记录字符出现的频率，并记录字符出现的最大频率  int[] map = new int[256]; char[] arr = s.toCharArray(); int max = 0; int length = s.length(); for (char c : arr) { map[c]++; max = Math.max(max, map[c]); } //2.1 创建桶  List\u0026lt;Character\u0026gt;[] buckets = new ArrayList[max]; for(int i = 0; i \u0026lt; max; i++){ buckets[i] = new ArrayList\u0026lt;Character\u0026gt;(); } //2.2 存放每个频率出现过的字符  for(int i = 0; i \u0026lt; 256; i++){ if(map[i] \u0026gt; 0){ buckets[map[i] - 1].add((char) i); } } //3 遍历桶，将字符按出现次数降序放入答案中  for(int i = max - 1; i \u0026gt;= 0; i--){ for(char c : buckets[i]){ for(int j = 0; j \u0026lt;= i; j++){ sb.append(c); } } } return sb.toString(); } } 时间消耗从 22 ms 优化到 6 ms。\n思路2改进：数组模拟Map+计数排序 这道题要求按序输出，我们可以直接进行计数排序，将时间复杂度降到 O(n) 。\n参考数组reference[i]存的是出现i次字符的个数，用于输出时进行参考。再从头进行一次累加，从而确定在输出序列中的序号。这就是计数排序的思路。\npublic String frequencySort(String s) { if(s.length() \u0026lt; 3) return s; StringBuilder res = new StringBuilder(); char[] arr = s.toCharArray(); int[] map = new int[256]; for (char c : arr) { map[c]++; } int maxOccurrence = 1, len = 0; int[] reference = new int[arr.length + 1]; for (int occur : map) { if (occur \u0026gt; 0) { reference[occur]++; len++; if (occur \u0026gt; maxOccurrence) { maxOccurrence = occur; } } } for (int i = 1; i \u0026lt;= maxOccurrence; ++i) { reference[i] += reference[i - 1]; } //我们先利用参考数组将所有字符进行排序，相同频率的字符放入时减一，从而错开位置。  char[] dict = new char[len]; for (char i = 0; i \u0026lt; 256; ++i) { if (map[i] \u0026gt; 0) { dict[len - 1 - --reference[map[i]]] = i; } } for (char tmp : dict) { for (int i = 0; i \u0026lt; map[tmp]; ++i) { res.append(tmp); } } return res.toString(); } 时间可以优化到 4 ms。\n","date":"2021-07-03T00:00:00Z","image":"https://winterorch.github.io/images/category/leetcode/TeaParty.jpg","permalink":"https://winterorch.github.io/p/leetcode-451-%E6%A0%B9%E6%8D%AE%E5%AD%97%E7%AC%A6%E5%87%BA%E7%8E%B0%E9%A2%91%E7%8E%87%E6%8E%92%E5%BA%8F/","title":"LeetCode 451 - 根据字符出现频率排序"},{"content":"645. Set Mismatch 题目  集合 s 包含从 1 到 n 的整数。不幸的是，因为数据错误，导致集合里面某一个数字复制了成了集合里面的另外一个数字的值，导致集合 丢失了一个数字 并且 有一个数字重复 。\n给定一个数组 nums 代表了集合 S 发生错误后的结果。\n请你找出重复出现的整数，再找到丢失的整数，将它们以数组的形式返回。\n 示例 1：\n输入：nums = [1,2,2,4]\r输出：[2,3]\r示例 2：\n输入：nums = [1,1]\r输出：[1,2]\r提示：\n 2 \u0026lt;= nums.length \u0026lt;= 104 1 \u0026lt;= nums[i] \u0026lt;= 104  题解 思路1：哈希表 以数字的值为 key，以数字是否出现过为 value，存入哈希表中。在存储的过程中若发现该 key 对应的 value 已经为 true，则该 key 为重复的数字。存储完成后遍历哈希表，如果某个 key 对应的 value 为 false，则该 key 为丢失的数字。\n在[LeetCode 451 - 根据字符出现频率排序]中介绍了使用数组模拟Map的方法，此例中该方法依然适用。\nclass Solution { public int[] findErrorNums(int[] nums) { //创建map用于指示数字是否出现过  boolean[] map = new boolean[nums.length]; int[] res = new int[2]; //存储的同时查询数字是否为第二次出现  for(int num : nums){ if(map[num - 1]){ res[0] = num; }else{ map[num - 1] = true; } } //遍历hash表，查找丢失的数字  for(int i = 0; i \u0026lt; map.length; i++){ if(!map[i]){ res[1] = i + 1; break; } } return res; } } 思路2：位运算 如果将 nums 和1 ~ n 这2n个数字异或，最后的结果 xor 将会是丢失的数字 n1 与重复的数字 n2 的异或。xor 中的每一个值都是 n1 与 n2 的二进制表示中不相同的位。\n取其中的一位 bit 与 nums 逐个异或，可以将 nums 分成两组，一组应该存在 n1但它缺失了，另一组 n2 出现了两次。\n取 bit 和 1 ~ n 逐个异或同样可以将其分成两组。将对应的组别异或即可得到 n1 与 n2 。\n最后查找 nums 中出现过的数字为 n2 ，否则其为 n1 。\nclass Solution { public int[] findErrorNums(int[] nums) { int n = nums.length; //计算 n1 ^ n2  int xor = 0; for (int num : nums) { xor ^= num; } for (int i = 1; i \u0026lt;= n; i++) { xor ^= i; } //取 n1 与 n2 二进制表示中一个不相同的位  int lowbit = xor \u0026amp; (-xor); //将 nums 分成两组  int num1 = 0, num2 = 0; for (int num : nums) { if ((num \u0026amp; lowbit) == 0) { num1 ^= num; } else { num2 ^= num; } } //将 1 ~ n 分成两组并异或得到 n1 和 n2  for (int i = 1; i \u0026lt;= n; i++) { if ((i \u0026amp; lowbit) == 0) { num1 ^= i; } else { num2 ^= i; } } //辨别 n1 和 n2  for (int num : nums) { if (num == num1) { return new int[]{num1, num2}; } } return new int[]{num2, num1}; } } ","date":"2021-07-03T00:00:00Z","image":"https://winterorch.github.io/images/category/leetcode/AfternoonTea.jpg","permalink":"https://winterorch.github.io/p/leetcode-645-%E9%94%99%E8%AF%AF%E7%9A%84%E9%9B%86%E5%90%88/","title":"LeetCode 645 - 错误的集合"},{"content":"NIO 与 AIO 模型 NIO（一般用同步非阻塞模式，如果阻塞就是 BIO 了）：服务器实现模式为一个请求一个线程，客户端发送连接请求全部注册到多路复用器上，多路复用器轮询到连接有 I/O 请求时才启动一个线程进行处理（解决了连接多而 I/O 少时资源占用问题）。\n NIO模型 \nAIO（异步非阻塞）：服务器实现模式为一个有效请求一个线程，客户端I/O请求由OS先完成再通知服务器应用启动线程进行处理。\n那么，为什么 Netty 选择 NIO 模型呢？\n 由于 UNIX 系统上 AIO 不成熟，底层仍然使用 EPOLL，没有很好实现 AIO，且 JDK 加了一层封装，因此实际速度并不比 NIO (epoll) 快。\nNetty 整体架构为 Reactor 模型，AIO 为 Proactor 模型，整合起来复杂且冗余度高。\nAIO 接收数据需要预分配内存，NIO 接收时才分配。AIO 对连接数量高但流量小的情况内存浪费大。\n Netty常见应用场景   作为 RPC 框架的网络通信工具\n分布式系统不同服务节点之间相互调用需要 RPC 框架\n  实现简单的 HTTP 服务器\n  实现即时通讯系统\n  实现消息推动系统\n  扩展：Java NIO  Selector\n多路复用器 Selector 建立在非阻塞基础上。\n  Channel 被注册到 Selector 上，FileChannel 不支持非阻塞\nchannel.configureBlocking(false); // 注册 SelectionKey key = channel.register(selector, SelectionKey.OP_READ); 第二个参数表明感兴趣事件，通过掩码形式传入：\n  SelectionKey.OP_READ\n 对应 00000001，通道中有数据可以进行读取\n   SelectionKey.OP_WRITE\n 对应 00000100，可以往通道中写入数据\n   SelectionKey.OP_CONNECT\n 对应 00001000，成功建立 TCP 连接\n   SelectionKey.OP_ACCEPT\n 对应 00010000，接受 TCP 连接\n   如果要监听多个事件，指定多位即可\n  调用 select() 方法获取通道信息，用于判断是否又感兴趣事件发生\n  异步 IO\nJava 异步 IO 提供了返回 Future 实例和使用回调函数 CompletionHandler 两种方式。\n 扩展：Linux Epoll  Linux 下的 Epoll 实例（epfd 通过本地方法 epoll_create 创建）用文件描述符表示，程序中注册的 Socket Channel 都会放到 Selector（Epoll）内部的 channel 集合中。\nint epoll_create(int size); //\t创建epoll实例，返回文件描述符用于epoll接口后续调用 当多路复用器进行 select ，通过本地方法 epollCtl 将事件注册到 epfd 上进行监听。\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); //\t用文件描述符epfd引用的epoll实例，对目标文件描述符fd执行op操作 本地方法 epollWait 阻塞等待读写事件发生，如果发生则由 OS 通过中断程序调用回调函数放到 Epoll 内的就绪事件列表 rdlist 。因此如果 rdlist 中已经有了 socket 引用，epoll_wait 返回，如果为空则阻塞进程。\nEpoll Select Poll 三种底层机制的差异\nselect 基于对所有 channel 的轮询遍历，每次调用都进行线性遍历，时间复杂度 $O(n)$ ，由于在数组上实现，最大连接有上限。\npoll 同样是对 channel 进行轮询，但在链表上实现，最大连接无上限。\n以上两种方法的共同问题是——要直到哪几个通道准备好了，需要自己进行一次遍历。\nepoll 通过回调，底层用哈希表实现，每当有 IO 事件就绪，系统注册的回调函数被调用，时间复杂度 $O(1)$ 。\n  Netty 支持的三种 Reactor 线程模型 Reactor 单线程模型\n所有 I/O 操作在同一 NIO 线程上完成，NIO 线程有以下任务：\n 作为 Server ，接收 Client 的 TCP 连接 作为 Client ，向 Server 发起 TCP 连接 读取通信对端的请求或应答消息 向通信对端发送消息请求或应答消息   \n如上图所示，套接字分离、Accept 新连接、分派请求等全部由一个线程完成，对于小容量场景可行，但高负载下一定无法支撑，会造成大量消息积压、大量超时重发请求进一步拥塞系统资源，造成节点故障。\nReactor 多线程模型\nI/O 操作由一组 NIO 线程协作完成：\n 专门的 NIO 线程 —— Acceptor 用于监听 Server ，接收 Client 的 TCP 连接请求； 网络 I/O 操作——读、写等由一个 NIO 线程池负责，包含一个任务队列和 N 各可用线程，由这些 NIO 线程负责消息的读取、解码、编码和发送； 一个 NIO 线程处理多条连接，而一个连接只对应一个 NIO 线程，防止发生并发操作问题。   \n相比第一种模式，多线程模型已经极大减轻了 Reactor 线程的工作量，但是如果有百万数量的并发连接，而 Reactor 需要对握手信息进行安全认证，这则非常损耗性能。因此这一部分工作可以再分。\n主从 Reactor 多线程模型\n再将新创建 Channel 注册到线程池这一工作分离出来，交给“从 Reactor”做，主 Reactor 仅负责完成登录、握手、安全认证，一旦链路成功，将链路注册到给后端 从 Reactor 线程，由它分发到后续线程池进行 I/O 操作。通常，从 Reactor 个数可与 CPU 个数相同（实际上，如果我们在 Netty 起服务端的时候调用默认的无参构造方法 NioEventLoopGroup() 构造 workerGroup，会起 NettyRuntime.availableProcessors() * 2 ，也就是两倍 CPU 核数的线程，作为从 Reactor 线程池）。\n \n除上述三种之外，Netty NIO 的默认模式其实是在主从 Reactor 基础上去掉线程池，Netty中的Boss类充当mainReactor，NioWorker类充当subReactor（默认 NioWorker的个数是 Runtime.getRuntime().availableProcessors() ）。在处理新来的请求时，NioWorker读完已收到的数据到 ChannelBuffer 中，之后触发 ChannelPipeline 中的 ChannelHandler 流。\nNetty 是事件驱动的，可以通过 ChannelHandler 链来（ ChannelPipline ）控制执行流向。因为ChannelHandler 链的执行过程在 subReactor 中是同步的，所以如果业务处理 handler 耗时长，将严重影响可支持的并发数，例如涉及数据库操作或其它阻塞交互模块时这些问题就会被放大，必须回到第三种模型上，通过线程池化解决。 Netty内置的ChannelHandler实现类–ExecutionHandler可以满足，因为仍然是 Handler ，仍然可以加入到 Pipeline 中，对使用者来说只是添加一行代码而已。\n对于 ExecutionHandler 需要的线程池模型，Netty提供了两种可选： 1） MemoryAwareThreadPoolExecutor 可控制Executor中待处理任务的上限（超过上限时，后续进来的任务将被阻塞），并可控制单个Channel待处理任务的上限； 2） OrderedMemoryAwareThreadPoolExecutor 是 MemoryAwareThreadPoolExecutor 的子类，它还可以保证同一Channel中处理的事件流的顺序性，这主要是控制事件在异步处理模式下可能出现的错误的事件顺序，但它并不保证同一Channel中的事件都在一个线程中执行（通常也没必要）。一般来说，OrderedMemoryAwareThreadPoolExecutor 是个很不错的选择，当然，如果有额外需要，也可以自行实现。\n Netty 中会起多少线程 ServerBootstrap 启动时，通常 bossGroup 只需设置为 1，ServerSocketChannel 在初始化阶段也只会注册到一个 EventLoop 上，用不到多个线程。\n而 IO 线程，为了充分利用 CPU，减少线程上下文切换开销，通常设置为 CPU 核数的两倍（我们知道英特尔的超线程技术，逻辑线程的个数也通常是 CPU 核数的两倍，猜测都是出于利用 CPU 性能的考虑）。\n Netty 事件驱动机制  事件队列（event queue）接收事件入口，存储待处理事件 分发器（event mediator）将不同事件分发到不同业务逻辑单元 事件通道（event channel）为分发器与处理器之间的联系渠道 事件处理器（event processor）实现业务逻辑，处理完成后会发出事件，触发下一步操作   \nChannelPipeline是ChannelHandler的集合，类似拦截器概念，Channel作为网络操作的抽象类，是ChannelEvent的生产者，ChannelEvent是数据或状态的载体。\n \n所有事件都来自 ChannelEvent 接口，涵盖监听接口、建立连接、读写数据等网络通讯各个阶段。事件处理者为 ChannelHandler ，连接处理、协议编解码、超时等机制都通过 Handler 完成。\n这种响应模式就类似于 AWT 中的 Reactor Pattern。\n Netty 的无锁化串行理念 其实 Redis 也是这样，我们知道并行处理可以提升并发性能，但是如果访问处理不当会带来严重的锁竞争，轻者带来部分效率损耗，重者整体性能下降。串行化设计，即消息的处理在同一线程内完成，期间不进行线程切换，避免竞争和同步锁。这对于 Redis、Netty 这样以简单高效为重的低层中间件非常有利。\n不同之处在于，Redis 单机下就是单线程的，而 Netty 本身默认就是多线程并行，只是每一 NioEventLoop 中通过 ChannelPipeline 处理消息，除非配置异步 Handler 否则不进行线程处理，从性能角度看是最优的。\n在实际使用中也要注意这一点，不要阻塞 EventLoop 。在耗时操作时，尽量使用 Future ，同时也尽量减少锁的使用。\n Netty 核心组件  \n这一部分主要介绍 Netty 中核心组件的功能，引用框中会补充一些实际使用中的调优技巧.\nEventLoopGroup 如图所示，两个 EventLoopGroup 实际上也就是两个线程池，Boss 仅负责接收连接，只需要一个线程，内部封装有一个Selector，Worker 负责具体 IO 处理，每个都有绑定的Selector。\nEventloopGroup 将为每个新创建的 Channel 分配一个 EventLoop 。每个 Channel 的整个生命周期内，所有操作都由相同的 Thread 执行。\n EventLoop \nChannel Channel 为 Netty 网络操作（读写等操作）抽象类，EventLoop 负责处理注册到其上的 Channel 的 I/O 操作，两个组件配合进行 I/O 操作。Channel 对 Java 原生的 ServerSocketChannel 和 SocketChannel 进行封装，得到了 NioServerSocketChannel 和 NioSocketChannel ，UDP 对应的是 NioDatagramChannel 。\nServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class)...... 如上图所示，channel 通过传一个 .class 对象给 Bootstrap ，很明显是工厂模式通过反射方式来创建实例，这一实例的实际实例化时机，也就是源码中 .newChannel() 调用，是在 Bootstrap 进行 bind(PORT) （对服务端而言）和 connect(HOST, PORT) （对客户端而言）时。\n 对于两个指定端点可以使用唯一 Channel ，在第一次创建后保存 Channel ，对同一 IP 地址下一次通信中复用而不需要重新建立。但这样做也需要保存不同 IP 的 Channel ，在初始化时可能存在一些并发问题，很多实际项目都有相应解决方法，https://mp.weixin.qq.com/s/JRsbK1Un2av9GKmJ8DK7IQ 介绍了一些解决方案。\n Handler handler 其实就是一种 AOP，负责接收到请求后的处理过程。通过 childHandler() 和 ChannelInitializer 可以指定多个 handler 组成 Pipeline ，类似拦截器概念，涉及 handler 的执行顺序。\nBootstrap 通过传入一个 ChannelInitializer 的实现类，在这个实现类中向 ChannelPipeline 中添加一系列 Handler ，这些 Handler 分别负责信息处理的某个环节。\n 以在 Netty 中进行 SSL 通信为例，首先加入的是 SslContext 实体提供的 Handler，用于进行加解密；然后需要加入一个 DelimiterBasedFrameDecoder ，这个编解码器通过分隔符拆分解决包尺寸过大造成的 TCP 粘包等问题；之后就是数据的编解码器，如 Netty 为 String 通信提供的 StringDecoder 和 StringEncoder ；最后便是我们业务自己的 Handler ，用于按业务逻辑处理消息。\n Future Future\u0026lt;V\u0026gt; 接口继承自 java.util.concurrent.Future\u0026lt;V\u0026gt; ，同样用于异步调用。增加了 sync() 和 await() 用于阻塞等待，还添加了 Listeners 用于任务结束后回调。\nPromise 接口继承自 Future ，实例内部是一个任务，其中的 setSuccess(V result) 和 setFailure(Throwable t) 会在执行任务的线程完成后调用。\n这一回调可能是 Listeners 回调函数进行（不一定是由线程自己执行，也可能是新线程或其他线程），也可能是从 await() 中返回。\n \n Netty 中的零拷贝 在 Bootstrap 配置参数的时候，使用 .option(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) 来指定一个池化的 Allocator，并且使用 ByteBuf buf = allocator.directBuffer() 来获取 Bytebuf。\nPooledByteBufAllocator 会帮你复用（无需 release，除非你后面还需要用到同一个 bytebuf）而不是每次都重新分配 ByteBuf。在IO操作中，Netty 接收和发送 ByteBuffer 采用直接内存进行Socket读写而不是JVM的堆空间，避免了在发送数据时，从JVM到直接内存的拷贝过程（文件传输采用transferTo，直接将缓冲区数据发到Channel，不存在循环write方式涉及的内存拷贝），这也就是 Zero Copy 的含义。Java NIO 中也有 Zero Copy Buffer 技术。\n同时，Netty 的组合Buffer对象可以聚合多个 ByteBuffer 对象，方便操作，避免通过内存拷贝将小Buffer合并成大的。\n","date":"2021-07-02T00:00:00Z","image":"https://winterorch.github.io/images/feature/ArseniXC/Ikarus-256.jpg","permalink":"https://winterorch.github.io/p/netty_basic/","title":"Netty - 基础知识"},{"content":"LCP 07. 传递信息 题目：  小朋友 A 在和 ta 的小伙伴们玩传信息游戏，游戏规则如下：\n 有 n 名玩家，所有玩家编号分别为 0 ～ n-1，其中小朋友 A 的编号为 0 每个玩家都有固定的若干个可传信息的其他玩家（也可能没有）。传信息的关系是单向的（比如 A 可以向 B 传信息，但 B 不能向 A 传信息）。 每轮信息必须需要传递给另一个人，且信息可重复经过同一个人  给定总玩家数 n，以及按 [玩家编号,对应可传递玩家编号] 关系组成的二维数组 relation。返回信息从小 A (编号 0 ) 经过 k 轮传递到编号为 n-1 的小伙伴处的方案数；若不能到达，返回 0。\n 示例1：\n 示例 1：\n输入：n = 5, relation = [[0,2],[2,1],[3,4],[2,3],[1,4],[2,0],[0,4]], k = 3\n输出：3\n解释：信息从小 A 编号 0 处开始，经 3 轮传递，到达编号 4。共有 3 种方案，分别是 0-\u0026gt;2-\u0026gt;0-\u0026gt;4， 0-\u0026gt;2-\u0026gt;1-\u0026gt;4， 0-\u0026gt;2-\u0026gt;3-\u0026gt;4。\n 示例2：\n 输入：n = 3, relation = [[0,2],[2,1]], k = 2\n输出：0\n解释：信息不能从小 A 处经过 2 轮传递到编号 2\n leetcode链接：LCP 07. 传递信息\n题解： 思路1：dfs 题目中的relation很容易抽象成有向图，而对于可行路径的查找也很自然地联想到使用深度优先搜索。主要步骤归纳如下：\n 有向图初始化  List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; edges; edges = new ArrayList\u0026lt;\u0026gt;(); for(int i = 0; i \u0026lt; n; i++){ edges.add(new ArrayList\u0026lt;\u0026gt;()); } for(int[] edge : relation){ edges.get(edge[0]).add(edge[1]); }  深度优先搜索  private void dfs(int cur, int steps){ if(steps == k){ if(cur == n - 1){ res++; //System.out.println(res);  } return; } List\u0026lt;Integer\u0026gt; l = edges.get(cur); for(int next : l){ dfs(next, steps + 1); } } public int numWays(int n, int[][] relation, int k) { ... dfs(0,0); } 合并后即可写出最终代码\nclass Solution { int res, n, k; List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; edges; public int numWays(int n, int[][] relation, int k) { res = 0; this.n = n; this.k = k; edges = new ArrayList\u0026lt;\u0026gt;(); for(int i = 0; i \u0026lt; n; i++){ edges.add(new ArrayList\u0026lt;\u0026gt;()); } for(int[] edge : relation){ edges.get(edge[0]).add(edge[1]); } dfs(0,0); return res; } private void dfs(int cur, int steps){ if(steps == k){ if(cur == n - 1){ res++; //System.out.println(res);  } return; } List\u0026lt;Integer\u0026gt; l = edges.get(cur); for(int next : l){ dfs(next, steps + 1); } } }  时间复杂度：O(n^k)。 空间复杂度：O(n+m+k)。  相应的bfs方法也可以解决本题，在此不再赘述\n但两者的时间复杂度显而易见地大，翻评论区却发现了一种更巧妙的方法——动态规划。\n思路2：动态规划 class Solution { public int numWays(int n, int[][] relation, int k) { int[][] dp = new int[k + 1][n]; dp[0][0] = 1; for(int i = 1; i \u0026lt; k; i++){ for(int[] edge : relation){ dp[i][edge[1]] += dp[i - 1][edge[0]]; } } return dp[k][n - 1]; } } 动态规划从代码入手更易于理解。dp数组用于存储 第i轮 中 每个小朋友 可达的方案数，其值为可以向 他 传递信息的小朋友 第i-1轮 可达方案数 的总和。第一层for循环用于遍历轮数，第二层for循环用于遍历边（信息传递的方向）——edge[1]即为该小朋友，edge[0]为可以向他传递信息的小朋友，思路理清后，代码也就呼之欲出了。\n","date":"2021-07-01T00:00:00Z","image":"https://winterorch.github.io/images/category/leetcode/AfternoonTea.jpg","permalink":"https://winterorch.github.io/p/leetcode-lcp-07-%E4%BC%A0%E9%80%92%E4%BF%A1%E6%81%AF/","title":"LeetCode LCP 07 - 传递信息"},{"content":"以下示例代码部分源自 [小专栏] 剖析面试最常见问题之Redis .\ntype name\t#查看当前 key 的类型  String string 数据结构是简单的 key-value 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 简单动态字符串（simple dynamic string，SDS）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外,Redis 的 SDS API 是安全的，不会造成缓冲区溢出。\n 常用命令: set,get,strlen,exists,dect,incr,setex 等等 应用场景 ：大多数需要缓存的场景、需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等  127.0.0.1:6379\u0026gt; set key value #设置 key-value 类型的值 OK 127.0.0.1:6379\u0026gt; get key # 根据 key 获得对应的 value \u0026#34;value\u0026#34; 127.0.0.1:6379\u0026gt; exists key # 判断某个 key 是否存在 (integer) 1 127.0.0.1:6379\u0026gt; strlen key # 返回 key 所储存的字符串值的长度。 (integer) 5 127.0.0.1:6379\u0026gt; del key # 删除某个 key 对应的值 (integer) 1 127.0.0.1:6379\u0026gt; get key (nil) 作计数器用 （字符串的内容为整数的时候可以使用）\n127.0.0.1:6379\u0026gt; set number 1 OK 127.0.0.1:6379\u0026gt; incr number # 将 key 中储存的数字值增一 (integer) 2 127.0.0.1:6379\u0026gt; get number \u0026#34;2\u0026#34; 127.0.0.1:6379\u0026gt; decr number # 将 key 中储存的数字值减一 (integer) 1 127.0.0.1:6379\u0026gt; get number \u0026#34;1\u0026#34; 设置过期（通用） 127.0.0.1:6379\u0026gt; expire key 60 # 数据在 60s 后过期 (integer) 1 127.0.0.1:6379\u0026gt; setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire) OK 127.0.0.1:6379\u0026gt; ttl key # 查看数据还有多久过期 (integer) 56  List 链表 当列表中存储数据量较大，列表通过双向循环链表实现。可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。\n 常用命令: rpush,lpop,lpush,rpop,lrange、llen 等。 应用场景: 发布与订阅或者说消息队列、慢查询。  实现队列\n127.0.0.1:6379\u0026gt; rpush myList value1 # 向 list 的头部（右边）添加元素 (integer) 1 127.0.0.1:6379\u0026gt; rpush myList value2 value3 # 向list的头部（最右边）添加多个元素 (integer) 3 127.0.0.1:6379\u0026gt; lpop myList # 将 list的尾部(最左边)元素取出 \u0026#34;value1\u0026#34; 127.0.0.1:6379\u0026gt; lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end 1) \u0026#34;value2\u0026#34; 2) \u0026#34;value3\u0026#34; 127.0.0.1:6379\u0026gt; lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一 1) \u0026#34;value2\u0026#34; 2) \u0026#34;value3\u0026#34; 实现栈\n127.0.0.1:6379\u0026gt; rpush myList2 value1 value2 value3 (integer) 3 127.0.0.1:6379\u0026gt; rpop myList2 # 将 list的头部(最右边)元素取出 \u0026#34;value3\u0026#34; 通过 lrange 查看对应下标范围的列表元素：\n127.0.0.1:6379\u0026gt; rpush myList value1 value2 value3 (integer) 3 127.0.0.1:6379\u0026gt; lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 127.0.0.1:6379\u0026gt; lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 3) \u0026#34;value3\u0026#34; 通过 lrange 命令，你可以基于 list 实现分页查询，性能非常高！\n通过 llen 查看链表长度：\n127.0.0.1:6379\u0026gt; llen myList (integer) 3  ZipList 压缩列表 压缩列表本质是字节数组，可以包含任意多个元素，每个元素可以是字节数组或整数。\n编码\n \n zlbytes：字节长度，占4字节，因此ZipList最长 $2^{32} - 1$ 字节 zltail：为元素相对起始地址的偏移量，占4字节 zllen：列表元素数目，占2字节，当数目超过 $2^{16}-1$ 时字段无效，只能通过遍历获取数目 entryX：若干元素 zlend：结尾字节，0xFF   Hash 无序散列表 存储键值对。当数据量较小，使用ZipList存储，否则使用散列表(使用MurmurHash2作为哈希函数)。\n当负载因子大于1，触发扩容，将散列表扩大为2倍。当负载因子小于0.1，触发缩容，缩小为实际负载的2倍大小。\n 常用命令： hset,hmset,hexists,hget,hgetall,hkeys,hvals 等。 应用场景: 系统中对象数据的存储。  127.0.0.1:6379\u0026gt; hset userInfoKey name \u0026#34;guide\u0026#34; description \u0026#34;dev\u0026#34; age \u0026#34;24\u0026#34; OK 127.0.0.1:6379\u0026gt; hexists userInfoKey name # 查看 key 对应的 value中指定的字段是否存在。 (integer) 1 127.0.0.1:6379\u0026gt; hget userInfoKey name # 获取存储在哈希表中指定字段的值。 \u0026#34;guide\u0026#34; 127.0.0.1:6379\u0026gt; hget userInfoKey age \u0026#34;24\u0026#34; 127.0.0.1:6379\u0026gt; hgetall userInfoKey # 获取在哈希表中指定 key 的所有字段和值 1) \u0026#34;name\u0026#34; 2) \u0026#34;guide\u0026#34; 3) \u0026#34;description\u0026#34; 4) \u0026#34;dev\u0026#34; 5) \u0026#34;age\u0026#34; 6) \u0026#34;24\u0026#34; 127.0.0.1:6379\u0026gt; hkeys userInfoKey # 获取 key 列表 1) \u0026#34;name\u0026#34; 2) \u0026#34;description\u0026#34; 3) \u0026#34;age\u0026#34; 127.0.0.1:6379\u0026gt; hvals userInfoKey # 获取 value 列表 1) \u0026#34;guide\u0026#34; 2) \u0026#34;dev\u0026#34; 3) \u0026#34;24\u0026#34; 127.0.0.1:6379\u0026gt; hset userInfoKey name \u0026#34;GuideGeGe\u0026#34; # 修改某个字段对应的值 127.0.0.1:6379\u0026gt; hget userInfoKey name \u0026#34;GuideGeGe\u0026#34;  Set 无序集合 集合中的元素没有先后顺序，不允许重复数据。\n 常用命令： sadd,spop,smembers,sismember,scard,sinterstore,sunion 等。 应用场景: 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景  127.0.0.1:6379\u0026gt; sadd mySet value1 value2 # 添加元素进去 (integer) 2 127.0.0.1:6379\u0026gt; sadd mySet value1 # 不允许有重复元素 (integer) 0 127.0.0.1:6379\u0026gt; smembers mySet # 查看 set 中所有的元素 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 127.0.0.1:6379\u0026gt; scard mySet # 查看 set 的长度 (integer) 2 127.0.0.1:6379\u0026gt; sismember mySet value1 # 检查某个元素是否存在set 中，只能接收单个元素 (integer) 1 127.0.0.1:6379\u0026gt; sadd mySet2 value2 value3 (integer) 2 127.0.0.1:6379\u0026gt; sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中 (integer) 1 127.0.0.1:6379\u0026gt; smembers mySet3 1) \u0026#34;value2\u0026#34; 127.0.0.1:6379\u0026gt; sunion mySet mySet2 # 获取 mySet 和 mySet2 的并集并打印 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 3) \u0026#34;value3\u0026#34; 通过以下的案例可知Set是无序的\n127.0.0.1:6379\u0026gt; sadd myset 1 2 3 4 5 6 (integer) 6 127.0.0.1:6379\u0026gt; spop myset 3 1) \u0026#34;4\u0026#34; 2) \u0026#34;5\u0026#34; 3) \u0026#34;1\u0026#34;  SortedSet 有序集合 存储键值对，有序集合的值被称为分值(score)，必须为浮点数。SortedSet 是唯一既可以跟据成员访问，又可以跟据分值以及分值排列顺序访问元素的结构。有点像是 Java 中 HashMap 和 TreeSet 的结合体。\n 常用命令： zadd,zcard,zscore,zrange,zrevrange,zrem 等。 应用场景： 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。  127.0.0.1:6379\u0026gt; zadd myZset 3.0 value1 # 添加元素到 sorted set 中 3.0 为权重 (integer) 1 127.0.0.1:6379\u0026gt; zadd myZset 2.0 value2 1.0 value3 # 一次添加多个元素 (integer) 2 127.0.0.1:6379\u0026gt; zcard myZset # 查看 sorted set 中的元素数量 (integer) 3 127.0.0.1:6379\u0026gt; zscore myZset value1 # 查看某个 value 的权重 \u0026#34;3\u0026#34; 127.0.0.1:6379\u0026gt; zrange myZset 0 -1 # 顺序输出某个范围区间的元素，0 -1 表示输出所有元素 1) \u0026#34;value3\u0026#34; 2) \u0026#34;value2\u0026#34; 3) \u0026#34;value1\u0026#34; 127.0.0.1:6379\u0026gt; zrange myZset 0 1 # 顺序输出某个范围区间的元素，0 为 start 1 为 stop 1) \u0026#34;value3\u0026#34; 2) \u0026#34;value2\u0026#34; 127.0.0.1:6379\u0026gt; zrevrange myZset 0 1 # 逆序输出某个范围区间的元素，0 为 start 1 为 stop 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34;  bitmap 适用只需要一个 bit 位来表示某个元素对应值或者状态的情况，如是否签到、是否登录等 Java 中使用 bool 的场景，加之 bitmap 可以统计设为 1 的位的数量\n常用命令： setbit 、getbit 、bitcount、bitop\n# SETBIT 会返回之前位的值（默认是 0）这里会生成 7 个位 127.0.0.1:6379\u0026gt; setbit mykey 7 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit mykey 7 0 (integer) 1 127.0.0.1:6379\u0026gt; getbit mykey 7 (integer) 0 127.0.0.1:6379\u0026gt; setbit mykey 6 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit mykey 8 1 (integer) 0 # 通过 bitcount 统计被被设置为 1 的位的数量。 127.0.0.1:6379\u0026gt; bitcount mykey (integer) 2 用户 ID 经常可以被用来作 bitmap 上的 offset，从而可以轻松统计“\u0026hellip;的用户个数”。\n相应的，位操作 BITOP operation destkey key [key ...] ，支持 AND OR NOT XOR 四种操作中任意一种参数。\n初始化数据：\n127.0.0.1:6379\u0026gt; setbit 20210308 1 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit 20210308 2 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit 20210309 1 1 (integer) 0 统计 20210308~20210309 总活跃用户数: 1\n127.0.0.1:6379\u0026gt; bitop and desk1 20210308 20210309 (integer) 1 127.0.0.1:6379\u0026gt; bitcount desk1 (integer) 1 统计 20210308~20210309 在线活跃用户数: 2\n127.0.0.1:6379\u0026gt; bitop or desk2 20210308 20210309 (integer) 1 127.0.0.1:6379\u0026gt; bitcount desk2 (integer) 2 实际上，如果需要统计日活、月活用户这种，Redis 有一个非常对口的数据结构——HyperLoglog，原理其实类似于布隆滤波器，也是一个哈希过滤器，有一定的误警率，因此一般用于统计日活用户数量之类对精确度没有很高要求的数据。\n 乐观锁  对应数据库中的 version 设计\n watch money\t#使用 watch 当作乐观锁操作 被监视数据，如果在事务对其执行操作前被其它线程修改，则在调用 exec 时会执行失败\nunwatch\t# 失败，乐观锁已经失效 watch money\t# 添加新的乐观锁  链接 你可以在《Redis设计与实现》的下述页码找到对应数据结构的常用命令：\n  string\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;P68 list\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;P71 hash\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;P74 set\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;P77 sorted set\u0026mdash;\u0026ndash;P81   ","date":"2021-06-30T00:00:00Z","image":"https://winterorch.github.io/images/feature/scenes/Street2.jpg","permalink":"https://winterorch.github.io/p/redis-%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"Redis - 常用数据类型"},{"content":"常见的内存数据库包括 Memcached 和 Redis。后者相较之下在 k/v 类型数据基础上提供了 list, set, zset, hash 等数据结构存储，并且可扩展性强，能够通过插件增加更多；同时具有容灾机制，支持数据持久化，也有原生集群模式，支持发布订阅模型、Lua 脚本、事务；并且支持更多编程语言，单线程模型更加高效。总而言之功能很强，应用很广。\n简要介绍 Redis 是用 C 开发的内存数据库，非关系型数据库，读写速度快，广泛应用于缓存，也可以做分布式锁、消息队列。\n Redis6.0 之前都是单线程处理，仅在4.0增加了对大键值对删除操作的“异步处理” 服务器内存使用完之后，将不用的数据存到磁盘上 过期数据的删除策略包括惰性删除与定期删除  缓存的作用\n访问数据库从硬盘中读取，过程较慢。如果用户访问数据为高频数据且不会经常改变，则可以存在缓存中，速度快。\n 删除策略和内存淘汰机制   惰性删除\n只在取出 key 的时候才对数据进行过期检查。CPU负担小，但会残留很多过期 key\n  定期删除\n周期性取一批 key 执行删除过期 key 操作，通过限制删除操作执行时长和频率来减少删除操作对 CPU 影响\n  删除策略并不能清理所有过期 key ，过期 key 还需要内存淘汰机制解决。\n除了缓解内存消耗，设置过期时间也可以用于满足业务需要，比如验证码、登录Token的有效时间。\n内存淘汰机制跟据从中挑选淘汰数据的数据集不同，分为三大类：\n  从已设置过期时间的数据集中 volatile\n  volatile-lru (least recently used)\n移除最近最少使用的 key\n  volatile-ttl\n移除将要过期的数据\n  volatile-random\n移除随机选择的数据\n  volatile-lfu\n(4.0新增) 移除最不经常使用的数据\n    从**数据集（所有）**中 allkeys\n  allkeys-lru (least recently used)\n移除最近最少使用的 key\n  allkeys-random\n移除随机选择的数据\n  allkeys-lfu (least frequently used)\n(4.0新增) 移除最不经常使用的 key\n    不进行数据淘汰 no\n  no-eviction\n内存不足以容纳新写入数据就直接报错\n     redisDB表结构 \n如图所示，Redis通过一个过期字典（类似HashTable）来保存数据过期时间，对应内存淘汰机制中 server.db[i].expires 。\n 持久化机制 为了保证Redis挂掉后再重启数据可以进行恢复，需要将内存数据写入硬盘。两种持久化机制分别是快照 (snapshotting, RDB) 和只追加文件 (append-only file, AOF) 。\nRDB 记录的是内存快照，AOF 记录的是执行过的所有命令。\n快照持久化是 Redis 默认采用的持久化方式，可以将快照复制到其他服务器从而创建具相同数据的服务器副本，在 Redis.conf 配置文件中默认有此下配置：\nsave 900 1 #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 save 300 10 #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 save 60 10000 #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 # 大部分情况下，15分钟够用，只保留这一条即可 RDB提供了三种机制\n save 命令将阻塞服务器主线程直到 RDB 完成 （不推荐） bgsave 命令 fork() 一个子线程在后台异步进行快照操作，同样会阻塞，但只发生在 fork() 阶段，时间较短。RDB 快照持久化期间父进程修改的数据不会被保存。 自动，通过配置完成  AOF 持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启：\nappendonly yes 开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 appendonly.aof。\n在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：\nappendfsync always #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度 appendfsync everysec #每秒钟同步一次，显示地将多个写命令同步到硬盘 appendfsync no #让操作系统决定何时进行同步 appendfsync everysec 比较好\n优点：写入性能非常高；即时日志文件过大出现后台重写也不会影响客户端读写（fork()新线程进行重写）；记录方式可读，适合用作紧急恢复\n缺点：日志文件更大，且会带来持续IO，对QPS影响更大\n总结\nRedis 重启时优先载入 AOF，因为 AOF 数据集一般更加完整，但 RDB 更适合用于备份数据库，快速重启，且没有 AOF 潜在 BUG\n Redis事务 关系型数据库的事务具备四大特性（ACID），合起来就是：\n  原子性\n确保都成功或都失败\n Redis 不具备原子性，因为不支持回滚，当然这也带来部分性能提升和开发便捷性\n   隔离性\n并发访问时，单用户事务不被其他事务所干扰，防止数据损坏\n Redis 不具备隔离级别概念，命令在事务中没有被直接执行。只有发起执行命令时才会执行。\n   持久性\n事务一旦提交，对数据库中数据的改变是持久的，被持久化写到存储器中，不会被系统其它问题改变\n Redis 同样不具备，但是当 AOF 持久化模式下，并且 appendfsync 选项值为 always 时，事务具有耐久性\n   一致性\n执行事务前后数据保持一致，多个事务对同一数据读取的结果相同\n  Redis 事务实际提供了将多个命令请求打包功能，再按顺序执行打包的所有命令，且不会被中途打断。具备 一次性、顺序性、排他性，分以下两种情况：\n 编译型异常中\n当命令出现错误，后续命令依旧可以添加到命令队列中，但所有命令都不会被执行\n  运行时异常中\n当命令出现错误，其它命令可以正常执行，只有错误命令抛出异常\n  缓存穿透攻击 黑客制造大量不存在 key 的请求，导致请求直接落到数据库进行查询，没有经过缓存层。\n要解决这一问题，最基本是要做好参数校验，不合法的参数直接抛异常给客户端。\n  缓存无效的 key\n即时返回的空对象也将其缓存起来，同时设置过期时间\n但在 key 变化频繁的情况下，尤其在恶意攻击中可能产生大量无效的 key\n  布隆过滤器\n先用布隆过滤器判断请求值是否存在，实际上就是哈希校验\n  缓存击穿 key 失效的瞬间，大量并发集中访问，直接落在数据库上。\n  设置热点数据不过期\n可以解决问题，但并不好\n  加互斥锁\n分布式锁来保证对每个 key 同时只有一个线程查询后端服务，其它线程没有获得分布式锁的权限，只需要等待，从而将高并发压力转移到分布式锁\n  缓存雪崩 服务器宕机或断网形成缓存雪崩，对数据库造成压力不可预知，很可能瞬间将数据库压垮。\n实际上就是压力累积超过临界导致的，\n 增设缓存集群，异地多活 限流降级，缓存失效后，通过加锁或队列来控制都数据库写缓存的线程数量 数据预热，预访问数据，使得尽可能多的数据被加载到缓存中，但要注意设置不同的过期时间，使缓存失效的时间点尽量均匀   单线程模型  单线程开发、维护容易 Redis性能瓶颈在内存和网络，CPU瓶颈不明显 多线程带来了死锁、线程上下文切换等问题，甚至可能影响性能  6.0 后引入多线程也是为了提高网络 IO 读写性能，仅用在网络数据读写这类耗时操作上，无需担心线程安全问题。\nRedis 事件处理模型对应其中单线程的文件事件处理器(File Event Handler)，因此是单线程模型。通过 IO 多路复用来监听大量连接，跟据套接字执行任务关联不同的事件处理器，不需要创建多余线程来监听连接。\n 虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。\n  缓存读写策略 缓存读写策略实际上也就是缓存和数据库间的位置关系，主要有以下三种\n旁路缓存模式 适用读请求较多的场景\n写：\n 先更新 DB 中数据 直接删除 cache   之所以先更新 DB ，是因为 cache 的删除操作相对快很多，数据不一致的可能性大大降低。相反，如果先删除 cache，此时如果有并行请求直接从 DB 中读取数据，这一操作很可能在 DB 中数据被更新前完成。\n 读：\n 从 cache 中读取数据，读到直接返回 读不到就从 DB 中读取并返回 数据放到 cache 中  缺点一、 首次请求数据一定不在 cache ，但是这一问题可以通过热点数据的提前缓存解决。\n缺点二、 写操作如果频繁，则 cache 数据被频繁删除，缓存命中率降低，缓存很大程度上被架空。在强一致场景下需要锁/分布锁保证更新 cache 时不存在线程问题；弱一致场景下可以 cache 和 DB 一起更新，cache 设置较短的过期事件以提高缓存命中率。\n读写穿透模式 cache 负责将数据读取和写入 DB，作为服务端和 DB 间的中间件。然而相当难实现，因为 Redis 不提供 DB 读写功能。\n写：\n 查 cache，不存在则直接更新 DB cache 存在，则先更新 cache，cache 服务自己更新 DB（cache 和 DB 同步更新）  读：\n 从 cache 读数据，读到直接返回 没读到就从 DB 加载到 cache，然后返回响应  由于 Redis 不提供 DB 读写，这一模式实际上只是在旁路模式上进行了封装。同样具有首次请求数据不在 cache 问题。\n异步缓存写入 和 读写穿透模式 相似，但只更新缓存，不直接更新 DB，用异步批量的方式来更新 DB。消息队列中消息异步写入磁盘、MySQL 的 InnoDB Buffer Pool 机制都用到这种策略。\nDB 的写性能非常高，适合数据频繁变化，数据一致性要求又不高的场景，如浏览量、点赞量。\n缺点很明显，数据一致性很难维护，cache 可能在数据异步更新前宕机。\n如何保证缓存数据库数据一致 旁路缓存模式下，可以增加 cache 更新重试机制——如果 cache 服务不可用而暂时无法删除缓存，就隔一段时间再试，多次失败就将更新失败 key 存入队列，等缓存恢复后进行删除。\n Redis Cluster Redis 集群主要解决的是性能问题，在缓存数据量过大的情况下将数据分散到各台 Redis 主机上，可以看作是一种负载均衡手段，方便业务进行横向拓展。\nRedis Cluster 有多个节点，是去中心化的分布式结构，每个节点都负责数据读写操作，各节点间会进行通信。通过分片 (sharding) 来进行数据管理，提供复制和故障转移功能。\nHash Slot\n共 16384 个槽被平均分配给节点进行管理，每个节点对自己负责的槽进行读写操作。各个节点间彼此通信，知晓其它节点负责管理的槽范围。\n作为一个分布式系统，各结点需要互相通信来维护一份所有其它示例的状态信息，基于 Gossip 协议实现数据的最终一致性。\n访问流程\n客户端访问任意节点时，对数据 key 按照 CRC16 进行 Hash 计算，然后对运算结果模 16384 ，判断槽是否在当前节点管理范围内：如果在，则执行命令，返回结果；如果不在，返回moved重定向异常，之后由客户端跟据重定向异常中目标节点信息去发送命令。\n迁移\n如果节点在迁移过程中收到客户端命令，会返回 ASK 重定向异常。\n Redis Replication Redis 主从主要解决的是可用性问题，读吞吐量过大情况下，可以通过一主多从来提高可用性和读吞吐量，从机多少取决于读吞吐量大小。\n从机只能读，不能写。主机断开连接，从机仍然连接到主机，只是没有任何写操作传入，如果主机上线，从机依然可以直接获取。通过指令 SLAVEOF no one 来脱离从机身份。\n复制\n  SYNC\n每次执行 SYNC ，主服务器需要 BGSAVE 来生成 RDB，并发送给从服务器；从服务器载入 RDB 期间阻塞进程，无法处理请求。\n  PSYNC\n部分重同步，主服务器收到 PSYNC 后返回 +CONTINUE ，示意准备执行部分重同步，然后继续发送新指令以完成同步。\n 主从服务器分别维护“复制偏移量”，记录收到的数据长度（字节数）。通过对比主从复制偏移量可以直到是否处于一致状态。\n主服务器维护一个定长 FIFO 队列，作为复制积压缓冲区。主服务器将写命令发给从机，同时入队到复制积压缓冲区。\n   如果从机先前没有复制过任何主机，或执行过 SLAVEOF no one ，则为了开始新复制而发送 PSYNC ? -1 ，请求主机进行完整重同步。主机返回 +FULLRESYNC \u0026lt;runid\u0026gt; \u0026lt;offsetid\u0026gt; 示意准备完整重同步。\n  反之，发送 PSYNC \u0026lt;runid\u0026gt; \u0026lt;offset\u0026gt; ，供主机判断执行哪种同步\n  哨兵\n主从的问题在于一旦主机宕机，从机晋升，将需要人工重新配置其余所有从机，复制新的主机，并改变应用方主机地址，为此需要一个（实际上一般是多个）哨兵来干这件事。\n单个哨兵如果检测到主服务器宕机，不会马上进行 failover ，而是认为主服务器“主观下线”。当检测到主服务器不可用的哨兵达到一定数量，则哨兵间进行投票，决定接替的从机，切换成功后，通过发布订阅模式，让各个哨兵把监控的从服务器实现切换主机，称为“客观下线”。\n客观下线后，即使原主机重新上线，也只能作为新主机的从机。\n缺点：无法在线扩容，集群容量到达上限，不好在线扩容；实现哨兵模式配置有很多选择，较为复杂\n","date":"2021-06-29T00:00:00Z","image":"https://winterorch.github.io/images/feature/scenes/Windmill.jpg","permalink":"https://winterorch.github.io/p/redis-common_questions/","title":"Redis - 面试常见问题"},{"content":"[LeetCode] 815. Bus Routes We have a list of bus routes. Each routes[i] is a bus route that the i-th bus repeats forever. For example if routes[0] = [1, 5, 7], this means that the first bus (0-th indexed) travels in the sequence 1-\u0026gt;5-\u0026gt;7-\u0026gt;1-\u0026gt;5-\u0026gt;7-\u0026gt;1-\u0026gt;\u0026hellip; forever.\nWe start at bus stop S (initially not on a bus), and we want to go to bus stop T. Travelling by buses only, what is the least number of buses we must take to reach our destination? Return -1 if it is not possible.\nExample 1:\nInput: routes = [[1,2,7],[3,6,7]], source = 1, target = 6\rOutput: 2\rExplanation: The best strategy is take the first bus to the bus stop 7, then take the second bus to the bus stop 6.\rExample 2:\nInput: routes = [[7,12],[4,5,15],[6],[15,19],[9,12,13]], source = 15, target = 12\rOutput: -1\rConstraints:\n 1 \u0026lt;= routes.length \u0026lt;= 500. 1 \u0026lt;= routes[i].length \u0026lt;= 10^5 All the values of routes[i] are unique. sum(routes[i].length) \u0026lt;= 10^5 0 \u0026lt;= routes[i][j] \u0026lt; 10^6 0 \u0026lt;= source, target \u0026lt; 10^6   顺便贴一下两年前这道题的提示：\n Note:  1 \u0026lt;= routes.length \u0026lt;= 500. 1 \u0026lt;= routes[i].length \u0026lt;= 500. 0 \u0026lt;= routes[i][j] \u0026lt; 10 ^ 6.      题解 图压缩 + 最短路径算法  类似题：LeetCode 127 Word Ladder II\n 看一下两年前和现在对案例限制的不同就可以看出来——力抠把这道题图的成分提升了，并且告诉你了一条公交路线里不会有重复站点，最终要的是，明确了公交站台的数量远远高于公交线路的数量（最离谱的是最后一个案例，尼玛十几条公交线路总共经过了五六万个站，要是在城市天际线里搞这种线路，小人上班还没坐到单位就老死了好吗），换句话说，如果不进行压缩，直接以公交站为结点进行 BFS ，你的图会相当大，如果压缩了，那效率上一定是有收益的。因此有必要将站台图压缩成公交线路的邻接图。\nint n = routes.length; boolean[][] edge = new boolean[n][n]; Map\u0026lt;Integer, List\u0026lt;Integer\u0026gt;\u0026gt; rec = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) { for (int site : routes[i]) { List\u0026lt;Integer\u0026gt; list = rec.getOrDefault(site, new ArrayList\u0026lt;\u0026gt;()); for (int j : list) { edge[i][j] = edge[j][i] = true; } list.add(i); rec.put(site, list); } } 这样下来，在搜索过程中队列中保存的就都是公交路线号而不是站台号了，那么起点和终点也就不是站台，而是经过相应站台所有公交线路的集合了，这其实就和 127 题那个单词编辑步长特别相似了，用 BFS 应当是可以的，而且其实这里的公交都是环线，完全可以用双向 BFS 进行优化（当发现一道 BFS 题的起点和终点可以互换，换句话说图是无向的，基本都可以用上双向 BFS）。\n然而官答这里直接当成图来做了，直接算了个到所有（除经过起始站的之外）其它公交线路的最少转车站数，用的还是 SPFA，考虑到最后判题案例中其实充斥的都是站点繁多但实际上连通却不多的稀疏图，这样的选择反而相当高效。所以说合适的输入案例是最有效的优化。\n虽然 OJ 里无环的情况下还是迪杰斯特拉稳妥一些，但 Leetcode 上基本 SPFA 完全没有问题，写起来还方便，直接用队列不断更新相邻结点的最小距离，一旦距离进行更新就将该结点也丢进队列里，继续更新，直到队列为空。这一算法在稀疏图中效率非常高。\n得到的结果里去找能到终点的最小距离就行了，整个算法理解起来非常简单。\nint[] dis = new int[n]; Arrays.fill(dis, -1); Queue\u0026lt;Integer\u0026gt; que = new ArrayDeque\u0026lt;\u0026gt;(); for (int site : rec.getOrDefault(source, new ArrayList\u0026lt;\u0026gt;())) { dis[site] = 1; que.offer(site); } while (!que.isEmpty()) { int x = que.poll(); for (int y = 0; y \u0026lt; n; y++) { if (edge[x][y] \u0026amp;\u0026amp; dis[y] == -1) { dis[y] = dis[x] + 1; que.offer(y); } } } int ret = Integer.MAX_VALUE; for (int site : rec.getOrDefault(target, new ArrayList\u0026lt;\u0026gt;())) { if (dis[site] != -1) { ret = Math.min(ret, dis[site]); } } return ret == Integer.MAX_VALUE ? -1 : ret; 代码总和\npublic int numBusesToDestination(int[][] routes, int source, int target) { if (source == target) { return 0; } int n = routes.length; boolean[][] edge = new boolean[n][n]; Map\u0026lt;Integer, List\u0026lt;Integer\u0026gt;\u0026gt; rec = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) { for (int site : routes[i]) { List\u0026lt;Integer\u0026gt; list = rec.getOrDefault(site, new ArrayList\u0026lt;\u0026gt;()); for (int j : list) { edge[i][j] = edge[j][i] = true; } list.add(i); rec.put(site, list); } } int[] dis = new int[n]; Arrays.fill(dis, -1); Queue\u0026lt;Integer\u0026gt; que = new ArrayDeque\u0026lt;\u0026gt;(); for (int site : rec.getOrDefault(source, new ArrayList\u0026lt;\u0026gt;())) { dis[site] = 1; que.offer(site); } while (!que.isEmpty()) { int x = que.poll(); for (int y = 0; y \u0026lt; n; y++) { if (edge[x][y] \u0026amp;\u0026amp; dis[y] == -1) { dis[y] = dis[x] + 1; que.offer(y); } } } int ret = Integer.MAX_VALUE; for (int site : rec.getOrDefault(target, new ArrayList\u0026lt;\u0026gt;())) { if (dis[site] != -1) { ret = Math.min(ret, dis[site]); } } return ret == Integer.MAX_VALUE ? -1 : ret; }  题解 BFS 这里再写一个双向 BFS 。压缩部分和前面是一样的，问题是搜索部分。\n首先，将起点和终点（其实是经过起点和终点的所有公交线路）分别装入两个方向的 BFS 队列中，如果这里就发现有一样的，那说明有车能从起点直达终点，不用搜了，直接输出 1 。\nboolean[] vis = new boolean[n]; Deque\u0026lt;Integer\u0026gt; src_q, des_q; List\u0026lt;Integer\u0026gt; tar = rec.get(source); if (tar == null) { return -1; } else { src_q = new ArrayDeque\u0026lt;\u0026gt;(tar); for (Integer i : tar) { vis[i] = true; } } tar = rec.get(target); if (tar == null) { return -1; } else { des_q = new ArrayDeque\u0026lt;\u0026gt;(tar); for (Integer i : tar) { if (vis[i]) return 1; else vis[i] = true; } } 接下来就是双向 BFS，既然是 BFS，我们每次走一步，搜一步能到的所有公交线路，如果搜到路线出现在另一方向的队列中，说明两个队列接上了，直接输出。\nint src_steps = 0, des_steps = 1; while (!src_q.isEmpty() \u0026amp;\u0026amp; !des_q.isEmpty()) { Deque\u0026lt;Integer\u0026gt; front, back; // 每次挑元素少的队列进行 BFS，从而收缩搜索范围  if (src_q.size() \u0026gt; des_q.size()) { front = des_q; back = src_q; ++des_steps; } else { front = src_q; back = des_q; ++src_steps; } // 检查邻结点中有没有能到对面（即另一个方向的队列）  for (int i = front.size(); i \u0026gt; 0; --i) { int t = front.removeFirst(); for (int j = 0; j \u0026lt; n; ++j) { if (edge[t][j] \u0026amp;\u0026amp; !vis[j]) { if (!vis[j]) { vis[j] = true; front.addLast(j); } else { if (back.contains(j)) { return src_steps + des_steps; } } } } } } return -1; 代码总和\npublic int numBusesToDestination(int[][] routes, int source, int target) { if (source == target) { return 0; } int n = routes.length; boolean[][] edge = new boolean[n][n]; Map\u0026lt;Integer, List\u0026lt;Integer\u0026gt;\u0026gt; rec = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) { for (int site : routes[i]) { List\u0026lt;Integer\u0026gt; list = rec.getOrDefault(site, new ArrayList\u0026lt;\u0026gt;()); for (int j : list) { edge[i][j] = edge[j][i] = true; } list.add(i); rec.put(site, list); } } boolean[] vis = new boolean[n]; Deque\u0026lt;Integer\u0026gt; src_q, des_q; List\u0026lt;Integer\u0026gt; tar = rec.get(source); if (tar == null) { return -1; } else { src_q = new ArrayDeque\u0026lt;\u0026gt;(tar); for (Integer i : tar) { vis[i] = true; } } tar = rec.get(target); if (tar == null) { return -1; } else { des_q = new ArrayDeque\u0026lt;\u0026gt;(tar); for (Integer i : tar) { if (vis[i]) return 1; else vis[i] = true; } } int src_steps = 0, des_steps = 1; while (!src_q.isEmpty() \u0026amp;\u0026amp; !des_q.isEmpty()) { Deque\u0026lt;Integer\u0026gt; front, back; if (src_q.size() \u0026gt; des_q.size()) { front = des_q; back = src_q; ++des_steps; } else { front = src_q; back = des_q; ++src_steps; } for (int i = front.size(); i \u0026gt; 0; --i) { int t = front.removeFirst(); for (int j = 0; j \u0026lt; n; ++j) { if (edge[t][j]) { if (!vis[j]) { vis[j] = true; front.addLast(j); } else { if (back.contains(j)) { return src_steps + des_steps; } } } } } } return -1; }  总结 这道题反正无论如何都绕不开图压缩了。搜索上，两种方法最终时间相差无几（指用 Leetcode 案例前提下），最小路径算法其实有些超过题目需求了，不过 SPFA 很契合这道题的场景，因此效率还是很高，加上写起来方便（重点），略优于双向 BFS。\n","date":"2021-06-27T00:00:00Z","image":"https://winterorch.github.io/images/category/leetcode/TeaParty.jpg","permalink":"https://winterorch.github.io/p/leetcode-815-%E5%85%AC%E4%BA%A4%E8%B7%AF%E7%BA%BF/","title":"LeetCode 815 - 公交路线"},{"content":"首先要踩一下 PYQT，如果使用 Python 过程中有 GUI 方面的需求，请一定一定先看有没有 QT 之外的选择 （Django不好吗？）。用过 PYQT 的都知道，QT 提供的不仅仅是 GUI 组件库，而是从线程到网络通信的一整套 QObject ，个人认为对于 Python 而言这实在是过于不实际了，我觉得大多数人对于 Python 开发的期望都是每一个模块各司其职，项目能够“高内聚，低耦合”，Python 在这方面也是非常令人满意的，然而在 QT 中除外。\nPYQT 来源于 C++ QT，其理念就是将众多组件耦合到一起，如果你在一个团队中进行开发，这会导致——无论是图形界面方面的责任，还是业务逻辑方面的问题都会堆到你这里，成为你的压力，而如果你作为个人进行开发，这会使你写 GUI 的时候无时无刻不得顾及业务需求，两边都得顾得上，两边都得一起调。出了问题的话，非常不幸，网上能找到的 PYQT 资料非常之有限，甚至官方文档中都有大量的 TODO ，且完全没有要补上的迹象，我写代码过程中基本都只能参考 QT 的官方文档，因为他实在是比 PyQt 官方提供的要友好得多。\n如果在确认了这些问题之后，还是要入门 PYQT，推荐几个 Github：PyQt Examples 提供了大部分常用 GUI 组件的使用 Deemo，虽然 PyQt 对于这些组件基本都有大量复杂数倍的替代品，供你完成非常繁杂的需求，但是，没有谁想从那入手的。\n 顺便提一下，有个非常不错（指功能上）的 PyQt 音乐播放器 FeelUOwn 项目。当时看到这个小项目是很感动的，非常兴奋地下下来源码，然后确信自己看的是天书——项目代码不是给人读的，PyQt 极大放大了代码可读性差的问题\n 接下来是正片——\n 开始 PyQt 项目，你要知道这些   如果用 PyCharm 构建 PyQt 项目，你在点下 Run/Debug 之前请务必检查一下 Debug 配置\nRun 和 Debug 图标左边那个下拉菜单，其中的 Edit Configurations，请检查一下 Configuration 下的 Excution 栏，确保 Emulate terminal in output console 这个选项勾上。否则即使你的程序挂掉，控制台也不会抛出一个异常来，没有什么比程序跑不起来，甚至连哪里出了问题都无法追溯更让人头疼的事情了。\n   使用 QSS ，你要知道这些 QSS 看似很美好，但也是重灾区。\n  QSS Style Sheet 会自动由父框架传递给子框架 什么意思呢？就是说你可能想给 QWidget 设个好看的边框，于是写下这么一段内容：\nQWidget { background: lightGray; border: 3px solid blue; } 然后发现所有 Widget 下所有的 QLabel 都诡异地多了个框而父框架反而没有。为什么呢？因为 QLabel 也是 QWidget 的一种，QWidget 的样式表会自动传递到它，并且生效。然而 QWidget 自己却不能生效，因为 QWidget 天生无法让自己的显式样式生效，它们只是用来传递给子框架的，换句话说，Qt 就这么设计的。\n如果想让父框架有边框之类的设置，请用 QFrame ，它不仅有同样的参数而且几乎能替代 QWidget 。\n  请尽量使用对象的 objectName 来区分子对象的样式 如果你想要你的设置仅仅对最外层，或子对象中的一个生效，请这么写：\nQWidget[objectName=\u0026#39;OutsidePanel\u0026#39;] { background: lightGray; border: 3px solid blue; } 那什么是 objectName 呢？它是 QObject 的一个成员变量，没错，PyQt 在最不需要解耦的地方做了一次解耦，让 objectName 需要单独设置。所以接下来，在这个你想让它有边框的 QWidget 的构造函数中写下：self.setObjectName(\u0026quot;OutsidePanel\u0026quot;) 。\n不推荐将组件的样式表颗粒化，在初始化过程中单独 setStyleSheet() ，还是推荐将一整个 Panel 的样式整合成一个文件，在父框架进行设置，而避免在运行过程中还要动态加载。我认为 Qt 的设计者也是这样希望的，应当有相应的优化。\n关于 QSS ，网上其实能查到很多内容，比方有人说可以直接跟据对象名和 CSS 一样用 # 设置对象的样式，实测并不行，推测可能是 PyQt 版本不同，能力也有所不同，很多网上提供的 QSS 属性也并不能生效。虽然 QSS 想让做 GUI 的人尽量用熟悉的方法——CSS来设计，但功能属实有限，不能达到 CSS 的效果不说，还给了有 CSS 使用经验的人过多不切实际的幻想，只能说是将 PyQt 本就有限的样式设置从 GUI 设计中部分解耦出来。\n  【未完，对 PyQt ，想吐槽的点实在是如涛涛江水一般】\n","date":"2021-06-25T00:00:00Z","image":"https://winterorch.github.io/images/feature/scenes/UAZ.jpg","permalink":"https://winterorch.github.io/p/python-pyqt_bloody_tips/","title":"Python - PYQT 踩坑记"},{"content":"[LeetCode] 752. Open the Lock You have a lock in front of you with 4 circular wheels. Each wheel has 10 slots: '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'. The wheels can rotate freely and wrap around: for example we can turn '9' to be '0', or '0' to be '9'. Each move consists of turning one wheel one slot.\nThe lock initially starts at '0000', a string representing the state of the 4 wheels.\nYou are given a list of deadends dead ends, meaning if the lock displays any of these codes, the wheels of the lock will stop turning and you will be unable to open it.\nGiven a target representing the value of the wheels that will unlock the lock, return the minimum total number of turns required to open the lock, or -1 if it is impossible.\nExample 1:\nInput: deadends = [\u0026quot;0201\u0026quot;,\u0026quot;0101\u0026quot;,\u0026quot;0102\u0026quot;,\u0026quot;1212\u0026quot;,\u0026quot;2002\u0026quot;], target = \u0026quot;0202\u0026quot;\rOutput: 6\rExplanation:\rA sequence of valid moves would be \u0026quot;0000\u0026quot; -\u0026gt; \u0026quot;1000\u0026quot; -\u0026gt; \u0026quot;1100\u0026quot; -\u0026gt; \u0026quot;1200\u0026quot; -\u0026gt; \u0026quot;1201\u0026quot; -\u0026gt; \u0026quot;1202\u0026quot; -\u0026gt; \u0026quot;0202\u0026quot;.\rNote that a sequence like \u0026quot;0000\u0026quot; -\u0026gt; \u0026quot;0001\u0026quot; -\u0026gt; \u0026quot;0002\u0026quot; -\u0026gt; \u0026quot;0102\u0026quot; -\u0026gt; \u0026quot;0202\u0026quot; would be invalid,\rbecause the wheels of the lock become stuck after the display becomes the dead end \u0026quot;0102\u0026quot;.\rExample 2:\nInput: deadends = [\u0026quot;8888\u0026quot;], target = \u0026quot;0009\u0026quot;\rOutput: 1\rExplanation:\rWe can turn the last wheel in reverse to move from \u0026quot;0000\u0026quot; -\u0026gt; \u0026quot;0009\u0026quot;.\rExample 3:\nInput: deadends = [\u0026quot;8887\u0026quot;,\u0026quot;8889\u0026quot;,\u0026quot;8878\u0026quot;,\u0026quot;8898\u0026quot;,\u0026quot;8788\u0026quot;,\u0026quot;8988\u0026quot;,\u0026quot;7888\u0026quot;,\u0026quot;9888\u0026quot;], target = \u0026quot;8888\u0026quot;\rOutput: -1\rExplanation:\rWe can't reach the target without getting stuck.\rExample 4:\nInput: deadends = [\u0026quot;0000\u0026quot;], target = \u0026quot;8888\u0026quot;\rOutput: -1\rConstraints:\n 1 \u0026lt;= deadends.length \u0026lt;= 500 deadends[i].length == 4 target.length == 4 target will not be in the list deadends. target and deadends[i] consist of digits only.   题解 双向 BFS  类似题：LeetCode 127 Word Ladder II\n 看到有 deadends 其实就比较明显了——这是个走迷宫问题，而且因为有四位密码，所以其实是个四维迷宫。维数并不会增加解法的复杂程度，倒是会严重增加敲代码的繁琐程度。一开始是打算真的和迷宫一样，用四维数组做的，后来发现参数实在太多了，光敲一个位置就要 mem[i0][i1][i2][i3] 这样来一遍，实在有点头皮发麻，改用 String 和 Map 来做记忆化了。\n还是当作迷宫来解，因此思想是 BFS ，因为入口和出口都是唯一确定的，前后都可以作为 BFS 的起点，因此可以通过双向 BFS 来收缩搜索范围。\n首先把 deadends 存到一个 HashSet 里，方便查验。BFS 需要前后两个队列，分别维护一个记忆化搜索表，记录到 key 位置的步长。\nDeque\u0026lt;String\u0026gt; d1 = new ArrayDeque\u0026lt;\u0026gt;(), d2 = new ArrayDeque\u0026lt;\u0026gt;(); Map\u0026lt;String, Integer\u0026gt; m1 = new HashMap\u0026lt;\u0026gt;(), m2 = new HashMap\u0026lt;\u0026gt;(); d1.addLast(s); m1.put(s, 0); d2.addLast(t); m2.put(t, 0); 然后就是 BFS 了，一直搜到队列空为止。为了尽量收缩双向 BFS 的搜索范围，每次从更小的队列取元素进行搜索。\nwhile (!d1.isEmpty() \u0026amp;\u0026amp; !d2.isEmpty()) { int t = -1; if (d1.size() \u0026lt;= d2.size()) { t = update(d1, m1, m2); } else { t = update(d2, m2, m1); } if (t != -1) return t; } 每次搜索要搜相邻的八个位置，也就是每一位的前后两个数字。原数字是 char[i] 的话，以十为模加一或加九就行了——(char) ('0' + ((chars[i] - '0' + offset) % 10)) 。\n新状态的检查包括这样一些原则——\n 新位置不能是 deadend 新位置不能已经去过（在同一队列中），同一队列两次经过同一位置步长一定不会变短，也就不需要考虑了 在满足前两个前提下，如果能在反向记忆中找到相同状态，那一定是最短路径，直接输出 不在反向记忆中，就加入到当前记忆队列中，从而引起下一轮 BFS  char ori = chars[i]; chars[i] = (char) (\u0026#39;0\u0026#39; + ((chars[i] - \u0026#39;0\u0026#39; + offset) % 10)); String go = String.valueOf(chars); chars[i] = ori; if (this.deadEnds.contains(go)) continue; if (fs_map.containsKey(go)) continue; if (ot_map.containsKey(go)) { this.res = step + 1 + ot_map.get(go); return true; } fs_map.put(go, step + 1); fs.addLast(go); 完整代码\nint res; int[] offset = {1, 9}; Set\u0026lt;String\u0026gt; deadEnds; public int openLock_remastered(String[] dead, String target) { if (target.equals(\u0026#34;0000\u0026#34;)) return 0; this.deadEnds = new HashSet\u0026lt;\u0026gt;(); // 虽然这里 IDE 会推荐让 Arrays 来把 String[] 转换成 Collection,但这样做对速度没有好处。  // IDE 上测出来差别不大，但到了 LeetCode 上居然能让整题多耗将近一倍时间，百思不得其解。  for (String str: dead) deadEnds.add(str); if (deadEnds.contains(\u0026#34;0000\u0026#34;)) return -1; Deque\u0026lt;String\u0026gt; front = new ArrayDeque\u0026lt;\u0026gt;(); Map\u0026lt;String, Integer\u0026gt; front_map = new HashMap\u0026lt;\u0026gt;(); Deque\u0026lt;String\u0026gt; back = new ArrayDeque\u0026lt;\u0026gt;(); Map\u0026lt;String, Integer\u0026gt; back_map = new HashMap\u0026lt;\u0026gt;(); front.addLast(\u0026#34;0000\u0026#34;); front_map.put(\u0026#34;0000\u0026#34;, 0); back.addLast(target); back_map.put(target, 0); while (!front.isEmpty() \u0026amp;\u0026amp; !back.isEmpty()) { if (front.size() \u0026lt; back.size()) { if (update(front, front_map, back_map)) return this.res; } else { if (update(back, back_map, front_map)) return this.res; } } return -1; } private boolean update(Deque\u0026lt;String\u0026gt; fs, Map\u0026lt;String, Integer\u0026gt; fs_map, Map\u0026lt;String, Integer\u0026gt; ot_map) { String cur = fs.pollFirst(); char[] chars = cur.toCharArray(); int step = fs_map.get(cur); for (int i = 0; i \u0026lt; 4; ++i) { for (int offset : this.offset) { char ori = chars[i]; // 在原 char[] 上改了，取完 String 再转回去，  // 会比 clone() 新的要快很多 \tchars[i] = (char) (\u0026#39;0\u0026#39; + ((chars[i] - \u0026#39;0\u0026#39; + offset) % 10)); String go = String.valueOf(chars); chars[i] = ori;\tif (this.deadEnds.contains(go)) continue; if (fs_map.containsKey(go)) continue; if (ot_map.containsKey(go)) { this.res = step + 1 + ot_map.get(go); return true; } fs_map.put(go, step + 1); fs.addLast(go); } } return false; }  题解 AStar 算法 作者：AC_OIer 链接：https://leetcode-cn.com/problems/open-the-lock/solution/gong-shui-san-xie-yi-ti-shuang-jie-shuan-wyr9/\n可以直接根据本题规则来设计 A* 的「启发式函数」。\n比如对于两个状态 a 和 b 可直接计算出「理论最小转换次数」：不同字符的转换成本之和 。\n需要注意的是：由于我们衡量某个字符 str 的估值是以目标字符串 target 为基准，因此我们只能确保 target 出队时为「距离最短」，而不能确保中间节点出队时「距离最短」，因此我们不能单纯根据某个节点是否「曾经入队」而决定是否入队，还要结合当前节点的「最小距离」是否被更新而决定是否入队。\n这一点十分关键，在代码层面上体现在 map.get(str).step \u0026gt; poll.step + 1 的判断上。\n注意：本题用 A* 过了，但通常我们需要先「确保有解」，A* 的启发搜索才会发挥真正价值。而本题，除非 t 本身在 deadends 中，其余情况我们无法很好提前判断「是否有解」。对于无解的情况 A* 效果不如「双向 BFS」。\n源码\nclass Solution { class Node { String str; int val, step; /** * str : 对应字符串 * val : 估值（与目标字符串 target 的最小转换成本） * step: 对应字符串是经过多少步转换而来 */ Node(String _str, int _val, int _step) { str = _str; val = _val; step = _step; } } int f(String str) { int ans = 0; for (int i = 0; i \u0026lt; 4; i++) { int cur = str.charAt(i) - \u0026#39;0\u0026#39;, target = t.charAt(i) - \u0026#39;0\u0026#39;; int a = Math.min(cur, target), b = Math.max(cur, target); // 在「正向转」和「反向转」之间取 min  int min = Math.min(b - a, a + 10 - b); ans += min; } return ans; } String s, t; Set\u0026lt;String\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); public int openLock(String[] ds, String _t) { s = \u0026#34;0000\u0026#34;; t = _t; if (s.equals(t)) return 0; for (String d : ds) set.add(d); if (set.contains(s)) return -1; PriorityQueue\u0026lt;Node\u0026gt; q = new PriorityQueue\u0026lt;\u0026gt;((a,b)-\u0026gt;a.val-b.val); Map\u0026lt;String, Node\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); Node root = new Node(s, f(s), 0); q.add(root); map.put(s, root); while (!q.isEmpty()) { Node poll = q.poll(); char[] pcs = poll.str.toCharArray(); int step = poll.step; if (poll.str.equals(t)) return step; for (int i = 0; i \u0026lt; 4; i++) { for (int j = -1; j \u0026lt;= 1; j++) { if (j == 0) continue; int cur = pcs[i] - \u0026#39;0\u0026#39;; int next = (cur + j) % 10; if (next == -1) next = 9; char[] clone = pcs.clone(); clone[i] = (char)(next + \u0026#39;0\u0026#39;); String str = String.valueOf(clone); if (set.contains(str)) continue; // 如果 str 还没搜索过，或者 str 的「最短距离」被更新，则入队  if (!map.containsKey(str) || map.get(str).step \u0026gt; step + 1) { Node node = new Node(str, step + 1 + f(str), step + 1); map.put(str, node); q.add(node); } } } } return -1; } } ","date":"2021-06-24T00:00:00Z","image":"https://winterorch.github.io/images/category/leetcode/TeaParty.jpg","permalink":"https://winterorch.github.io/p/leetcode-752-%E6%89%93%E5%BC%80%E8%BD%AC%E7%9B%98%E9%94%81/","title":"LeetCode 752 - 打开转盘锁"},{"content":"Spring 支持的依赖注入有 @Autowired @Resource @Inject 三种\n@Autowired 来自 org.springframwork.beans.factory.annotation.Autowired ，装配顺序为：\n 按 type 在上下文中查找匹配的 bean 如果有多个 bean，则按照 name 进行匹配  如有 @Qualifier ，则按指定的 name 进行匹配 如没有，则按变量名进行匹配   匹配不到就报错  @Autowired(required=false) 则注入失败不抛异常\n@Inject Spring 环境下和 @Autowired 相同，都依赖 AutowiredAnnotationBeanPostProcess 进行处理，但不能 (required=false)。@Inject 由 JSR-330 定义，可以切换到谷歌的 DI 框架——Guice。\n@Inject 在 Java EE 包内，SE 环境需要单独引入。\n@Resource JSR-250 定义。在 CommonAnnotationBeanPostProcessor 实现处理。同样有 name 和 type。装配顺序：\n 如同时指定 name 和 type ，从上下文找到唯一匹配 bean 进行装配，找不到抛异常 如指定 name ，则到上下文找 id 匹配的 bean 进行装配，找不到抛异常 如指定 type ，则到上下文找类型匹配的唯一 bean 进行装配，找不到或找到不唯一都会抛异常 如果都没有指定，则默认按 byName 方式装配，找不到再按 byType 进行装配   IDEA 使用 @Autowired 时很常见警告 Field injection is not recommended。\nSpring 团队建议永远使用构造方法，也就是 c-args 进行依赖注入。IDEA 对这一警告的默认修改方式也是——创建一个构造器进行依赖注入。并且，跟据 Spring 团队建议，对必须的依赖，应当使用断言进行确认\nAssert.notNull(svc, \u0026#34;svc must not be null\u0026#34;); 为什么不能用成员依赖注入呢？\nfield 注入虽然简洁，但存在问题：\n 由于添加依赖过于简单（加个注释），我们很容易无意识地向一个类注入大量依赖，这违反了单一职责原理，因为我们过去通过构造器进行注入，而要是你的构造器出现大量入参，那很容易意识到自己的代码结构不对劲。打个比方——原本要数着钞票买东西的，一下子变成移动支付，点一下付钱了，就容易到了月底为账单发愁，因为我们金钱意识变薄弱了。解决方法就是——继续用构造器注入，因此对于强制依赖，Spring推荐用 c-args 注入。 依赖注入与容器本身耦合了，即——类唯一的正常工作方式就是通过容器反射进行实例化，这就像是集成测试一样，不像个健康的类，就像一个人原本你把饭给他就能自己吃，现在非要注射进去一样。为了让类能在容器外使用，自然还是要用 c-args 和 s-args。 属性注入不能用来注入 final 变量。   因此 Spring 给出建议：constructor-based 和 setter-based DI 可以混用，\n  强制依赖就用 constructor-based\n很好理解，类离开强制依赖就无法工作，这和构造方法职能相吻合，也能注入 final 变量。构造器可以保证这些变量的值不会是 null 。\n  可选、可变依赖用 setter-based\nsetter 值应被用于注入非必须依赖，这些依赖可以很方便地被改变或重新注入，否则会需要大量的 null 检查。\n  ","date":"2021-06-24T00:00:00Z","image":"https://winterorch.github.io/images/feature/scenes/Arctic.jpg","permalink":"https://winterorch.github.io/p/spring-%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%8C%BA%E5%88%86/","title":"Spring - 依赖注入注解的区分"},{"content":"剑指 Offer 56 - I. 数组中数字出现的次数 一个整型数组 nums 里除两个数字之外，其他数字都出现了两次。请写程序找出这两个只出现一次的数字。要求时间复杂度是O(n)，空间复杂度是O(1)。\n示例 1：\n 输入：nums = [4,1,4,6] 输出：[1,6] 或 [6,1]\n 示例 2：\n 输入：nums = [1,2,10,4,1,4,3,3] 输出：[2,10] 或 [10,2]\n 限制：\n 2 \u0026lt;= nums.length \u0026lt;= 10000\n  题解 时空复杂度已经很明显提示了，要用位运算，异或消除掉出现过两次的数字\nfor(int num : nums) n ^= num; 如果只有一个出现一次的数字，那答案已经出来了。然而这题有两个数字 x, y，得到的 n 是两者的异或 n = x ^ y 。因为 x != y ，n 必定有至少一个非零位，接下来肯定得围绕着这个非零位作文章。\n而这个非零位有什么用呢？它告诉我们，x 和 y 中有一个 (x) 在该比特位上非零，另一个 (y) 为零。前面知道，通过异或只能得出唯一一个出现一次的数字，而现在有两个数字，那思路应当是——把这两个数字区分开来，分成具有不同特点的两组，这样就能分别求出这两个数字了。而现在，这个用来区分的特点有了——在 n 最低非零位上是否为零。\n因此，接下来要做的就是——再遍历一遍原数组，在 n 最低非零位上跟据是否为零放到两个 int 上去异或。\n完整答案\npublic int[] singleNumbers(int[] nums) { int x = 0, y = 0, n = 0, m = 1; for(int num : nums) // 1. 遍历异或  n ^= num; while((n \u0026amp; m) == 0) // 2. 循环左移，计算 m  m \u0026lt;\u0026lt;= 1; for(int num: nums) { // 3. 遍历 nums 分组  if((num \u0026amp; m) != 0) x ^= num; // 4. 当 num \u0026amp; m != 0  else y ^= num; // 4. 当 num \u0026amp; m == 0  } return new int[] {x, y}; // 5. 返回出现一次的数字 } ","date":"2021-06-20T00:00:00Z","image":"https://winterorch.github.io/images/category/leetcode/AfternoonTea.jpg","permalink":"https://winterorch.github.io/p/%E5%89%91%E6%8C%87-offer-56-i.-%E6%95%B0%E7%BB%84%E4%B8%AD%E6%95%B0%E5%AD%97%E5%87%BA%E7%8E%B0%E7%9A%84%E6%AC%A1%E6%95%B0/","title":"剑指 Offer 56 - I. 数组中数字出现的次数"},{"content":"首先，在 Spring 4.X 之后（不用 Spring Boot 的话）使用注释需要添加 aop 依赖。虽然不需要这么做了，还是有助于了解 Spring Boot 到底为我们做了什么。\n\u0026lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-aop --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-aop\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;{springframework.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 而且需要在 XML 中添加约束并在 context 中配置扫描范围。\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\u0026#34;\u0026gt; \u0026lt;context:annotation-config/\u0026gt; \u0026lt;/beans\u0026gt; 配置扫描范围\n\u0026lt;!--指定注解扫描包--\u0026gt; \u0026lt;context:component-scan base-package=\u0026#34;com.yourpackage\u0026#34;/\u0026gt; 接下来按类别整理一些最常用的注释。\nBean 的扫描   @ComponentScan\n   @ComponentScan：通过注释方式配置扫描范围，将其下的 @Component 组件（包括@Controller、@Service、@Repository）纳入 IOC 容器. 只能作用于配置类，且 Spring Boot 的入口类不能被纳入到扫描范围中.\n Spring Boot 默认的扫描范围是启动类所在包开始，当前包及子包下的所有文件\n @Configuration @ComponentScan(\u0026#34;cc.mrbird.demo\u0026#34;) public class WebConfig { }  可以通过 excludeFilters 来排除一些组件的扫描，通过 @Filter 注释完成\n@Configuration @ComponentScan(value = \u0026#34;cc.mrbird.demo\u0026#34;, excludeFilters = { // 将注解为 Controller 和 Repository 的类排除  @Filter(type = FilterType.ANNOTATION, classes = {Controller.class, Repository.class}), // 排除所有 User 类（及子类、实现类）  @Filter(type = FilterType.ASSIGNABLE_TYPE, classes = User.class) }) public class WebConfig { } 如上所示，可以跟据注释或直接指定排除相应类型（包括其子类、实现类）\nincludeFilters的作用和excludeFilters相反，其指定的是哪些组件需要被扫描：\n@Configuration @ComponentScan(value = \u0026#34;cc.mrbird.demo\u0026#34;, includeFilters = { // 仅纳入注释为 Service 的类  @Filter(type = FilterType.ANNOTATION, classes = Service.class) }, useDefaultFilters = false) public class WebConfig { } 通过实现 org.springframework.core.type.filter.TypeFilter接口可以自定义扫描策略，通过实现 match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) 方法，返回 true 说明匹配成功。\n   Bean 的注册   @Bean, @Component\n   @Bean：通过注解向 IOC 容器注册默认为方法名的 Bean，也可以通过 @Bean(\u0026quot;{name}\u0026quot;) 来重新命名\n@Configuration public class WebConfig { @Bean() public User user() { return new User(\u0026#34;mrbirdy\u0026#34;, 18); } }  实现了 FactoryBean\u0026lt;T\u0026gt; 接口的 Bean 是一类特殊的 Bean\npublic class CherryFactoryBean implements FactoryBean\u0026lt;Cherry\u0026gt; { @Override public Cherry getObject() { return new Cherry(); } @Override public Class\u0026lt;?\u0026gt; getObjectType() { return Cherry.class; } @Override public boolean isSingleton() { return false; } } 如果 isSingleton() 为 false ，则每次会调用 getObject() 从中获取 Bean。\n通过加上前缀 \u0026amp; 从工厂中取出对应的 Bean\nObject cherryFactoryBean = context.getBean(\u0026#34;\u0026amp;cherryFactoryBean\u0026#34;);    @Component：component-scan 指定的扫描路径下所有被@Controller、@Service、@Repository和@Component注解标注的类都会被纳入IOC容器中\n@Component(\u0026#34;user\u0026#34;) // 相当于配置文件中 \u0026lt;bean id=\u0026#34;user\u0026#34; class=\u0026#34;当前注解的类\u0026#34;/\u0026gt; public class User { public String name = ... } 说明该类被Spring管理。Component 类的有参构造方法会被默认用作依赖注入，所以相比在成员变量上加 @Autowire 来注入依赖，更合适的方法是通过构造方法注入。\n衍生注解：按照MVC三层架构分层\n @Repository：用于DAO层，数据库操作 @Service：用于Service层，复杂逻辑 @Controller：用于Controller层，接收用户请求并调用Service层返回数据  连同@Component，四个注解功能一样，都代表将某个类注册到Spring中\n  Bean 的加载   @Scope, @Lazy, @Conditional\n   @Scope：改变组件的作用域（默认 singleton）\n singleton：单实例（默认）,在Spring IOC容器启动的时候会调用方法创建对象然后纳入到IOC容器中，以后每次获取都是直接从IOC容器中获取（map.get()）； prototype：多实例，IOC容器启动的时候并不会去创建对象，而是在每次获取的时候才会去调用方法创建对象； request：一个请求对应一个实例； session：同一个session对应一个实例。    @Lazy：懒加载（针对 singleton ）\n懒加载的单例不会马上调用方法创建对象并注册，只有当第一次被使用时才会调用方法创建对象并加入容器中。\n  @Conditional：条件加载，类似于前面 @ComponentScan 中的 Filter\n使用@Conditional注解我们可以指定组件注册的条件，即满足特定条件才将组件纳入到 IOC 容器中。\n在使用该注解之前，我们需要创建一个类，实现Condition接口：\npublic class MyCondition implements Condition {\r@Override\rpublic boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) {\rreturn false;\r}\r}\r该接口包含一个matches方法，包含两个入参:\n ConditionContext：上下文信息； AnnotatedTypeMetadata：注解信息。  简单完善一下这个实现类:\npublic class MyCondition implements Condition { @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { String osName = context.getEnvironment().getProperty(\u0026#34;os.name\u0026#34;); return osName != null \u0026amp;\u0026amp; osName.contains(\u0026#34;Windows\u0026#34;); } } 接着将这个条件添加到User Bean注册的地方：\n@Bean @Conditional(MyCondition.class) public User user() { return new User(\u0026#34;mrbird\u0026#34;, 18); } 在Windows环境下，User这个组件将被成功注册，如果是别的操作系统，这个组件将不会被注册到IOC容器中。\n  属性注入   @Value, @ConfigurationProperties, @PropertySource\n   @Value:\tProperty注入\n可以直接用在成员变量上，也可以用在Setter上\n 需要注意的是 @value这种方式是不被推荐的，Spring 比较建议的是下面几种读取配置信息的方式。\n   @ConfigurationProperties: Properties 读取并与 bean 绑定\n LibraryProperties 类上加了 @Component 注解，我们可以像使用普通 bean 一样将其注入到类中使用。\n import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; import org.springframework.stereotype.Component; import java.util.List; @Component @ConfigurationProperties(prefix = \u0026#34;library\u0026#34;) class LibraryProperties { private String location; private List\u0026lt;Book\u0026gt; books; static class Book { String name; String description; } } 相应的配置文件内容\nlibrary:\rlocation: 湖北武汉加油中国加油\rbooks:\r- name: 天才基本法\rdescription: 二十二岁的林朝夕在父亲确诊阿尔茨海默病这天，得知自己暗恋多年的校园男神裴之即将出国深造的消息——对方考取的学校，恰是父亲当年为她放弃的那所。\r- name: 时间的秩序\rdescription: 为什么我们记得过去，而非未来？时间“流逝”意味着什么？是我们存在于时间之内，还是时间存在于我们之中？卡洛·罗韦利用诗意的文字，邀请我们思考这一亘古难题——时间的本质。\r- name: 了不起的我\rdescription: 如何养成一个新习惯？如何让心智变得更成熟？如何拥有高质量的关系？ 如何走出人生的艰难时刻？\r然后就可以通过 private final LibraryProperties library 注入 Property 对象了。\n题外话：InitializingBean 接口下的 afterPropertiesSet() 方法可以作为一个 Property 注入后的 AOP 使用，如下所示：\n@SpringBootApplication public class ReadConfigPropertiesApplication implements InitializingBean { private final LibraryProperties library; public ReadConfigPropertiesApplication(LibraryProperties library) { this.library = library; } public static void main(String[] args) { SpringApplication.run(ReadConfigPropertiesApplication.class, args); } @Override public void afterPropertiesSet() { System.out.println(library.getLocation()); System.out.println(library.getBooks()); } }  如果 Property类上不加 Component ，就需要在 SpringBootApplication 上加 @EnableConfigurationProperties 来注册 Bean ，如下所示：\n@SpringBootApplication @EnableConfigurationProperties(ProfileProperties.class) public class ReadConfigPropertiesApplication implements InitializingBean { private final ProfileProperties profileProperties; public ReadConfigPropertiesApplication(ProfileProperties profileProperties) { this.profileProperties = profileProperties; } public static void main(String[] args) { SpringApplication.run(ReadConfigPropertiesApplication.class, args); } @Override public void afterPropertiesSet() { System.out.println(profileProperties.toString()); } }    @PropertySource: 有单独文件的 properties 可以通过 @PropertySource 来读取\nimport org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.PropertySource; import org.springframework.stereotype.Component; @Component @PropertySource(\u0026#34;classpath:website.properties\u0026#34;) class WebSite { @Value(\u0026#34;${url}\u0026#34;) private String url; }   校验注解  这里可以参考 Spring Boot 指南\n  JSR 提供的校验注解:\n @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式  public class Person { @NotNull(message = \u0026#34;classId 不能为空\u0026#34;) private String classId; @Size(max = 33) @NotNull(message = \u0026#34;name 不能为空\u0026#34;) private String name; @Pattern(regexp = \u0026#34;((^Man$|^Woman$|^UGM$))\u0026#34;, message = \u0026#34;sex 值不在可选范围\u0026#34;) @NotNull(message = \u0026#34;sex 不能为空\u0026#34;) private String sex; @Email(message = \u0026#34;email 格式不正确\u0026#34;) @NotNull(message = \u0026#34;email 不能为空\u0026#34;) private String email; } Hibernate Validator 提供的校验注解：\n @NotBlank(message =) 验证字符串非 null，且长度必须大于 0 @Email 被注释的元素必须是电子邮箱地址 @Length(min=,max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内  自动装配   @Autowired, @Resource\n  @Autowired  自动装配，先byType再byName，如果不能唯一自动装配，则需要@Qualifier(value=\u0026quot;xxx\u0026quot;).\n在成员变量上实现：\npublic class User { @Autowired private Cat cat; @Autowired private Dog dog; private String str; public Cat getCat() { return cat; } public Dog getDog() { return dog; } public String getStr() { return str; } } 然后在XML中配置Bean\n\u0026lt;context:annotation-config/\u0026gt; \u0026lt;bean id=\u0026#34;dog\u0026#34; class=\u0026#34;com.kuang.pojo.Dog\u0026#34;/\u0026gt; \u0026lt;bean id=\u0026#34;cat\u0026#34; class=\u0026#34;com.kuang.pojo.Cat\u0026#34;/\u0026gt; \u0026lt;bean id=\u0026#34;user\u0026#34; class=\u0026#34;com.kuang.pojo.User\u0026#34;/\u0026gt;   @Qualifer()：如果bean名字不为类的默认名字，则要加@Qualifer\n@Autowired @Qualifier(value = \u0026#34;cat2\u0026#34;) private Cat cat; @Autowired @Qualifier(value = \u0026#34;dog2\u0026#34;) private Dog dog;    \u0026lt;/br\u0026gt;\r- #### `@Resource`\r自动装配，先`byName`再`byType`，如果`name`属性指定，则只会按照名称进行装配.\r默认按照名称进行装配，名称可以通过name属性进行指定。如果没有指定name属性，当注解写在字段上时，默认取字段名进行按照名称查找，如果注解写在setter方法上默认取属性名进行装配\r```java\rpublic class User {\r//如果允许对象为null，设置required = false,默认为true\r@Resource(name = \u0026quot;cat2\u0026quot;)\rprivate Cat cat;\r@Resource\rprivate Dog dog;\rprivate String str;\r}\r事务   @Transactional\n   @Transactional\n在 Service 的实现类中使用，将方法标注为 SQL 事务.\n首先需要在入口类上加入 @EnableTransactionManagement 注解以开启事务：\n@EnableTransactionManagement @SpringBootApplication public class TransactionApplication { public static void main(String[] args) throws Exception { SpringApplication.run(TransactionApplication.class, args); } } 然后再 @Service 中标注事务：\n@Service public class UserServiceImpl implements UserService { private final UserMapper userMapper; public UserServiceImpl(UserMapper userMapper) { this.userMapper = userMapper; } @Transactional @Override public void saveUser(User user) { userMapper.save(user); // 测试事务回滚  if (!StringUtils.hasText(user.getUsername())) { throw new RuntimeException(\u0026#34;username不能为空\u0026#34;); } } } 如果生效，当用户名为空（这里用的是 org.springframework.util 包下的 hasText() 方法，要求字符串不为 null 、长度大于0、不全为空），则会捕获到异常而进行回滚。\n @Transactional 同样利用的是 Spring 的 AOP 机制, 这里有两个坑.\n注意点一\n如果抛出的异常不是 RuntimeException 或者 Error ，也不是 @Transactional 注解指定的回滚异常类型，则不会进行事务回滚。所以在自定义需要回滚的异常时，要么继承 RuntimeException ，要么直接在注释上标出来：\n@Transactional(rollbackFor = Exception.class) @Override public void saveUser(User user) throws Exception { userMapper.save(user); // 测试事务回滚  if (!StringUtils.hasText(user.getUsername())) { throw new Exception(\u0026#34;username不能为空\u0026#34;); } } 注意点二\n如果我们在相同 Service 下的非事务方法中，对事务方法进行调用，事务同样不会生效。如下：\n@Service public class UserServiceImpl implements UserService { private final UserMapper userMapper; public UserServiceImpl(UserMapper userMapper) { this.userMapper = userMapper; } @Override public void saveUserTest(User user) { this.saveUser(user); } @Transactional @Override public void saveUser(User user) { userMapper.save(user); // 测试事务回滚  if (!StringUtils.hasText(user.getUsername())) { throw new ParamInvalidException(\u0026#34;username不能为空\u0026#34;); } } } 因为 Spring 事务控制通过 AOP 代理实现，通过代理目标对象来增强目标方法，而如果用 this 调用方法，this 绕过了代理类（实际上是代理类绕过原类，this 无视了代理类），直接用了类本身，从而没有触发事务。\n要让代理类重新生效有两种方法\n1、 从 IOC 中获取 Bean 后再调用：\n@Override public void saveUserTest(User user) { UserService userService = context.getBean(UserService.class); userService.saveUser(user); } 2、 直接从 AOP 上下文取代理对象进行调用（需要引入 AOP Starter 依赖），且需要再在 SpringBoot 入口类中通过注解@EnableAspectJAutoProxy(exposeProxy = true)将当前代理对象暴露到 AOP 上下文中（通过 AopContext 的 ThreadLocal 实现）\n@Override public void saveUserTest(User user) { UserService userService = (UserService) AopContext.currentProxy(); userService.saveUser(user); } 总之是有种为了舍近求远又额外兜了一大圈的感觉，个人认为写事务就不要代入编程优雅方面的考虑了，没必要在方法单一职责上那么较真。\n   ","date":"2021-06-16T00:00:00Z","image":"https://winterorch.github.io/images/feature/scenes/Fancy1.jpg","permalink":"https://winterorch.github.io/p/spring-%E5%B8%B8%E7%94%A8%E6%B3%A8%E9%87%8A/","title":"Spring - 常用注释"},{"content":"先简单过一下接口语法中的注意点。\n注意点   接口中的变量隐式指定为 public static final\n  接口中的方法会被隐式指定为 public abstract （JDK 1.9 后允许 private，其它修饰符会报错）\n 这也决定了接口中所有方法都必须被实现，当然这一要求有两种特殊的满足方式——抽象类实现接口，那么接口方法不一定要实现，可以由抽象类的子类实现；JDK 1.8 后有默认实现的接口方法也不必被实现类显式实现。\n   接口不能有构造方法\n  JDK 1.8 后，接口可以有静态方法和方法体\n  JDK 1.8 后，接口方法可以有默认方法，用 default 关键字修饰\n  与抽象类语法上的区别   一个类可以实现多个接口\n  一个接口可以继承多个其它接口\nJava 接口是对行为的抽象，一个行为本身可以看作多个行为的耦合\npublic interface Hockey extends Sports, Event    接口与抽象类区别 接口和抽象类语法上的不同在之前两个文档中都已经接释清楚了，这里主要看两者思想上的不同。\n摘取一些《Effective Java》中的说法\n 接口是对行为的抽象，达到 API 定义与实现分类 的目的，因此支持多实现。甚至可以用没有任何方法的接口，作为 Marker Interface，目的仅仅是进行声明。但是用接口导出常量是不合适的使用，接口应当尽量减少细节泄露，常量应当由类保管。\n相较之下，抽象类的主要目的是 代码重用，本质是不能实例化的类。\n 重点有两个——抽象类和接口的本质、目的都不同。\n本质 抽象类本质是类，因此不能多继承。C++ 允许多继承而 Java 不允许，这体现两者多态思想上的差别。我们知道 Java 继承其实叫 extends ，严格来讲不叫“继承”，因为在 Java 中，继承首先是一种 is-a 关系，即 Student 要继承 Person ，首先要满足 “Student is a Person” 。这很好理解，按照里氏替换原则 (Liskov Substitution)，进行继承关系抽象时，凡是可以用父类或者基类的地方，都可以用子类进行替换。因此这显然不是中文里面继承的语义，因为中文里“儿子继承父亲”，但儿子不可能是父亲，两者有本质区别。\n然后，Java 为什么只允许单继承就很好理解了。如果我想让 A 同时继承 B 和 C，那说明 A is B, A is C，那 B 和 C 之间自然应当满足某种继承关系，三者应当是一个继承链的关系而非继承树的关系，通过单继承也可以表示清楚，并不需要让 A 同时继承 B 和 C。更不用说 C++ 为了实现多继承，其实也带来菱形继承问题，可能造成内存浪费和数据冗余。\n C++中因为允许多继承，可能会因为菱形继承造成内存浪费和数据冗余（如两个类BC分别继承同一基类A，再从这两个类派生出一个类D时会有冗余成员），因此最好使用虚继承。虚继承下，D实例内存地址中，BC虚继承来的A部分会通过一个指针分别指向一张虚基表（准确来讲是指向其中的虚基表偏移指针的存储地址，然后通过该指针取出偏移量），从虚基表中取出从基类A虚继承来成员在D内存中的偏移地址。\n 曾看到有博客认为 C++ 多继承机制较为合理，给出的理由是“人可以有父母，那类也应当可以多继承”。结合前文内容，这个理由显然没有什么道理，但是我认为却很好地反映了 Java 中接口的思想。我们知道，对于生物而言，父和母显然是不等价的，母完成了作为母的职责，父完成了作为父的职责，然后才有“子”，因此与其类比为继承，不如类比为接口实现更妥当，因为父、母实际上在这里归根结底是行为的抽象，父类必须实现接口 CanBeFather，母类必须实现接口 CanBeMother，这是一种行为关系。这一接口在使用过程中屏蔽了其它底层细节，无论父母是什么学历、有什么资产，这一过程中都不关注，也没有影响，这便是类功能上的解耦，通过一个用来将行为抽象化的接口完成了。\n目的 目的上面其实也说了，《Effective Java》总结的很到位，接口是对行为的抽象，达到 API 定义与实现分类 的目的。如果一个类可以有多个行为、实现多个功能，那它当然可以实现多个接口。\n而抽象类更多还是用来减少冗余代码，换句话说——提高代码质量、提高可读性、降低维护难度……\n Java 继承与里氏替换原则 Java中子类重写父类方法时不能抛出父类中没有抛出的异常，编译会不过，不抛是完全可以的。同时，该方法在子类中的访问级别也不能低于超类中的访问级别。这两项规则确保可使用超类实例的地方也能使用子类实例，符合里氏替换原则。\n 变量只能被隐藏（静态及非静态），不能被覆盖 静态方法只能被隐藏，不能覆盖 静态方法只能用静态方法隐藏，非静态方法只能用非静态方法覆盖（否则编译不过） 最终方法不能覆盖。私有方法（private）实际会被隐式指定为 final ，所以同样不能覆盖。 抽象方法必须覆盖  同时要注意的是关于构造方法的内容\n 子类实例化对象时，如果子类构造方法没有显式调用父类构造方法，默认调用 super() 子类要使用父类有参构造方法，使用 super(...) 形式，且 super() 必须是子类构造方法中第一行语句 父类没有不带参构造方法，子类构造方法中必须显示调用父类其它构造方法，否则编译不过  ","date":"2021-06-02T20:04:58+01:30","image":"https://winterorch.github.io/images/feature/abyss/05.jpg","permalink":"https://winterorch.github.io/p/java-%E6%8E%A5%E5%8F%A3%E4%B8%8E%E6%8A%BD%E8%B1%A1%E7%B1%BB%E7%9A%84%E5%8C%BA%E5%88%AB/","title":"Java - 接口与抽象类的区别"},{"content":"网络层只把分组发送到目的主机，但是真正通信的并不是主机而是主机中的进程。传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。\n TCP 与 UDP 协议区别     连接 传输可靠性 传输形式 传输效率 所需资源 应用场景 首部字节     TCP 面向连接 可靠 字节流 低 多 要求数据可靠性 20 - 60   UDP 无连接 不可靠 数据报文段 高 少 要求通信效率 8     TCP（Transmission Control Protocol） TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。\n \n  序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。\n  确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。\n  数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。\n  确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。\n  同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。\n  终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。\n  窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。\n  一、TCP 三次握手和四次挥手 可靠，TCP 协议的设计都是为了可靠无误\n1.1 三次握手  TCP三次握手 \n 客户端–发送带有 SYN 标志的数据包–一次握手–服务端 服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端 客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端  为什么这么设计，可以从三次握手后双方获得的信息入手，对于发送方而言：\n    自己发送正常 自己接收正常 对方发送正常 对方接收正常     第一次 未知 未知 未知 未知   第二次 确认 确认 确认 确认   第三次 - - - -    对于接收方而言：\n    自己发送正常 自己接收正常 对方发送正常 对方接收正常     第一次 未知 确认 确认 未知   第二次 未知 - - 未知   第三次 确认 确认 确认 确认    要接收双方都能完整确认双方接收功能正常，三次握手缺一不可。\n 第2次握手传回了ACK，为什么还要传回SYN？\n接收端传回发送端所发送的ACK是为了告诉客户端，我接收到的信息确实就是你所发送的信号了，这表明从客户端到服务端的通信是正常的。而回传SYN则是为了建立并确认从服务端到客户端的通信。”\n  客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。\n 1.2 四次挥手  \n断开一个 TCP 连接则需要“四次挥手”：\n  客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送\n 客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态\n   服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加1 。和 SYN 一样，一个 FIN 将占用一个序号\n  服务器-关闭与客户端的连接，发送一个FIN给客户端\n TIME_WAIT\n客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：\n  确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。\n  等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。\n     客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加1\n      传达信息     A: FIN A：我没有数据要传了   B：ack B：我知道你没数据要传了   B：FIN B：我没有数据要传了   A：ack A：我知道你没数据要传了    二、TCP 如何保证可靠传输  **分块：**应用数据被分割成 TCP 认为最适合发送的数据块。 **有序：**TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 **去重：**TCP 的接收端会丢弃重复的数据。 流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制） 拥塞控制： 当网络拥塞时，减少数据的发送。 ARQ协议： 通过确认和超时机制实现可靠信息传输。 超时重传： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。  2.1 ARQ 自动重传请求（Automatic Repeat-reQuest，ARQ）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议。\n停止等待ARQ协议 每发完一个分组就停止发送，等待对方确认（回复ACK）。如果超时还没有收到 ACK 确认，需要重新发送，直到收到确认后再发下一个分组。若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。\n 优点： 简单 缺点： 信道利用率低，等待时间长  连续ARQ协议 连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。\n 优点： 信道利用率高，容易实现，即使确认丢失，也不必重传。 缺点： 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。  2.2 滑动窗口和流量控制 窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。\nTCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。\n2.3 拥塞控制 拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。\n为了进行拥塞控制，TCP 发送方要维持一个 拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接收窗口中较小的一个。\n TCP 窗口基于字节，但这里拥塞窗口的大小单位是报文段。\n TCP的拥塞控制采用了四种算法，即 慢开始 、 拥塞避免 、快重传 和 快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生。\n 当然，谈论拥塞控制的前提是不会发生流量控制，即接收方有足够大的接收缓存。\n  \n  慢开始： 为防止立即注入大量数据导致拥塞，先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍。\n 如果在慢开始阶段出现超时，将令 ssthresh = cwnd / 2 并重新执行慢开始\n   拥塞避免： 拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间RTT就把发送方的 cwnd 加 1。\n  快重传与快恢复： 在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定下一个报文段丢失，立即重传丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。\n例如收到三个 M2，则 M3丢失，立即重传 M3。\n 这种情况下，丢失个别报文段不认作网络拥塞，因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh ，此时直接进入拥塞避免。\n 当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。\n   慢开始和快恢复的快慢，指的是 cwnd 的起始值而非增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。\n  UDP（User Datagram Protocol） 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。\n \n首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。\n","date":"2021-06-02T00:00:00Z","image":"https://winterorch.github.io/images/feature/abyss/09.jpg","permalink":"https://winterorch.github.io/p/computer_network-transport_layer/","title":"计算机网络 - 传输层"},{"content":"剑指 Offer 59 - I. 滑动窗口的最大值 给定一个数组 nums 和滑动窗口的大小 k，请找出所有滑动窗口里的最大值。\n示例 1：\n 输入: nums = [1,3,-1,-3,5,3,6,7], 和 k = 3 输出: [3,3,5,5,6,7] 解释:\n滑动窗口的位置 最大值\n [1 3 -1] -3 5 3 6 7 3 1 [3 -1 -3] 5 3 6 7 3 1 3 [-1 -3 5] 3 6 7 5 1 3 -1 [-3 5 3] 6 7 5 1 3 -1 -3 [5 3 6] 7 6 1 3 -1 -3 5 [3 6 7] 7\n 提示：\n你可以假设 k 总是有效的，在输入数组不为空的情况下，1 ≤ k ≤ 输入数组的大小。\n 题解一 单调队列 要求滑动窗口内的最大值，首先想到的是双向队列，一边推窗一边保持最大元素在队首。由于要确保窗口长度，队列中存的是下标。\npublic int[] maxSlidingWindow(int[] nums, int k) { int[] res = new int[nums.length - k + 1]; Deque\u0026lt;Integer\u0026gt; deque = new ArrayDeque\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; nums.length; ++i) { if (!deque.isEmpty() \u0026amp;\u0026amp; deque.peekFirst() == i - k) { deque.removeFirst(); } while (!deque.isEmpty() \u0026amp;\u0026amp; nums[deque.peekLast()] \u0026lt; nums[i]) { deque.removeLast(); } deque.addLast(i); if (i \u0026gt;= k - 1) { res[i - k + 1] = nums[deque.peekFirst()]; } } return res; } 题解二 双向遍历 如果通过固定队列长度可以来限制搜索范围，通过双向遍历也可以。不依靠队列的话有个问题，最大值会不断传播，如果 [0] 处是数组最大值，这一最大值可以一直传播到队尾。那我们必须进行适当的划分，让最大值最远传播 k 个数字（包含自己）。\n我们直接将队列分成一段段长为 k 的区间，每一段区间中，第一次遍历取得前半段（[0.. i % k]）上的最大值。\nfor (int i = 0; i \u0026lt; n; ++i) { if (i % k == 0) { prefixMax[i] = nums[i]; } else { prefixMax[i] = Math.max(prefixMax[i - 1], nums[i]); } } 然后从后向前进行一次遍历，取得后半段（[i % k .. k - 1]）上的最大值。\nfor (int i = n - 1; i \u0026gt;= 0; --i) { if (i == n - 1 || (i + 1) % k == 0) { suffixMax[i] = nums[i]; } else { suffixMax[i] = Math.max(suffixMax[i + 1], nums[i]); } } 然后，我们要取以 i 为起点长度为 k 的窗口的最大值，实际要取的就是当前区间上 [i % k .. k - 1] 上的最大值，和下一区间 [0 .. (i - 1 + k) % k] 上的最大值。\n完整答案\npublic int[] maxSlidingWindow(int[] nums, int k) { int n = nums.length; if (n == 0) { return new int[0]; } int[] prefixMax = new int[n]; int[] suffixMax = new int[n]; for (int i = 0; i \u0026lt; n; ++i) { if (i % k == 0) { prefixMax[i] = nums[i]; } else { prefixMax[i] = Math.max(prefixMax[i - 1], nums[i]); } } for (int i = n - 1; i \u0026gt;= 0; --i) { if (i == n - 1 || (i + 1) % k == 0) { suffixMax[i] = nums[i]; } else { suffixMax[i] = Math.max(suffixMax[i + 1], nums[i]); } } int[] ans = new int[n - k + 1]; for (int i = 0; i \u0026lt;= n - k; ++i) { ans[i] = Math.max(suffixMax[i], prefixMax[i + k - 1]); } return ans; } ","date":"2021-06-01T00:00:00Z","image":"https://winterorch.github.io/images/category/leetcode/AfternoonTea.jpg","permalink":"https://winterorch.github.io/p/%E5%89%91%E6%8C%87-offer-59-i.-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E6%9C%80%E5%A4%A7%E5%80%BC/","title":"剑指 Offer 59 - I. 滑动窗口的最大值"},{"content":"常用端口及协议    应用 协议 端口号 传输层 备注     域名解析 DNS 53 UDP/TCP 长度超过 512 字节时使用 TCP   动态主机配置协议 DHCP 67/68 UDP    简单网络管理协议 SNMP 161/162 UDP    文件传送协议 FTP 20/21 TCP 控制连接 21，数据连接 20   远程终端协议 TELNET 23 TCP    超文本传送协议 HTTP 80 TCP    简单邮件传送协议 SMTP 25 TCP    邮件读取协议 POP3 110 TCP    网际报文存取协议 IMAP 143 TCP    超文本传送协议 HTTPS 443 TCP      域名系统 DNS ( Domain Name System ) 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。\n域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。\n DNS分层 \nDNS 使用 UDP/TCP DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这样 DNS 服务器负载更低，响应更快，不过这要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。一般在两种情况下会使用 TCP 进行传输：\n  如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）\n  区域传送\n辅域名服务器会定时（一般三小时）向主域名服务器查询变动，如有变动则需要区域传送来同步数据，这一过程数据量很大，且对可靠性有一定要求，因此使用 TCP\n  有一种比较少见的情况——客户端可以指定向 DNS 服务器查询时用 TCP，但很多 DNS 服务器都配置为仅支持 UDP 查询。\nDNS 缓存 DNS 有多级缓存，按离浏览器距离，有浏览器缓存、系统缓存、路由器缓存、IPS服务器缓存、根域名服务器缓存、顶级域名服务器缓存、主域名服务器缓存。\n 文件传送协议 FTP ( File Transfer Protocol ) 使用 TCP 进行连接，它需要两个连接来传送一个文件：\n 控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。 数据连接：用来传送一个文件数据。  根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：\n 主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。   主动模式 \n 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。   被动模式 \n主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。\n 动态主机配置协议 自动配置 IP 地址等信息，DHCP ( Dynamic Host Configuration Protocol ) 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。\nDHCP 工作过程如下：\n 客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。 DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。 DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。   DHCP \n 远程登录协议 TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。\nTELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。\n 电子邮件协议 一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。\n邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。\n \n  SMTP\nSMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。\n   \n POP3\nPOP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。但最新版本的 POP3 可以不删除邮件。\n  IMAP\nIMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。\n   HTTP / HTTPS 状态码：\n    类别 原因     1XX Informational（信息性） 接收的请求正在处理   2XX Success（成功） 请求正常处理完毕   3XX Redirection（重定向） 需要进行附加操作以完成请求   4XX Client Error（客户端错误） 服务器无法处理请求   5XX Server Error（服务器错误） 服务器处理请求出错    HTTP/1.1 起默认使用长连接，用以保持连接特性，并支持请求的流水线 (Pipelining) 处理。实现长连接需要客户端和服务端都支持长连接。使用长连接的 HTTP 协议会在响应头加入这行代码：\nConnection:keep-alive 网页打开后，客户端与服务器间用于传输 HTTP 数据的 TCP 连接不会关闭，再次访问服务器时会继续使用。连接的保持时间由服务器设定。\n HTTP 本身是无状态协议，因此 Session 机制通过服务端记录用户状态。服务端为特定用户创建特定 Session 后用以标识和跟踪用户。\n大部分情况下，服务端通过在 Cookie 中附加 Session ID 来跟踪，并将 Session 存在缓存或数据库中。如果 Cookie 被禁用，也可以利用 URL 重写附在 URL 路径后面。\n不过诸如 Spring Security 等安全框架中采用 Token 认证，服务器通过Payload、Header和一个密钥(secret)创建令牌（Token）并将 Token 发送给客户端，客户端将 Token 保存在 Cookie 或者 localStorage 里面，以后客户端发出的所有请求都会携带这个令牌。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP Header 的 Authorization字段中： Authorization: Bearer Token。\n  扩展：HTTP 协议的优化\n参考阅读材料： https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A?\nHTTP1.1 引入了更多缓存控制策略，并允许对某个资源的部分请求，新增了 24 个错误状态响应码，请求和响应消息都支持 Host 头域（这使得多个主机可以共享一个IP，一台物理服务器从而可以存在多个虚拟主机），最重要的——支持了长连接和请求的流水线处理\n2012年 Google 提出 SPDY 方案，通过多路复用 (Multiplexing) 提高 TCP 连接利用率（因为浏览器一般对同一域名有最大连接数限制），为每个 Request 设置优先级（展示内容可以优先加载，优化了用户体验），加了首部压缩协议，并强制使用 HTTPS 保障安全，服务端也可以主动推动（例如客户端请求 style.css 文件时，服务端可以将相关的 style.js 也推送过去）。\nSPDY位于HTTP之下，TCP和SSL之上，这样可以轻松兼容老版本的HTTP协议(将HTTP1.x的内容封装成一种新的frame格式)，同时可以使用已有的SSL功能。\n HTTPS 运行在 SSL/TLS 上，而 SSL/TLS 运行在 TCP 上，所有传输内容都经过对称加密，对称密钥用服务器方的证书进行了非对称加密。因此 HTTPS 消耗服务器资源比 HTTP 多。\nCA ( Certification Authority ) 负责签发证书，并且能够验证域名所属——通过 DNS 记录或指定 URI 下放置的特殊文件供 CA 通过外网访问。\n 如果网站证书被 CA 私自发给了第三方，那第三方就能够利用证书实施中间人攻击了，因此 CA 信用非常重要。\n  Web 页面请求过程 也算是比较常见的面试题吧\n DHCP 配置主机信息    假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。\n  主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。\n  该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。\n  该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:FF，将广播到与交换机连接的所有设备。\n  连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。\n  该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。\n  主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。\n  ARP 解析 MAC 地址    主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。\n  主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。\n  该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。\n  该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。\n  DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。\n  主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。\n  网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。\n  DNS 解析域名    知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。\n  网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。\n  因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。\n  到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。\n  找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。\n  HTTP 请求页面 (TCP、HTTP)    有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。\n  在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。\n  HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。\n  连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。\n  HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。\n  浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。\n  ","date":"2021-05-31T00:00:00Z","image":"https://winterorch.github.io/images/feature/abyss/10.jpg","permalink":"https://winterorch.github.io/p/computer_network-application_layer/","title":"计算机网络 - 应用层"},{"content":"语法 抽象类中可以存在\n 构造方法 抽象方法 非抽象方法 成员变量 静态成员变量  总结：除了不能被实例化，抽象类几乎具有普通类的所有特性。\n 注意点   抽象类不能被实例化，如果试图实例化抽象类，编译无法通过\n  抽象类中可以有构造方法，但是构造方法不能为抽象方法，其中原因见 [为什么构造函数不能为抽象]\n 抽象类及其实现的构造方法也必须遵循一般继承中的构造方法规范，包括：\n 子类实例化对象时，如果子类构造方法没有显式调用父类构造方法，默认调用 super() 子类要使用父类有参构造方法，使用 super(...) 形式，且 super() 必须是子类构造方法中第一行语句 父类没有不带参构造方法（只定义了有参构造方法而没有定义无参的），子类构造方法中必须显示调用父类其它构造方法，否则编译不过     抽象类中的静态方法也不能为抽象方法\n  抽象类中的抽象方法只能声明，不能有具体实现，这与接口不同（接口方法在 JDK 1.8 后也可以有默认实现），具体原因见 [为什么抽象方法不能有实现而接口方法可以]\n   有端联想 抽象类总结了几个比较有嚼劲的问题\n1. 为什么构造函数不能为抽象 Java 抽象函数 和 C++ 虚函数 是等价概念，因此这里直接从 C++ 的角度找答案了。结论就是——构造函数从语言和逻辑来看都不能为虚函数。\n  从内存结构角度来看\n虚函数对应虚函数表 vtable ，表为类所有，但虚函数表指针为每个对象所有，在构造函数运行时进行空间分配，因此构造函数无法在未创建虚表指针的情况下调用虚表。\n  从语言逻辑角度来看\n构造函数目的是初始化实例，我们知道抽象类和虚基类都没有实例化的需求，将构造函数定义为虚函数是没有意义的。\n可以先回顾一下虚函数的作用过程——通过指针或者引用来调用虚函数的时候能够调用到子类的对应成员函数。而构造函数是在创建对象时自动调用的，调用这一函数的指针或引用所对应的对象还不存在，也就决定了构造函数不能是虚函数。\n  2. 为什么抽象方法不能有实现而接口方法可以 JDK 1.8 以前两者都不能有实现，这对接口的实现造成了一些麻烦，因为很多时候我们希望接口方法能有一些默认实现，从而减少其实现类中的重复代码；更多的时候，我们实现接口也并不需要用到其中所有方法，但没有默认实现导致我们不得不在实现一个接口时实现其中所有方法（因此出现了很多用于适配接口与实现类的 Adapter 类），哪怕根本不会用到。综上，JDK 1.8 以后接口也可以有默认实现了。\n 这其实让我联想到数据库设计范式对数据库粒度的苛求。按照规范来说，如果有类在实现接口过程中存在用不到的方法，那说明接口的粒度仍不够小——对行为的定义不够细，但从另一方面来讲，追求完美的接口粒度又会使代码晦涩难懂，且不够灵活。\n 但是抽象类中从一开始就不存在这个问题——因为抽象类并不只能包含抽象方法，还能包含普通方法，而 Java 中普通方法本身就是“虚函数”，允许子类重写。那么如果想要一个默认实现，直接写普通方法就行了。Java 语言设计抽象类的目的本就是方便代码重用，但在设计接口之初并没有把这一需求囊括进来。\n而抽象方法，仅用于标识子类必须实现的方法（有一种特殊情况除外，就是子类也是抽象类）。\n","date":"2021-05-30T00:00:00Z","image":"https://winterorch.github.io/images/feature/arknights/Penguin.jpg","permalink":"https://winterorch.github.io/p/java-%E6%8A%BD%E8%B1%A1%E7%B1%BB/","title":"Java - 抽象类"},{"content":"LeetCode 354. Russian Doll Envelopes You have a number of envelopes with widths and heights given as a pair of integers (w, h). One envelope can fit into another if and only if both the width and height of one envelope is greater than the width and height of the other envelope.\nWhat is the maximum number of envelopes can you Russian doll? (put one inside other)\nExample: Given envelopes = [[5,4],[6,4],[6,7],[2,3]], the maximum number of envelopes you can Russian doll is 3 ([2,3] =\u0026gt; [5,4] =\u0026gt; [6,7]).\n 大信封装小信封，为了方便DP，先进行排序，按宽度升序。出现了问题，高度怎么排呢？如果是单纯的暴力DP，那两个循环，高度其实是无所谓的，满足宽度、高度都更大就行了，怎么排都可以，如下：\nclass Solution { public: int maxEnvelopes(vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;\u0026amp; envelopes) { int res = 0, n = envelopes.size(); vector\u0026lt;int\u0026gt; dp(n, 1); sort(envelopes.begin(), envelopes.end()); for (int i = 0; i \u0026lt; n; ++i) { for (int j = 0; j \u0026lt; i; ++j) { if (envelopes[i].first \u0026gt; envelopes[j].first \u0026amp;\u0026amp; envelopes[i].second \u0026gt; envelopes[j].second) { dp[i] = max(dp[i], dp[j] + 1); } } res = max(res, dp[i]); } return res; } }; 但是其实可以优化速度。首先知道，宽度相同的一组信封肯定只能用一张。那用那张呢？应该趋向于高度尽量小的那张，这样更可能套的上宽度更大的信封。\n因为宽度已经是升序了，我们实际上只需要用一个数组按升序保存所有高度就可以了（实际上是一个大顶堆）。那问题来了，万一有很多张同一宽度不同高度的信封那不是没法区分，会全被加进来了吗？很简单，我们排序的时候加一个规则——宽度相同的信封按高度降序排。这样，首先加进来的一定是同一宽度中最高的信封，同一宽度下后加的一定是比较短的信封，自然不可能把前面的装下，也就不会出现同一宽度加多次的情况。\n但前面说了，同一宽度下我们其实最希望用最短的那张，更短的我们是希望拿来把最外面那张替掉的。那么我们拿着这张更短信封的高度在数组（堆）中二分搜索，搜索的其实是第一个大于此高度的位置，然后把这个位置上的高度替掉。如果是能满足要求（比最外层小比次外层大），那自然可以把最外面这张替掉。\n这里可能有疑问，那万一替掉的不是最外层，把里面宽度更小的替掉了呢？这里用的DP方法确实存在这样的问题，数组里存储的并不是实际可行的一个套娃方案，但是我们的信封其实并不关心里面啊，最外面一个是对的就行了，加上我们的高度是降序排列的，替也只能往前面小的替，也就是往里层替，不会影响最外层，更不会影响我们最关心的问题——能套几层。所以这一方法是完全可行的，完整代码如下：\npublic class Leet354_RussianDollEnvelopes { public int maxEnvelopes(int[][] envelopes) { //虽然Java类库用起来简单，但还是会比写lambda慢一点  //Arrays.sort(envelopes, Comparator.comparingInt((int[] array) -\u0026gt; array[0])  // .thenComparing(array -\u0026gt; -array[1]));  Arrays.sort(envelopes, (e1, e2) -\u0026gt; { if (e1[0] != e2[0]) { // 宽度升序  return e1[0] - e2[0]; } else { // 高度降序  return e2[1] - e1[1]; } }); // 由于主序是宽度，只要关注高度就可以了  List\u0026lt;Integer\u0026gt; dp = new ArrayList\u0026lt;\u0026gt;(); for (int[] envelope : envelopes) { int left = 0, right = dp.size(), t = envelope[1]; while (left \u0026lt; right) { int mid = left + (right - left) / 2; if (dp.get(mid) \u0026lt; t) left = mid + 1; else right = mid; } if (right \u0026gt;= dp.size()) dp.add(t); else dp.set(right, t); } return dp.size(); } public static void main(String[] args) { int[][] env = {{2,100},{3,200},{4,300},{5,500},{5,400},{5,250},{6,370},{6,360},{7,380}}; Leet354_RussianDollEnvelopes ins = new Leet354_RussianDollEnvelopes(); System.out.println(ins.maxEnvelopes(env)); } } 这个其实就是Leet300用的方法。\n","date":"2021-05-20T00:00:00Z","image":"https://winterorch.github.io/images/category/leetcode/TeaParty.jpg","permalink":"https://winterorch.github.io/p/leetcode-354-%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/","title":"LeetCode 354 - 俄罗斯套娃信封问题"},{"content":"一、垃圾收集算法  下面这张图中存在 Permanent Space ，因此明显是基于 JDK 1.8 以前版本画的，在之后版本，元空间取代了永久代成为了 HotSpot 对方法区的实现\n  JDK1.8以前的Java堆分代 \n跟据 Object 生命周期分为三个层次\n Young Generation Old Generation Permanent Generation  Young Generation 包括 Eden 区和两个存活区（From 和 To），采用“停止-复制（Stop-and-copy）”清理法。大部分对象在 Eden 区域分配，一次新生代垃圾回收后如果对象还存活，则升1岁进入 s0 或 s1 ，清理 Eden 和使用过的一块 Survivor。\n HotSpot 虚拟机的 Eden 和 Survivor 大小比例默认为 8:1，保证内存利用率有 90%。\n Eden 区满时执行 Minor GC 清理可销毁对象，将不可销毁的迁移至其中一个存活区，而将另一个存活区直接清空，下一次 GC 时两个存活区角色交换，交换次数超过 15 （MaxTenuringThreshold）的进入 Old Generation。\n 复制算法（young代GC算法）\n该算法会将内存区域分为两个大小一样的区域。GC回收时，遍历当前使用区域，只将正在引用的对象复制到另一个区域，因此复制成本较低，且复制过程中还会进行内存整理，不会出现“碎片”问题。缺点就是：需要两个大小一样的内存区域和生命周期短的对象。所以该算法不适合大内存对象和长生命周期的对象，适用于young代的SO/S1\n  Hotspot 的动态年龄阈值\nHotspot遍历对象时按年龄从小到大对其所占用大小进行累积，当累积的某个年龄大小超过了 survivor 区一半，取年龄与 MaxTenuringThreshold 中更小的作为新年龄阈值\n Old Generation 通过“标记-整理”算法，标记处仍存活对象，并将所有存活对象向一端移动以保证内存连续，清理掉剩余部分内存。当进入的对象超过剩余空间大小，则触发 Full GC。“标记-整理”好处是不需要额外内存区域。\nPermanent Generation 主要存放字节码、字符串常量池、静态变量、可持久化数据等。每次发生 Full GC 时，同时也会销毁 Permanent Generation 中的可销毁对象。\n 永久代实际上是HotSpot JVM对JVM方法区的实现。由于永久代内存经常不够或发生内存泄露，造成OOM(PermGen)，从JDK8开始废弃了永久代，替换为了本地内存(native memory) 中的 Metaspace。\n 元空间与永久代最大区别在于它不在虚拟机中，而是使用本地内存。两者都是对JVM规范中方法区的实现，用于存储类的信息、常量池、方法数据、方法代码等。\n 字符串常量从JDK1.7开始由永久代转移到堆中(Java heap space)\n  永久代的变动 \n 二、经典垃圾收集器  HotSpot中的垃圾收集器 \n HotSpot 中的安全点一般设置在方法调用、循环跳转、异常跳转等地方，只在安全点位置建立根节点枚举，强制到大安全点后才暂停，进行垃圾收集。\n HotSpot 中有7个垃圾收集器，连线表示可以配合使用。\n  Serial 串行的单线程收集器，简单高效。在 Client 场景下为默认 Young Generation 收集器，单线程收集效率高。Server 场景用于和 Parallel Scavenge 搭配使用。\n  ParNew Serial 的多线程版本。在 Server 场景下为默认 Young Generation 收集器，可以与 CMS 配合使用。\n  Parallel Scavenge 多线程。以“吞吐量”为优先考虑，即 CPU 运行用户代码的时间占总时间比值最高，CPU 用于垃圾回收的时间占总时间比值最低，而非其它垃圾收集器“尽可能缩短垃圾收集时用户线程的停顿时间”的目标，垃圾回收较为频繁。\nCPU效率更高，也适合后台运算任务，不适合对停顿和响应敏感的交互式程序。\nJVM中有配置以打开 GC 中新生代大小、Eden、S区自适应调节策略。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。\n  Serial Old 收集器  \nSerial 收集器的老年代版本，也是给 Client 场景下的虚拟机使用。如果用在 Server 场景下，它有两大用途：\n 在 JDK 1.5 以及之前版本（Parallel Old 诞生以前）中与 Parallel Scavenge 收集器搭配使用。 作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。    Parallel Old 收集器  \n是 Parallel Scavenge 收集器的老年代版本。\n在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。\n  CMS  \nCMS（Concurrent Mark Sweep），Mark Sweep 指的是标记 - 清除算法。\n分为以下四个流程：\n 初始标记：仅仅只是标记一下 GC Roots 能直接关联（一级连接，不遍历）到的对象，同时遍历新生代可直达地老年对象，速度很快，需要停顿。 并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。 并发清除： 清理删除掉标记阶段判断已经死亡的对象，不需要停顿。  在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。\n具有以下缺点：\n 吞吐量低：对处理器资源敏感，低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。因此 CMS 适用于四核以上的处理器。 无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。 标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。    G1 G1（Garbage-First），它是一款面向服务端应用的垃圾收集器，在多 CPU 和大内存的场景下有很好的性能。HotSpot 开发团队赋予它的使命是未来可以替换掉 CMS 收集器。\n堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或者老年代，而 G1 可以直接对新生代和老年代一起回收。\n img \nG1 把堆划分成多个大小相等的独立区域（Region），新生代和老年代不再物理隔离。 img \n通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。\n每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。\n 但是这样设计也存在副作用，region 大小固定为 1MB 到 32 MB 间的 2的幂值数，尽量能划 2048 个左右同等大小的 region 。\n    因为大小固定，和大对象很难保证一致，容易造成空间浪费，也很容易令大对象很难找到连续空间存放。\n  img \n如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤：\n 初始标记：短暂停顿线程以标记 GC Roots 直接关联到的对象，并修改 TAMS (Next Top at Mark Start) 值，让下一并发阶段能在正确 Region 中创建新对象。 并发标记：从 GC Roots 开始对堆对象进行可达性分析，递归扫描堆中的对象图，找出存活的对象，耗时长，但可以并发执行。 最终标记：为了修正在并发标记阶段遗留的因用户程序继续运作而导致变动的标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要短暂停顿线程，但是可并行执行。 筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。  具备如下特点：\n 空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。 可预测的停顿：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。   除经典垃圾收集器外还有 Shenandoah 收集器（CAS并发）、ZGC 收集器（通过染色体指针减少GC中内存屏障的使用）等低延迟垃圾收集器，见以下博客\nhttps://blog.csdn.net/qq_31709249/article/details/106711606\n  三、内存分配与回收策略 Minor GC 和 Full GC\n Minor GC：回收新生代，因为新生代对象存活时间很短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快。 Full GC：回收老年代和新生代，老年代对象其存活时间长，因此 Full GC 很少执行，执行速度会比 Minor GC 慢很多。  内存分配策略 1. 对象优先在 Eden 分配 大多数情况下，对象在新生代 Eden 上分配，当 Eden 空间不够时，发起 Minor GC。\n  -Xmx： 最大堆大小 -Xms： 最小堆大小 -Xmn： 年轻代堆大小 -XXSurvivorRatio： 年轻代中Eden区与Survivor区的大小比值   2. 大对象直接进入老年代 大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。\n经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。\n -XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 和 Survivor 之间的大量内存复制。\n 3. 长期存活的对象进入老年代 为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。\n -XX:MaxTenuringThreshold 用来定义对象进入老年期的年龄阈值。\n 4. 动态对象年龄判定 虚拟机并不是永远要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。\n5. 空间分配担保 在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。\n如果不成立的话虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 的值不允许冒险，那么就要进行一次 Full GC。\n JDK 6 Update 24 后，如果老年代连续空间大于新生代对象总大小或历次晋升的平均大小，则直接 Minor GC，否则 Full GC。\n Full GC 的触发条件 对于 Minor GC，其触发条件非常简单，当 Eden 空间满时，就将触发一次 Minor GC。而 Full GC 则相对复杂，有以下条件：\n  调用 System.gc()\n只是建议虚拟机执行 Full GC，但是虚拟机不一定真正去执行。不建议使用这种方式，而是让虚拟机管理内存。\n  老年代空间不足\n老年代空间不足的常见场景为前文所讲的大对象直接进入老年代、长期存活的对象进入老年代等。\n为了避免以上原因引起的 Full GC，应当尽量不要创建过大的对象以及数组。除此之外，可以通过 -Xmn 虚拟机参数调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。还可以通过 -XX:MaxTenuringThreshold 调大对象进入老年代的年龄，让对象在新生代多存活一段时间。\n  空间分配担保失败\n使用复制算法的 Minor GC 需要老年代的内存空间作担保，如果担保失败会执行一次 Full GC。具体内容请参考上面的第 5 小节。\n  JDK 1.7 及以前的永久代空间不足\n在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些 Class 的信息、常量、静态变量等数据。\n当系统中要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么虚拟机会抛出 java.lang.OutOfMemoryError。\n为避免以上原因引起的 Full GC，可采用的方法为增大永久代空间或转为使用 CMS GC。\n  Concurrent Mode Failure\n执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足），便会报 Concurrent Mode Failure 错误，并触发 Full GC。\n   四、可销毁对象  Java 虚拟机不使用引用计数算法，因为两个对象如果循环引用，则引用计数器永远无法为 0。\n 可达性分析  可达树 \n根搜索方法，将所有 Java 对象构成“搜索树”结构，有一个根节点 root，每次从根节点触发进行搜索，遍历完后，不存在的变量成为可销毁对象。\nroot 包括所有正在运行线程栈上的引用变量、所有全局变量、所有 ClassLoader 。\n类的卸载 类卸载必须满足很多条件，最基本的有：所有实例都被回收；ClassLoader已被回收；对应的Class对象没有在任何地方被引用。\n 8u40 以后 G1 增加并默认开启 ClassUnloadingWithConcurrentMark ，在并发标记阶段结束后，JVM 直接进行类卸载。\n ","date":"2021-03-17T00:00:00Z","image":"https://winterorch.github.io/images/feature/lastofus/gamersky_04origin_07_2016715154B35.jpg","permalink":"https://winterorch.github.io/p/java-jvm-ram_and_gc/","title":"Java - JVM GC"}]