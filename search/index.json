[{"content":"NIO 与 AIO 模型 NIO（一般用同步非阻塞模式，如果阻塞就是 BIO 了）：服务器实现模式为一个请求一个线程，客户端发送连接请求全部注册到多路复用器上，多路复用器轮询到连接有 I/O 请求时才启动一个线程进行处理（解决了连接多而 I/O 少时资源占用问题）。\n\rNIO模型\r\nAIO（异步非阻塞）：服务器实现模式为一个有效请求一个线程，客户端I/O请求由OS先完成再通知服务器应用启动线程进行处理。\n那么，为什么 Netty 选择 NIO 模型呢？\n 由于 UNIX 系统上 AIO 不成熟，底层仍然使用 EPOLL，没有很好实现 AIO，且 JDK 加了一层封装，因此实际速度并不比 NIO (epoll) 快。\nNetty 整体架构为 Reactor 模型，AIO 为 Proactor 模型，整合起来复杂且冗余度高。\nAIO 接收数据需要预分配内存，NIO 接收时才分配。AIO 对连接数量高但流量小的情况内存浪费大。\n Netty常见应用场景   作为 RPC 框架的网络通信工具\n分布式系统不同服务节点之间相互调用需要 RPC 框架\n  实现简单的 HTTP 服务器\n  实现即时通讯系统\n  实现消息推动系统\n  扩展：Java NIO  Selector\n多路复用器 Selector 建立在非阻塞基础上。\n  Channel 被注册到 Selector 上，FileChannel 不支持非阻塞\nchannel.configureBlocking(false); // 注册 SelectionKey key = channel.register(selector, SelectionKey.OP_READ); 第二个参数表明感兴趣事件，通过掩码形式传入：\n  SelectionKey.OP_READ\n 对应 00000001，通道中有数据可以进行读取\n   SelectionKey.OP_WRITE\n 对应 00000100，可以往通道中写入数据\n   SelectionKey.OP_CONNECT\n 对应 00001000，成功建立 TCP 连接\n   SelectionKey.OP_ACCEPT\n 对应 00010000，接受 TCP 连接\n   如果要监听多个事件，指定多位即可\n  调用 select() 方法获取通道信息，用于判断是否又感兴趣事件发生\n  异步 IO\nJava 异步 IO 提供了返回 Future 实例和使用回调函数 CompletionHandler 两种方式。\n 扩展：Linux Epoll  Linux 下的 Epoll 实例（epfd 通过本地方法 epoll_create 创建）用文件描述符表示，程序中注册的 Socket Channel 都会放到 Selector（Epoll）内部的 channel 集合中。\nint epoll_create(int size); //\t创建epoll实例，返回文件描述符用于epoll接口后续调用 当多路复用器进行 select ，通过本地方法 epollCtl 将事件注册到 epfd 上进行监听。\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); //\t用文件描述符epfd引用的epoll实例，对目标文件描述符fd执行op操作 本地方法 epollWait 阻塞等待读写事件发生，如果发生则由 OS 通过中断程序调用回调函数放到 Epoll 内的就绪事件列表 rdlist 。因此如果 rdlist 中已经有了 socket 引用，epoll_wait 返回，如果为空则阻塞进程。\nEpoll Select Poll 三种底层机制的差异\nselect 基于对所有 channel 的轮询遍历，每次调用都进行线性遍历，时间复杂度 $O(n)$ ，由于在数组上实现，最大连接有上限。\npoll 同样是对 channel 进行轮询，但在链表上实现，最大连接无上限。\n以上两种方法的共同问题是——要直到哪几个通道准备好了，需要自己进行一次遍历。\nepoll 通过回调，底层用哈希表实现，每当有 IO 事件就绪，系统注册的回调函数被调用，时间复杂度 $O(1)$ 。\n  Netty 支持的三种 Reactor 线程模型 Reactor 单线程模型\n所有 I/O 操作在同一 NIO 线程上完成，NIO 线程有以下任务：\n 作为 Server ，接收 Client 的 TCP 连接 作为 Client ，向 Server 发起 TCP 连接 读取通信对端的请求或应答消息 向通信对端发送消息请求或应答消息  \r\n如上图所示，套接字分离、Accept 新连接、分派请求等全部由一个线程完成，对于小容量场景可行，但高负载下一定无法支撑，会造成大量消息积压、大量超时重发请求进一步拥塞系统资源，造成节点故障。\nReactor 多线程模型\nI/O 操作由一组 NIO 线程协作完成：\n 专门的 NIO 线程 —— Acceptor 用于监听 Server ，接收 Client 的 TCP 连接请求； 网络 I/O 操作——读、写等由一个 NIO 线程池负责，包含一个任务队列和 N 各可用线程，由这些 NIO 线程负责消息的读取、解码、编码和发送； 一个 NIO 线程处理多条连接，而一个连接只对应一个 NIO 线程，防止发生并发操作问题。  \r\n相比第一种模式，多线程模型已经极大减轻了 Reactor 线程的工作量，但是如果有百万数量的并发连接，而 Reactor 需要对握手信息进行安全认证，这则非常损耗性能。因此这一部分工作可以再分。\n主从 Reactor 多线程模型\n再将新创建 Channel 注册到线程池这一工作分离出来，交给“从 Reactor”做，主 Reactor 仅负责完成登录、握手、安全认证，一旦链路成功，将链路注册到给后端 从 Reactor 线程，由它分发到后续线程池进行 I/O 操作。通常，从 Reactor 个数可与 CPU 个数相同（实际上，如果我们在 Netty 起服务端的时候调用默认的无参构造方法 NioEventLoopGroup() 构造 workerGroup，会起 NettyRuntime.availableProcessors() * 2 ，也就是两倍 CPU 核数的线程，作为从 Reactor 线程池）。\n\r\n除上述三种之外，Netty NIO 的默认模式其实是在主从 Reactor 基础上去掉线程池，Netty中的Boss类充当mainReactor，NioWorker类充当subReactor（默认 NioWorker的个数是 Runtime.getRuntime().availableProcessors() ）。在处理新来的请求时，NioWorker读完已收到的数据到 ChannelBuffer 中，之后触发 ChannelPipeline 中的 ChannelHandler 流。\nNetty 是事件驱动的，可以通过 ChannelHandler 链来（ ChannelPipline ）控制执行流向。因为ChannelHandler 链的执行过程在 subReactor 中是同步的，所以如果业务处理 handler 耗时长，将严重影响可支持的并发数，例如涉及数据库操作或其它阻塞交互模块时这些问题就会被放大，必须回到第三种模型上，通过线程池化解决。 Netty内置的ChannelHandler实现类–ExecutionHandler可以满足，因为仍然是 Handler ，仍然可以加入到 Pipeline 中，对使用者来说只是添加一行代码而已。\n对于 ExecutionHandler 需要的线程池模型，Netty提供了两种可选： 1） MemoryAwareThreadPoolExecutor 可控制Executor中待处理任务的上限（超过上限时，后续进来的任务将被阻塞），并可控制单个Channel待处理任务的上限； 2） OrderedMemoryAwareThreadPoolExecutor 是 MemoryAwareThreadPoolExecutor 的子类，它还可以保证同一Channel中处理的事件流的顺序性，这主要是控制事件在异步处理模式下可能出现的错误的事件顺序，但它并不保证同一Channel中的事件都在一个线程中执行（通常也没必要）。一般来说，OrderedMemoryAwareThreadPoolExecutor 是个很不错的选择，当然，如果有额外需要，也可以自行实现。\n Netty 中会起多少线程 ServerBootstrap 启动时，通常 bossGroup 只需设置为 1，ServerSocketChannel 在初始化阶段也只会注册到一个 EventLoop 上，用不到多个线程。\n而 IO 线程，为了充分利用 CPU，减少线程上下文切换开销，通常设置为 CPU 核数的两倍（我们知道英特尔的超线程技术，逻辑线程的个数也通常是 CPU 核数的两倍，猜测都是出于利用 CPU 性能的考虑）。\n Netty 事件驱动机制  事件队列（event queue）接收事件入口，存储待处理事件 分发器（event mediator）将不同事件分发到不同业务逻辑单元 事件通道（event channel）为分发器与处理器之间的联系渠道 事件处理器（event processor）实现业务逻辑，处理完成后会发出事件，触发下一步操作  \r\nChannelPipeline是ChannelHandler的集合，类似拦截器概念，Channel作为网络操作的抽象类，是ChannelEvent的生产者，ChannelEvent是数据或状态的载体。\n\r\n所有事件都来自 ChannelEvent 接口，涵盖监听接口、建立连接、读写数据等网络通讯各个阶段。事件处理者为 ChannelHandler ，连接处理、协议编解码、超时等机制都通过 Handler 完成。\n这种响应模式就类似于 AWT 中的 Reactor Pattern。\n Netty 的无锁化串行理念 其实 Redis 也是这样，我们知道并行处理可以提升并发性能，但是如果访问处理不当会带来严重的锁竞争，轻者带来部分效率损耗，重者整体性能下降。串行化设计，即消息的处理在同一线程内完成，期间不进行线程切换，避免竞争和同步锁。这对于 Redis、Netty 这样以简单高效为重的低层中间件非常有利。\n不同之处在于，Redis 单机下就是单线程的，而 Netty 本身默认就是多线程并行，只是每一 NioEventLoop 中通过 ChannelPipeline 处理消息，除非配置异步 Handler 否则不进行线程处理，从性能角度看是最优的。\n在实际使用中也要注意这一点，不要阻塞 EventLoop 。在耗时操作时，尽量使用 Future ，同时也尽量减少锁的使用。\n Netty 核心组件 \r\n这一部分主要介绍 Netty 中核心组件的功能，引用框中会补充一些实际使用中的调优技巧.\nEventLoopGroup 如图所示，两个 EventLoopGroup 实际上也就是两个线程池，Boss 仅负责接收连接，只需要一个线程，内部封装有一个Selector，Worker 负责具体 IO 处理，每个都有绑定的Selector。\nEventloopGroup 将为每个新创建的 Channel 分配一个 EventLoop 。每个 Channel 的整个生命周期内，所有操作都由相同的 Thread 执行。\n\rEventLoop\r\nChannel Channel 为 Netty 网络操作（读写等操作）抽象类，EventLoop 负责处理注册到其上的 Channel 的 I/O 操作，两个组件配合进行 I/O 操作。Channel 对 Java 原生的 ServerSocketChannel 和 SocketChannel 进行封装，得到了 NioServerSocketChannel 和 NioSocketChannel ，UDP 对应的是 NioDatagramChannel 。\nServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class)...... 如上图所示，channel 通过传一个 .class 对象给 Bootstrap ，很明显是工厂模式通过反射方式来创建实例，这一实例的实际实例化时机，也就是源码中 .newChannel() 调用，是在 Bootstrap 进行 bind(PORT) （对服务端而言）和 connect(HOST, PORT) （对客户端而言）时。\n 对于两个指定端点可以使用唯一 Channel ，在第一次创建后保存 Channel ，对同一 IP 地址下一次通信中复用而不需要重新建立。但这样做也需要保存不同 IP 的 Channel ，在初始化时可能存在一些并发问题，很多实际项目都有相应解决方法，https://mp.weixin.qq.com/s/JRsbK1Un2av9GKmJ8DK7IQ 介绍了一些解决方案。\n Handler handler 其实就是一种 AOP，负责接收到请求后的处理过程。通过 childHandler() 和 ChannelInitializer 可以指定多个 handler 组成 Pipeline ，类似拦截器概念，涉及 handler 的执行顺序。\nBootstrap 通过传入一个 ChannelInitializer 的实现类，在这个实现类中向 ChannelPipeline 中添加一系列 Handler ，这些 Handler 分别负责信息处理的某个环节。\n 以在 Netty 中进行 SSL 通信为例，首先加入的是 SslContext 实体提供的 Handler，用于进行加解密；然后需要加入一个 DelimiterBasedFrameDecoder ，这个编解码器通过分隔符拆分解决包尺寸过大造成的 TCP 粘包等问题；之后就是数据的编解码器，如 Netty 为 String 通信提供的 StringDecoder 和 StringEncoder ；最后便是我们业务自己的 Handler ，用于按业务逻辑处理消息。\n Future Future\u0026lt;V\u0026gt; 接口继承自 java.util.concurrent.Future\u0026lt;V\u0026gt; ，同样用于异步调用。增加了 sync() 和 await() 用于阻塞等待，还添加了 Listeners 用于任务结束后回调。\nPromise 接口继承自 Future ，实例内部是一个任务，其中的 setSuccess(V result) 和 setFailure(Throwable t) 会在执行任务的线程完成后调用。\n这一回调可能是 Listeners 回调函数进行（不一定是由线程自己执行，也可能是新线程或其他线程），也可能是从 await() 中返回。\n\r\n Netty 中的零拷贝 在 Bootstrap 配置参数的时候，使用 .option(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) 来指定一个池化的 Allocator，并且使用 ByteBuf buf = allocator.directBuffer() 来获取 Bytebuf。\nPooledByteBufAllocator 会帮你复用（无需 release，除非你后面还需要用到同一个 bytebuf）而不是每次都重新分配 ByteBuf。在IO操作中，分配直接内存而不是JVM的堆空间，避免了在发送数据时，从JVM到直接内存的拷贝过程，这也就是 Zero Copy 的含义。Java NIO 中也有 Zero Copy Buffer 技术。\n","date":"2021-07-02T00:00:00Z","image":"https://winterorch.github.io/images/feature/ArseniXC/Ikarus-256.jpg","permalink":"https://winterorch.github.io/p/netty_basic/","title":"Netty - 基础知识"},{"content":"题目：  小朋友 A 在和 ta 的小伙伴们玩传信息游戏，游戏规则如下：\n 有 n 名玩家，所有玩家编号分别为 0 ～ n-1，其中小朋友 A 的编号为 0 每个玩家都有固定的若干个可传信息的其他玩家（也可能没有）。传信息的关系是单向的（比如 A 可以向 B 传信息，但 B 不能向 A 传信息）。 每轮信息必须需要传递给另一个人，且信息可重复经过同一个人  给定总玩家数 n，以及按 [玩家编号,对应可传递玩家编号] 关系组成的二维数组 relation。返回信息从小 A (编号 0 ) 经过 k 轮传递到编号为 n-1 的小伙伴处的方案数；若不能到达，返回 0。\n 示例1：\n 示例 1：\n输入：n = 5, relation = [[0,2],[2,1],[3,4],[2,3],[1,4],[2,0],[0,4]], k = 3\n输出：3\n解释：信息从小 A 编号 0 处开始，经 3 轮传递，到达编号 4。共有 3 种方案，分别是 0-\u0026gt;2-\u0026gt;0-\u0026gt;4， 0-\u0026gt;2-\u0026gt;1-\u0026gt;4， 0-\u0026gt;2-\u0026gt;3-\u0026gt;4。\n 示例2：\n 输入：n = 3, relation = [[0,2],[2,1]], k = 2\n输出：0\n解释：信息不能从小 A 处经过 2 轮传递到编号 2\n leetcode链接：LCP 07. 传递信息\n题解： 思路1：dfs\n题目中的relation很容易抽象成有向图，而对于可行路径的查找也很自然地联想到使用深度优先搜索。主要步骤归纳如下：\n 有向图初始化  List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; edges; edges = new ArrayList\u0026lt;\u0026gt;(); for(int i = 0; i \u0026lt; n; i++){ edges.add(new ArrayList\u0026lt;\u0026gt;()); } for(int[] edge : relation){ edges.get(edge[0]).add(edge[1]); }  深度优先搜索  private void dfs(int cur, int steps){ if(steps == k){ if(cur == n - 1){ res++; //System.out.println(res);  } return; } List\u0026lt;Integer\u0026gt; l = edges.get(cur); for(int next : l){ dfs(next, steps + 1); } } public int numWays(int n, int[][] relation, int k) { ... dfs(0,0); } 合并后即可写出最终代码\nclass Solution { int res, n, k; List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; edges; public int numWays(int n, int[][] relation, int k) { res = 0; this.n = n; this.k = k; edges = new ArrayList\u0026lt;\u0026gt;(); for(int i = 0; i \u0026lt; n; i++){ edges.add(new ArrayList\u0026lt;\u0026gt;()); } for(int[] edge : relation){ edges.get(edge[0]).add(edge[1]); } dfs(0,0); return res; } private void dfs(int cur, int steps){ if(steps == k){ if(cur == n - 1){ res++; //System.out.println(res);  } return; } List\u0026lt;Integer\u0026gt; l = edges.get(cur); for(int next : l){ dfs(next, steps + 1); } } }  时间复杂度：O(n^k)。 空间复杂度：O(n+m+k)。  相应的bfs方法也可以解决本题，在此不再赘述\n但两者的时间复杂度显而易见地大，翻评论区却发现了一种更巧妙的方法——动态规划。\n思路2：动态规划\nclass Solution { public int numWays(int n, int[][] relation, int k) { int[][] dp = new int[k + 1][n]; dp[0][0] = 1; for(int i = 1; i \u0026lt; k; i++){ for(int[] edge : relation){ dp[i][edge[1]] += dp[i - 1][edge[0]]; } } return dp[k][n - 1]; } } 动态规划从代码入手更易于理解。dp数组用于存储 第i轮 中 每个小朋友 可达的方案数，其值为可以向 他 传递信息的小朋友 第i-1轮 可达方案数 的总和。第一层for循环用于遍历轮数，第二层for循环用于遍历边（信息传递的方向）——edge[1]即为该小朋友，edge[0]为可以向他传递信息的小朋友，思路理清后，代码也就呼之欲出了。\n","date":"2021-07-01T00:00:00Z","permalink":"https://winterorch.github.io/p/leetcode-lcp-07-%E4%BC%A0%E9%80%92%E4%BF%A1%E6%81%AF/","title":"LeetCode LCP 07 - 传递信息"},{"content":"以下示例代码部分源自 [小专栏] 剖析面试最常见问题之Redis .\ntype name\t#查看当前 key 的类型  String string 数据结构是简单的 key-value 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 简单动态字符串（simple dynamic string，SDS）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外,Redis 的 SDS API 是安全的，不会造成缓冲区溢出。\n 常用命令: set,get,strlen,exists,dect,incr,setex 等等 应用场景 ：大多数需要缓存的场景、需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等  127.0.0.1:6379\u0026gt; set key value #设置 key-value 类型的值 OK 127.0.0.1:6379\u0026gt; get key # 根据 key 获得对应的 value \u0026#34;value\u0026#34; 127.0.0.1:6379\u0026gt; exists key # 判断某个 key 是否存在 (integer) 1 127.0.0.1:6379\u0026gt; strlen key # 返回 key 所储存的字符串值的长度。 (integer) 5 127.0.0.1:6379\u0026gt; del key # 删除某个 key 对应的值 (integer) 1 127.0.0.1:6379\u0026gt; get key (nil) 作计数器用 （字符串的内容为整数的时候可以使用）\n127.0.0.1:6379\u0026gt; set number 1 OK 127.0.0.1:6379\u0026gt; incr number # 将 key 中储存的数字值增一 (integer) 2 127.0.0.1:6379\u0026gt; get number \u0026#34;2\u0026#34; 127.0.0.1:6379\u0026gt; decr number # 将 key 中储存的数字值减一 (integer) 1 127.0.0.1:6379\u0026gt; get number \u0026#34;1\u0026#34; 设置过期（通用） 127.0.0.1:6379\u0026gt; expire key 60 # 数据在 60s 后过期 (integer) 1 127.0.0.1:6379\u0026gt; setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire) OK 127.0.0.1:6379\u0026gt; ttl key # 查看数据还有多久过期 (integer) 56  List 链表 当列表中存储数据量较大，列表通过双向循环链表实现。可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。\n 常用命令: rpush,lpop,lpush,rpop,lrange、llen 等。 应用场景: 发布与订阅或者说消息队列、慢查询。  实现队列\n127.0.0.1:6379\u0026gt; rpush myList value1 # 向 list 的头部（右边）添加元素 (integer) 1 127.0.0.1:6379\u0026gt; rpush myList value2 value3 # 向list的头部（最右边）添加多个元素 (integer) 3 127.0.0.1:6379\u0026gt; lpop myList # 将 list的尾部(最左边)元素取出 \u0026#34;value1\u0026#34; 127.0.0.1:6379\u0026gt; lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end 1) \u0026#34;value2\u0026#34; 2) \u0026#34;value3\u0026#34; 127.0.0.1:6379\u0026gt; lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一 1) \u0026#34;value2\u0026#34; 2) \u0026#34;value3\u0026#34; 实现栈\n127.0.0.1:6379\u0026gt; rpush myList2 value1 value2 value3 (integer) 3 127.0.0.1:6379\u0026gt; rpop myList2 # 将 list的头部(最右边)元素取出 \u0026#34;value3\u0026#34; 通过 lrange 查看对应下标范围的列表元素：\n127.0.0.1:6379\u0026gt; rpush myList value1 value2 value3 (integer) 3 127.0.0.1:6379\u0026gt; lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 127.0.0.1:6379\u0026gt; lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 3) \u0026#34;value3\u0026#34; 通过 lrange 命令，你可以基于 list 实现分页查询，性能非常高！\n通过 llen 查看链表长度：\n127.0.0.1:6379\u0026gt; llen myList (integer) 3  ZipList 压缩列表 压缩列表本质是字节数组，可以包含任意多个元素，每个元素可以是字节数组或整数。\n编码\n zlbytes：字节长度，占4字节，因此ZipList最长 $2^{32} - 1$ 字节 zltail：为元素相对起始地址的偏移量，占4字节 zllen：列表元素数目，占2字节，当数目超过 $2^{16}-1$ 时字段无效，只能通过遍历获取数目 entryX：若干元素 zlend：结尾字节，0xFF   Hash 无序散列表 存储键值对。当数据量较小，使用ZipList存储，否则使用散列表(使用MurmurHash2作为哈希函数)。\n当负载因子大于1，触发扩容，将散列表扩大为2倍。当负载因子小于0.1，触发缩容，缩小为实际负载的2倍大小。\n 常用命令： hset,hmset,hexists,hget,hgetall,hkeys,hvals 等。 应用场景: 系统中对象数据的存储。  127.0.0.1:6379\u0026gt; hset userInfoKey name \u0026#34;guide\u0026#34; description \u0026#34;dev\u0026#34; age \u0026#34;24\u0026#34; OK 127.0.0.1:6379\u0026gt; hexists userInfoKey name # 查看 key 对应的 value中指定的字段是否存在。 (integer) 1 127.0.0.1:6379\u0026gt; hget userInfoKey name # 获取存储在哈希表中指定字段的值。 \u0026#34;guide\u0026#34; 127.0.0.1:6379\u0026gt; hget userInfoKey age \u0026#34;24\u0026#34; 127.0.0.1:6379\u0026gt; hgetall userInfoKey # 获取在哈希表中指定 key 的所有字段和值 1) \u0026#34;name\u0026#34; 2) \u0026#34;guide\u0026#34; 3) \u0026#34;description\u0026#34; 4) \u0026#34;dev\u0026#34; 5) \u0026#34;age\u0026#34; 6) \u0026#34;24\u0026#34; 127.0.0.1:6379\u0026gt; hkeys userInfoKey # 获取 key 列表 1) \u0026#34;name\u0026#34; 2) \u0026#34;description\u0026#34; 3) \u0026#34;age\u0026#34; 127.0.0.1:6379\u0026gt; hvals userInfoKey # 获取 value 列表 1) \u0026#34;guide\u0026#34; 2) \u0026#34;dev\u0026#34; 3) \u0026#34;24\u0026#34; 127.0.0.1:6379\u0026gt; hset userInfoKey name \u0026#34;GuideGeGe\u0026#34; # 修改某个字段对应的值 127.0.0.1:6379\u0026gt; hget userInfoKey name \u0026#34;GuideGeGe\u0026#34;  Set 无序集合 集合中的元素没有先后顺序，不允许重复数据。\n 常用命令： sadd,spop,smembers,sismember,scard,sinterstore,sunion 等。 应用场景: 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景  127.0.0.1:6379\u0026gt; sadd mySet value1 value2 # 添加元素进去 (integer) 2 127.0.0.1:6379\u0026gt; sadd mySet value1 # 不允许有重复元素 (integer) 0 127.0.0.1:6379\u0026gt; smembers mySet # 查看 set 中所有的元素 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 127.0.0.1:6379\u0026gt; scard mySet # 查看 set 的长度 (integer) 2 127.0.0.1:6379\u0026gt; sismember mySet value1 # 检查某个元素是否存在set 中，只能接收单个元素 (integer) 1 127.0.0.1:6379\u0026gt; sadd mySet2 value2 value3 (integer) 2 127.0.0.1:6379\u0026gt; sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中 (integer) 1 127.0.0.1:6379\u0026gt; smembers mySet3 1) \u0026#34;value2\u0026#34; 127.0.0.1:6379\u0026gt; sunion mySet mySet2 # 获取 mySet 和 mySet2 的并集并打印 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 3) \u0026#34;value3\u0026#34; 通过以下的案例可知Set是无序的\n127.0.0.1:6379\u0026gt; sadd myset 1 2 3 4 5 6 (integer) 6 127.0.0.1:6379\u0026gt; spop myset 3 1) \u0026#34;4\u0026#34; 2) \u0026#34;5\u0026#34; 3) \u0026#34;1\u0026#34;  SortedSet 有序集合 存储键值对，有序集合的值被称为分值(score)，必须为浮点数。SortedSet 是唯一既可以跟据成员访问，又可以跟据分值以及分值排列顺序访问元素的结构。有点像是 Java 中 HashMap 和 TreeSet 的结合体。\n 常用命令： zadd,zcard,zscore,zrange,zrevrange,zrem 等。 应用场景： 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。  127.0.0.1:6379\u0026gt; zadd myZset 3.0 value1 # 添加元素到 sorted set 中 3.0 为权重 (integer) 1 127.0.0.1:6379\u0026gt; zadd myZset 2.0 value2 1.0 value3 # 一次添加多个元素 (integer) 2 127.0.0.1:6379\u0026gt; zcard myZset # 查看 sorted set 中的元素数量 (integer) 3 127.0.0.1:6379\u0026gt; zscore myZset value1 # 查看某个 value 的权重 \u0026#34;3\u0026#34; 127.0.0.1:6379\u0026gt; zrange myZset 0 -1 # 顺序输出某个范围区间的元素，0 -1 表示输出所有元素 1) \u0026#34;value3\u0026#34; 2) \u0026#34;value2\u0026#34; 3) \u0026#34;value1\u0026#34; 127.0.0.1:6379\u0026gt; zrange myZset 0 1 # 顺序输出某个范围区间的元素，0 为 start 1 为 stop 1) \u0026#34;value3\u0026#34; 2) \u0026#34;value2\u0026#34; 127.0.0.1:6379\u0026gt; zrevrange myZset 0 1 # 逆序输出某个范围区间的元素，0 为 start 1 为 stop 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34;  bitmap 适用只需要一个 bit 位来表示某个元素对应值或者状态的情况，如是否签到、是否登录等 Java 中使用 bool 的场景，加之 bitmap 可以统计设为 1 的位的数量\n常用命令： setbit 、getbit 、bitcount、bitop\n# SETBIT 会返回之前位的值（默认是 0）这里会生成 7 个位 127.0.0.1:6379\u0026gt; setbit mykey 7 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit mykey 7 0 (integer) 1 127.0.0.1:6379\u0026gt; getbit mykey 7 (integer) 0 127.0.0.1:6379\u0026gt; setbit mykey 6 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit mykey 8 1 (integer) 0 # 通过 bitcount 统计被被设置为 1 的位的数量。 127.0.0.1:6379\u0026gt; bitcount mykey (integer) 2 用户 ID 经常可以被用来作 bitmap 上的 offset，从而可以轻松统计“\u0026hellip;的用户个数”。\n相应的，位操作 BITOP operation destkey key [key ...] ，支持 AND OR NOT XOR 四种操作中任意一种参数。\n初始化数据：\n127.0.0.1:6379\u0026gt; setbit 20210308 1 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit 20210308 2 1 (integer) 0 127.0.0.1:6379\u0026gt; setbit 20210309 1 1 (integer) 0 统计 20210308~20210309 总活跃用户数: 1\n127.0.0.1:6379\u0026gt; bitop and desk1 20210308 20210309 (integer) 1 127.0.0.1:6379\u0026gt; bitcount desk1 (integer) 1 统计 20210308~20210309 在线活跃用户数: 2\n127.0.0.1:6379\u0026gt; bitop or desk2 20210308 20210309 (integer) 1 127.0.0.1:6379\u0026gt; bitcount desk2 (integer) 2 实际上，如果需要统计日活、月活用户这种，Redis 有一个非常对口的数据结构——HyperLoglog，原理其实类似于布隆滤波器，也是一个哈希过滤器，有一定的误警率，因此一般用于统计日活用户数量之类对精确度没有很高要求的数据。\n 乐观锁  对应数据库中的 version 设计\n watch money\t#使用 watch 当作乐观锁操作 被监视数据，如果在事务对其执行操作前被其它线程修改，则在调用 exec 时会执行失败\nunwatch\t# 失败，乐观锁已经失效 watch money\t# 添加新的乐观锁  链接 你可以在《Redis设计与实现》的下述页码找到对应数据结构的常用命令：\n  string\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;P68 list\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;P71 hash\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;P74 set\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;P77 sorted set\u0026mdash;\u0026ndash;P81   ","date":"2021-06-30T00:00:00Z","image":"https://winterorch.github.io/images/feature/scenes/Street2.jpg","permalink":"https://winterorch.github.io/p/redis-%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"Redis - 常用数据类型"},{"content":"常见的内存数据库包括 Memcached 和 Redis。后者相较之下在 k/v 类型数据基础上提供了 list, set, zset, hash 等数据结构存储，并且可扩展性强，能够通过插件增加更多；同时具有容灾机制，支持数据持久化，也有原生集群模式，支持发布订阅模型、Lua 脚本、事务；并且支持更多编程语言，单线程模型更加高效。总而言之功能很强，应用很广。\n简要介绍 Redis 是用 C 开发的内存数据库，非关系型数据库，读写速度快，广泛应用于缓存，也可以做分布式锁、消息队列。\n Redis6.0 之前都是单线程处理，仅在4.0增加了对大键值对删除操作的“异步处理” 服务器内存使用完之后，将不用的数据存到磁盘上 过期数据的删除策略包括惰性删除与定期删除  缓存的作用\n访问数据库从硬盘中读取，过程较慢。如果用户访问数据为高频数据且不会经常改变，则可以存在缓存中，速度快。\n 删除策略和内存淘汰机制   惰性删除\n只在取出 key 的时候才对数据进行过期检查。CPU负担小，但会残留很多过期 key\n  定期删除\n周期性取一批 key 执行删除过期 key 操作，通过限制删除操作执行时长和频率来减少删除操作对 CPU 影响\n  删除策略并不能清理所有过期 key ，过期 key 还需要内存淘汰机制解决。\n除了缓解内存消耗，设置过期时间也可以用于满足业务需要，比如验证码、登录Token的有效时间。\n内存淘汰机制跟据从中挑选淘汰数据的数据集不同，分为三大类：\n  从已设置过期时间的数据集中 volatile\n  volatile-lru (least recently used)\n移除最近最少使用的 key\n  volatile-ttl\n移除将要过期的数据\n  volatile-random\n移除随机选择的数据\n  volatile-lfu\n(4.0新增) 移除最不经常使用的数据\n    从**数据集（所有）**中 allkeys\n  allkeys-lru (least recently used)\n移除最近最少使用的 key\n  allkeys-random\n移除随机选择的数据\n  allkeys-lfu (least frequently used)\n(4.0新增) 移除最不经常使用的 key\n    不进行数据淘汰 no\n  no-eviction\n内存不足以容纳新写入数据就直接报错\n    \rredisDB表结构\r\n如图所示，Redis通过一个过期字典（类似HashTable）来保存数据过期时间，对应内存淘汰机制中 server.db[i].expires 。\n 持久化机制 为了保证Redis挂掉后再重启数据可以进行恢复，需要将内存数据写入硬盘。两种持久化机制分别是快照 (snapshotting, RDB) 和只追加文件 (append-only file, AOF) 。\nRDB 记录的是内存快照，AOF 记录的是执行过的所有命令。\n快照持久化是 Redis 默认采用的持久化方式，可以将快照复制到其他服务器从而创建具相同数据的服务器副本，在 Redis.conf 配置文件中默认有此下配置：\nsave 900 1 #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 save 300 10 #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 save 60 10000 #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 # 大部分情况下，15分钟够用，只保留这一条即可 RDB提供了三种机制\n save 命令将阻塞服务器主线程直到 RDB 完成 （不推荐） bgsave 命令 fork() 一个子线程在后台异步进行快照操作，同样会阻塞，但只发生在 fork() 阶段，时间较短。RDB 快照持久化期间父进程修改的数据不会被保存。 自动，通过配置完成  AOF 持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启：\nappendonly yes 开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 appendonly.aof。\n在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：\nappendfsync always #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度 appendfsync everysec #每秒钟同步一次，显示地将多个写命令同步到硬盘 appendfsync no #让操作系统决定何时进行同步 appendfsync everysec 比较好\n优点：写入性能非常高；即时日志文件过大出现后台重写也不会影响客户端读写（fork()新线程进行重写）；记录方式可读，适合用作紧急恢复\n缺点：日志文件更大，且会带来持续IO，对QPS影响更大\n总结\nRedis 重启时优先载入 AOF，因为 AOF 数据集一般更加完整，但 RDB 更适合用于备份数据库，快速重启，且没有 AOF 潜在 BUG\n Redis事务 关系型数据库的事务具备四大特性（ACID），合起来就是：\n  原子性\n确保都成功或都失败\n Redis 不具备原子性，因为不支持回滚，当然这也带来部分性能提升和开发便捷性\n   隔离性\n并发访问时，单用户事务不被其他事务所干扰，防止数据损坏\n Redis 不具备隔离级别概念，命令在事务中没有被直接执行。只有发起执行命令时才会执行。\n   持久性\n事务一旦提交，对数据库中数据的改变是持久的，被持久化写到存储器中，不会被系统其它问题改变\n Redis 同样不具备，但是当 AOF 持久化模式下，并且 appendfsync 选项值为 always 时，事务具有耐久性\n   一致性\n执行事务前后数据保持一致，多个事务对同一数据读取的结果相同\n  Redis 事务实际提供了将多个命令请求打包功能，再按顺序执行打包的所有命令，且不会被中途打断。具备 一次性、顺序性、排他性，分以下两种情况：\n 编译型异常中\n当命令出现错误，后续命令依旧可以添加到命令队列中，但所有命令都不会被执行\n  运行时异常中\n当命令出现错误，其它命令可以正常执行，只有错误命令抛出异常\n  缓存穿透攻击 黑客制造大量不存在 key 的请求，导致请求直接落到数据库进行查询，没有经过缓存层。\n要解决这一问题，最基本是要做好参数校验，不合法的参数直接抛异常给客户端。\n  缓存无效的 key\n即时返回的空对象也将其缓存起来，同时设置过期时间\n但在 key 变化频繁的情况下，尤其在恶意攻击中可能产生大量无效的 key\n  布隆过滤器\n先用布隆过滤器判断请求值是否存在，实际上就是哈希校验\n  缓存击穿 key 失效的瞬间，大量并发集中访问，直接落在数据库上。\n  设置热点数据不过期\n可以解决问题，但并不好\n  加互斥锁\n分布式锁来保证对每个 key 同时只有一个线程查询后端服务，其它线程没有获得分布式锁的权限，只需要等待，从而将高并发压力转移到分布式锁\n  缓存雪崩 服务器宕机或断网形成缓存雪崩，对数据库造成压力不可预知，很可能瞬间将数据库压垮。\n实际上就是压力累积超过临界导致的，\n 增设缓存集群，异地多活 限流降级，缓存失效后，通过加锁或队列来控制都数据库写缓存的线程数量 数据预热，预访问数据，使得尽可能多的数据被加载到缓存中，但要注意设置不同的过期时间，使缓存失效的时间点尽量均匀   单线程模型  单线程开发、维护容易 Redis性能瓶颈在内存和网络，CPU瓶颈不明显 多线程带来了死锁、线程上下文切换等问题，甚至可能影响性能  6.0 后引入多线程也是为了提高网络 IO 读写性能，仅用在网络数据读写这类耗时操作上，无需担心线程安全问题。\nRedis 事件处理模型对应其中单线程的文件事件处理器(File Event Handler)，因此是单线程模型。通过 IO 多路复用来监听大量连接，跟据套接字执行任务关联不同的事件处理器，不需要创建多余线程来监听连接。\n 虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。\n  缓存读写策略 缓存读写策略实际上也就是缓存和数据库间的位置关系，主要有以下三种\n旁路缓存模式 适用读请求较多的场景\n写：\n 先更新 DB 中数据 直接删除 cache   之所以先更新 DB ，是因为 cache 的删除操作相对快很多，数据不一致的可能性大大降低。相反，如果先删除 cache，此时如果有并行请求直接从 DB 中读取数据，这一操作很可能在 DB 中数据被更新前完成。\n 读：\n 从 cache 中读取数据，读到直接返回 读不到就从 DB 中读取并返回 数据放到 cache 中  缺点一、 首次请求数据一定不在 cache ，但是这一问题可以通过热点数据的提前缓存解决。\n缺点二、 写操作如果频繁，则 cache 数据被频繁删除，缓存命中率降低，缓存很大程度上被架空。在强一致场景下需要锁/分布锁保证更新 cache 时不存在线程问题；弱一致场景下可以 cache 和 DB 一起更新，cache 设置较短的过期事件以提高缓存命中率。\n读写穿透模式 cache 负责将数据读取和写入 DB，作为服务端和 DB 间的中间件。然而相当难实现，因为 Redis 不提供 DB 读写功能。\n写：\n 查 cache，不存在则直接更新 DB cache 存在，则先更新 cache，cache 服务自己更新 DB（cache 和 DB 同步更新）  读：\n 从 cache 读数据，读到直接返回 没读到就从 DB 加载到 cache，然后返回响应  由于 Redis 不提供 DB 读写，这一模式实际上只是在旁路模式上进行了封装。同样具有首次请求数据不在 cache 问题。\n异步缓存写入 和 读写穿透模式 相似，但只更新缓存，不直接更新 DB，用异步批量的方式来更新 DB。消息队列中消息异步写入磁盘、MySQL 的 InnoDB Buffer Pool 机制都用到这种策略。\nDB 的写性能非常高，适合数据频繁变化，数据一致性要求又不高的场景，如浏览量、点赞量。\n缺点很明显，数据一致性很难维护，cache 可能在数据异步更新前宕机。\n如何保证缓存数据库数据一致 旁路缓存模式下，可以增加 cache 更新重试机制——如果 cache 服务不可用而暂时无法删除缓存，就隔一段时间再试，多次失败就将更新失败 key 存入队列，等缓存恢复后进行删除。\n Redis Cluster Redis 集群主要解决的是性能问题，在缓存数据量过大的情况下将数据分散到各台 Redis 主机上，可以看作是一种负载均衡手段，方便业务进行横向拓展。\nRedis Cluster 有多个节点，是去中心化的分布式结构，每个节点都负责数据读写操作，各节点间会进行通信。通过分片 (sharding) 来进行数据管理，提供复制和故障转移功能。\nHash Slot\n共 16384 个槽被平均分配给节点进行管理，每个节点对自己负责的槽进行读写操作。各个节点间彼此通信，知晓其它节点负责管理的槽范围。\n作为一个分布式系统，各结点需要互相通信来维护一份所有其它示例的状态信息，基于 Gossip 协议实现数据的最终一致性。\n访问流程\n客户端访问任意节点时，对数据 key 按照 CRC16 进行 Hash 计算，然后对运算结果模 16384 ，判断槽是否在当前节点管理范围内：如果在，则执行命令，返回结果；如果不在，返回moved重定向异常，之后由客户端跟据重定向异常中目标节点信息去发送命令。\n迁移\n如果节点在迁移过程中收到客户端命令，会返回 ASK 重定向异常。\n Redis Replication Redis 主从主要解决的是可用性问题，读吞吐量过大情况下，可以通过一主多从来提高可用性和读吞吐量，从机多少取决于读吞吐量大小。\n从机只能读，不能写。主机断开连接，从机仍然连接到主机，只是没有任何写操作传入，如果主机上线，从机依然可以直接获取。通过指令 SLAVEOF no one 来脱离从机身份。\n复制\n  SYNC\n每次执行 SYNC ，主服务器需要 BGSAVE 来生成 RDB，并发送给从服务器；从服务器载入 RDB 期间阻塞进程，无法处理请求。\n  PSYNC\n部分重同步，主服务器收到 PSYNC 后返回 +CONTINUE ，示意准备执行部分重同步，然后继续发送新指令以完成同步。\n 主从服务器分别维护“复制偏移量”，记录收到的数据长度（字节数）。通过对比主从复制偏移量可以直到是否处于一致状态。\n主服务器维护一个定长 FIFO 队列，作为复制积压缓冲区。主服务器将写命令发给从机，同时入队到复制积压缓冲区。\n   如果从机先前没有复制过任何主机，或执行过 SLAVEOF no one ，则为了开始新复制而发送 PSYNC ? -1 ，请求主机进行完整重同步。主机返回 +FULLRESYNC \u0026lt;runid\u0026gt; \u0026lt;offsetid\u0026gt; 示意准备完整重同步。\n  反之，发送 PSYNC \u0026lt;runid\u0026gt; \u0026lt;offset\u0026gt; ，供主机判断执行哪种同步\n  哨兵\n主从的问题在于一旦主机宕机，从机晋升，将需要人工重新配置其余所有从机，复制新的主机，并改变应用方主机地址，为此需要一个（实际上一般是多个）哨兵来干这件事。\n单个哨兵如果检测到主服务器宕机，不会马上进行 failover ，而是认为主服务器“主观下线”。当检测到主服务器不可用的哨兵达到一定数量，则哨兵间进行投票，决定接替的从机，切换成功后，通过发布订阅模式，让各个哨兵把监控的从服务器实现切换主机，称为“客观下线”。\n客观下线后，即使原主机重新上线，也只能作为新主机的从机。\n缺点：无法在线扩容，集群容量到达上限，不好在线扩容；实现哨兵模式配置有很多选择，较为复杂\n","date":"2021-06-29T00:00:00Z","image":"https://winterorch.github.io/images/feature/scenes/Windmill.jpg","permalink":"https://winterorch.github.io/p/redis-common_questions/","title":"Redis - 面试常见问题"},{"content":"[LeetCode] 815. Bus Routes We have a list of bus routes. Each routes[i] is a bus route that the i-th bus repeats forever. For example if routes[0] = [1, 5, 7], this means that the first bus (0-th indexed) travels in the sequence 1-\u0026gt;5-\u0026gt;7-\u0026gt;1-\u0026gt;5-\u0026gt;7-\u0026gt;1-\u0026gt;\u0026hellip; forever.\nWe start at bus stop S (initially not on a bus), and we want to go to bus stop T. Travelling by buses only, what is the least number of buses we must take to reach our destination? Return -1 if it is not possible.\nExample 1:\nInput: routes = [[1,2,7],[3,6,7]], source = 1, target = 6\rOutput: 2\rExplanation: The best strategy is take the first bus to the bus stop 7, then take the second bus to the bus stop 6.\rExample 2:\nInput: routes = [[7,12],[4,5,15],[6],[15,19],[9,12,13]], source = 15, target = 12\rOutput: -1\rConstraints:\n 1 \u0026lt;= routes.length \u0026lt;= 500. 1 \u0026lt;= routes[i].length \u0026lt;= 10^5 All the values of routes[i] are unique. sum(routes[i].length) \u0026lt;= 10^5 0 \u0026lt;= routes[i][j] \u0026lt; 10^6 0 \u0026lt;= source, target \u0026lt; 10^6   顺便贴一下两年前这道题的提示：\n Note:  1 \u0026lt;= routes.length \u0026lt;= 500. 1 \u0026lt;= routes[i].length \u0026lt;= 500. 0 \u0026lt;= routes[i][j] \u0026lt; 10 ^ 6.      题解 图压缩 + 最短路径算法  类似题：LeetCode 127 Word Ladder II\n 看一下两年前和现在对案例限制的不同就可以看出来——力抠把这道题图的成分提升了，并且告诉你了一条公交路线里不会有重复站点，最终要的是，明确了公交站台的数量远远高于公交线路的数量（最离谱的是最后一个案例，尼玛十几条公交线路总共经过了五六万个站，要是在城市天际线里搞这种线路，小人上班还没坐到单位就老死了好吗），换句话说，如果不进行压缩，直接以公交站为结点进行 BFS ，你的图会相当大，如果压缩了，那效率上一定是有收益的。因此有必要将站台图压缩成公交线路的邻接图。\nint n = routes.length; boolean[][] edge = new boolean[n][n]; Map\u0026lt;Integer, List\u0026lt;Integer\u0026gt;\u0026gt; rec = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) { for (int site : routes[i]) { List\u0026lt;Integer\u0026gt; list = rec.getOrDefault(site, new ArrayList\u0026lt;\u0026gt;()); for (int j : list) { edge[i][j] = edge[j][i] = true; } list.add(i); rec.put(site, list); } } 这样下来，在搜索过程中队列中保存的就都是公交路线号而不是站台号了，那么起点和终点也就不是站台，而是经过相应站台所有公交线路的集合了，这其实就和 127 题那个单词编辑步长特别相似了，用 BFS 应当是可以的，而且其实这里的公交都是环线，完全可以用双向 BFS 进行优化（当发现一道 BFS 题的起点和终点可以互换，换句话说图是无向的，基本都可以用上双向 BFS）。\n然而官答这里直接当成图来做了，直接算了个到所有（除经过起始站的之外）其它公交线路的最少转车站数，用的还是 SPFA，考虑到最后判题案例中其实充斥的都是站点繁多但实际上连通却不多的稀疏图，这样的选择反而相当高效。所以说合适的输入案例是最有效的优化。\n虽然 OJ 里无环的情况下还是迪杰斯特拉稳妥一些，但 Leetcode 上基本 SPFA 完全没有问题，写起来还方便，直接用队列不断更新相邻结点的最小距离，一旦距离进行更新就将该结点也丢进队列里，继续更新，直到队列为空。这一算法在稀疏图中效率非常高。\n得到的结果里去找能到终点的最小距离就行了，整个算法理解起来非常简单。\nint[] dis = new int[n]; Arrays.fill(dis, -1); Queue\u0026lt;Integer\u0026gt; que = new ArrayDeque\u0026lt;\u0026gt;(); for (int site : rec.getOrDefault(source, new ArrayList\u0026lt;\u0026gt;())) { dis[site] = 1; que.offer(site); } while (!que.isEmpty()) { int x = que.poll(); for (int y = 0; y \u0026lt; n; y++) { if (edge[x][y] \u0026amp;\u0026amp; dis[y] == -1) { dis[y] = dis[x] + 1; que.offer(y); } } } int ret = Integer.MAX_VALUE; for (int site : rec.getOrDefault(target, new ArrayList\u0026lt;\u0026gt;())) { if (dis[site] != -1) { ret = Math.min(ret, dis[site]); } } return ret == Integer.MAX_VALUE ? -1 : ret; 代码总和\npublic int numBusesToDestination(int[][] routes, int source, int target) { if (source == target) { return 0; } int n = routes.length; boolean[][] edge = new boolean[n][n]; Map\u0026lt;Integer, List\u0026lt;Integer\u0026gt;\u0026gt; rec = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) { for (int site : routes[i]) { List\u0026lt;Integer\u0026gt; list = rec.getOrDefault(site, new ArrayList\u0026lt;\u0026gt;()); for (int j : list) { edge[i][j] = edge[j][i] = true; } list.add(i); rec.put(site, list); } } int[] dis = new int[n]; Arrays.fill(dis, -1); Queue\u0026lt;Integer\u0026gt; que = new ArrayDeque\u0026lt;\u0026gt;(); for (int site : rec.getOrDefault(source, new ArrayList\u0026lt;\u0026gt;())) { dis[site] = 1; que.offer(site); } while (!que.isEmpty()) { int x = que.poll(); for (int y = 0; y \u0026lt; n; y++) { if (edge[x][y] \u0026amp;\u0026amp; dis[y] == -1) { dis[y] = dis[x] + 1; que.offer(y); } } } int ret = Integer.MAX_VALUE; for (int site : rec.getOrDefault(target, new ArrayList\u0026lt;\u0026gt;())) { if (dis[site] != -1) { ret = Math.min(ret, dis[site]); } } return ret == Integer.MAX_VALUE ? -1 : ret; }  题解 BFS 这里再写一个双向 BFS 。压缩部分和前面是一样的，问题是搜索部分。\n首先，将起点和终点（其实是经过起点和终点的所有公交线路）分别装入两个方向的 BFS 队列中，如果这里就发现有一样的，那说明有车能从起点直达终点，不用搜了，直接输出 1 。\nboolean[] vis = new boolean[n]; Deque\u0026lt;Integer\u0026gt; src_q, des_q; List\u0026lt;Integer\u0026gt; tar = rec.get(source); if (tar == null) { return -1; } else { src_q = new ArrayDeque\u0026lt;\u0026gt;(tar); for (Integer i : tar) { vis[i] = true; } } tar = rec.get(target); if (tar == null) { return -1; } else { des_q = new ArrayDeque\u0026lt;\u0026gt;(tar); for (Integer i : tar) { if (vis[i]) return 1; else vis[i] = true; } } 接下来就是双向 BFS，既然是 BFS，我们每次走一步，搜一步能到的所有公交线路，如果搜到路线出现在另一方向的队列中，说明两个队列接上了，直接输出。\nint src_steps = 0, des_steps = 1; while (!src_q.isEmpty() \u0026amp;\u0026amp; !des_q.isEmpty()) { Deque\u0026lt;Integer\u0026gt; front, back; // 每次挑元素少的队列进行 BFS，从而收缩搜索范围  if (src_q.size() \u0026gt; des_q.size()) { front = des_q; back = src_q; ++des_steps; } else { front = src_q; back = des_q; ++src_steps; } // 检查邻结点中有没有能到对面（即另一个方向的队列）  for (int i = front.size(); i \u0026gt; 0; --i) { int t = front.removeFirst(); for (int j = 0; j \u0026lt; n; ++j) { if (edge[t][j] \u0026amp;\u0026amp; !vis[j]) { if (!vis[j]) { vis[j] = true; front.addLast(j); } else { if (back.contains(j)) { return src_steps + des_steps; } } } } } } return -1; 代码总和\npublic int numBusesToDestination(int[][] routes, int source, int target) { if (source == target) { return 0; } int n = routes.length; boolean[][] edge = new boolean[n][n]; Map\u0026lt;Integer, List\u0026lt;Integer\u0026gt;\u0026gt; rec = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) { for (int site : routes[i]) { List\u0026lt;Integer\u0026gt; list = rec.getOrDefault(site, new ArrayList\u0026lt;\u0026gt;()); for (int j : list) { edge[i][j] = edge[j][i] = true; } list.add(i); rec.put(site, list); } } boolean[] vis = new boolean[n]; Deque\u0026lt;Integer\u0026gt; src_q, des_q; List\u0026lt;Integer\u0026gt; tar = rec.get(source); if (tar == null) { return -1; } else { src_q = new ArrayDeque\u0026lt;\u0026gt;(tar); for (Integer i : tar) { vis[i] = true; } } tar = rec.get(target); if (tar == null) { return -1; } else { des_q = new ArrayDeque\u0026lt;\u0026gt;(tar); for (Integer i : tar) { if (vis[i]) return 1; else vis[i] = true; } } int src_steps = 0, des_steps = 1; while (!src_q.isEmpty() \u0026amp;\u0026amp; !des_q.isEmpty()) { Deque\u0026lt;Integer\u0026gt; front, back; if (src_q.size() \u0026gt; des_q.size()) { front = des_q; back = src_q; ++des_steps; } else { front = src_q; back = des_q; ++src_steps; } for (int i = front.size(); i \u0026gt; 0; --i) { int t = front.removeFirst(); for (int j = 0; j \u0026lt; n; ++j) { if (edge[t][j]) { if (!vis[j]) { vis[j] = true; front.addLast(j); } else { if (back.contains(j)) { return src_steps + des_steps; } } } } } } return -1; }  总结 这道题反正无论如何都绕不开图压缩了。搜索上，两种方法最终时间相差无几（指用 Leetcode 案例前提下），最小路径算法其实有些超过题目需求了，不过 SPFA 很契合这道题的场景，因此效率还是很高，加上写起来方便（重点），略优于双向 BFS。\n","date":"2021-06-27T00:00:00Z","permalink":"https://winterorch.github.io/p/leetcode-815-%E5%85%AC%E4%BA%A4%E8%B7%AF%E7%BA%BF/","title":"LeetCode 815 - 公交路线"},{"content":"首先要踩一下 PYQT，如果使用 Python 过程中有 GUI 方面的需求，请一定一定先看有没有 QT 之外的选择 （Django不好吗？）。用过 PYQT 的都知道，QT 提供的不仅仅是 GUI 组件库，而是从线程到网络通信的一整套 QObject ，个人认为对于 Python 而言这实在是过于不实际了，我觉得大多数人对于 Python 开发的期望都是每一个模块各司其职，项目能够“高内聚，低耦合”，Python 在这方面也是非常令人满意的，然而在 QT 中除外。\nPYQT 来源于 C++ QT，其理念就是将众多组件耦合到一起，如果你在一个团队中进行开发，这会导致——无论是图形界面方面的责任，还是业务逻辑方面的问题都会堆到你这里，成为你的压力，而如果你作为个人进行开发，这会使你写 GUI 的时候无时无刻不得顾及业务需求，两边都得顾得上，两边都得一起调。出了问题的话，非常不幸，网上能找到的 PYQT 资料非常之有限，甚至官方文档中都有大量的 TODO ，且完全没有要补上的迹象，我写代码过程中基本都只能参考 QT 的官方文档，因为他实在是比 PyQt 官方提供的要友好得多。\n如果在确认了这些问题之后，还是要入门 PYQT，推荐几个 Github：PyQt Examples 提供了大部分常用 GUI 组件的使用 Deemo，虽然 PyQt 对于这些组件基本都有大量复杂数倍的替代品，供你完成非常繁杂的需求，但是，没有谁想从那入手的。\n 顺便提一下，有个非常不错（指功能上）的 PyQt 音乐播放器 FeelUOwn 项目。当时看到这个小项目是很感动的，非常兴奋地下下来源码，然后确信自己看的是天书——项目代码不是给人读的，PyQt 极大放大了代码可读性差的问题\n 接下来是正片——\n 开始 PyQt 项目，你要知道这些   如果用 PyCharm 构建 PyQt 项目，你在点下 Run/Debug 之前请务必检查一下 Debug 配置\nRun 和 Debug 图标左边那个下拉菜单，其中的 Edit Configurations，请检查一下 Configuration 下的 Excution 栏，确保 Emulate terminal in output console 这个选项勾上。否则即使你的程序挂掉，控制台也不会抛出一个异常来，没有什么比程序跑不起来，甚至连哪里出了问题都无法追溯更让人头疼的事情了。\n   使用 QSS ，你要知道这些 QSS 看似很美好，但也是重灾区。\n  QSS Style Sheet 会自动由父框架传递给子框架 什么意思呢？就是说你可能想给 QWidget 设个好看的边框，于是写下这么一段内容：\nQWidget { background: lightGray; border: 3px solid blue; } 然后发现所有 Widget 下所有的 QLabel 都诡异地多了个框而父框架反而没有。为什么呢？因为 QLabel 也是 QWidget 的一种，QWidget 的样式表会自动传递到它，并且生效。然而 QWidget 自己却不能生效，因为 QWidget 天生无法让自己的显式样式生效，它们只是用来传递给子框架的，换句话说，Qt 就这么设计的。\n如果想让父框架有边框之类的设置，请用 QFrame ，它不仅有同样的参数而且几乎能替代 QWidget 。\n  请尽量使用对象的 objectName 来区分子对象的样式 如果你想要你的设置仅仅对最外层，或子对象中的一个生效，请这么写：\nQWidget[objectName=\u0026#39;OutsidePanel\u0026#39;] { background: lightGray; border: 3px solid blue; } 那什么是 objectName 呢？它是 QObject 的一个成员变量，没错，PyQt 在最不需要解耦的地方做了一次解耦，让 objectName 需要单独设置。所以接下来，在这个你想让它有边框的 QWidget 的构造函数中写下：self.setObjectName(\u0026quot;OutsidePanel\u0026quot;) 。\n不推荐将组件的样式表颗粒化，在初始化过程中单独 setStyleSheet() ，还是推荐将一整个 Panel 的样式整合成一个文件，在父框架进行设置，而避免在运行过程中还要动态加载。我认为 Qt 的设计者也是这样希望的，应当有相应的优化。\n关于 QSS ，网上其实能查到很多内容，比方有人说可以直接跟据对象名和 CSS 一样用 # 设置对象的样式，实测并不行，推测可能是 PyQt 版本不同，能力也有所不同，很多网上提供的 QSS 属性也并不能生效。虽然 QSS 想让做 GUI 的人尽量用熟悉的方法——CSS来设计，但功能属实有限，不能达到 CSS 的效果不说，还给了有 CSS 使用经验的人过多不切实际的幻想，只能说是将 PyQt 本就有限的样式设置从 GUI 设计中部分解耦出来。\n  【未完，对 PyQt ，想吐槽的点实在是如涛涛江水一般】\n","date":"2021-06-25T00:00:00Z","image":"https://winterorch.github.io/images/feature/scenes/UAZ.jpg","permalink":"https://winterorch.github.io/p/python-pyqt_bloody_tips/","title":"Python - PYQT 踩坑记"},{"content":"[LeetCode] 752. Open the Lock You have a lock in front of you with 4 circular wheels. Each wheel has 10 slots: '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'. The wheels can rotate freely and wrap around: for example we can turn '9' to be '0', or '0' to be '9'. Each move consists of turning one wheel one slot.\nThe lock initially starts at '0000', a string representing the state of the 4 wheels.\nYou are given a list of deadends dead ends, meaning if the lock displays any of these codes, the wheels of the lock will stop turning and you will be unable to open it.\nGiven a target representing the value of the wheels that will unlock the lock, return the minimum total number of turns required to open the lock, or -1 if it is impossible.\nExample 1:\nInput: deadends = [\u0026quot;0201\u0026quot;,\u0026quot;0101\u0026quot;,\u0026quot;0102\u0026quot;,\u0026quot;1212\u0026quot;,\u0026quot;2002\u0026quot;], target = \u0026quot;0202\u0026quot;\rOutput: 6\rExplanation:\rA sequence of valid moves would be \u0026quot;0000\u0026quot; -\u0026gt; \u0026quot;1000\u0026quot; -\u0026gt; \u0026quot;1100\u0026quot; -\u0026gt; \u0026quot;1200\u0026quot; -\u0026gt; \u0026quot;1201\u0026quot; -\u0026gt; \u0026quot;1202\u0026quot; -\u0026gt; \u0026quot;0202\u0026quot;.\rNote that a sequence like \u0026quot;0000\u0026quot; -\u0026gt; \u0026quot;0001\u0026quot; -\u0026gt; \u0026quot;0002\u0026quot; -\u0026gt; \u0026quot;0102\u0026quot; -\u0026gt; \u0026quot;0202\u0026quot; would be invalid,\rbecause the wheels of the lock become stuck after the display becomes the dead end \u0026quot;0102\u0026quot;.\rExample 2:\nInput: deadends = [\u0026quot;8888\u0026quot;], target = \u0026quot;0009\u0026quot;\rOutput: 1\rExplanation:\rWe can turn the last wheel in reverse to move from \u0026quot;0000\u0026quot; -\u0026gt; \u0026quot;0009\u0026quot;.\rExample 3:\nInput: deadends = [\u0026quot;8887\u0026quot;,\u0026quot;8889\u0026quot;,\u0026quot;8878\u0026quot;,\u0026quot;8898\u0026quot;,\u0026quot;8788\u0026quot;,\u0026quot;8988\u0026quot;,\u0026quot;7888\u0026quot;,\u0026quot;9888\u0026quot;], target = \u0026quot;8888\u0026quot;\rOutput: -1\rExplanation:\rWe can't reach the target without getting stuck.\rExample 4:\nInput: deadends = [\u0026quot;0000\u0026quot;], target = \u0026quot;8888\u0026quot;\rOutput: -1\rConstraints:\n 1 \u0026lt;= deadends.length \u0026lt;= 500 deadends[i].length == 4 target.length == 4 target will not be in the list deadends. target and deadends[i] consist of digits only.   题解 双向 BFS  类似题：LeetCode 127 Word Ladder II\n 看到有 deadends 其实就比较明显了——这是个走迷宫问题，而且因为有四位密码，所以其实是个四维迷宫。维数并不会增加解法的复杂程度，倒是会严重增加敲代码的繁琐程度。一开始是打算真的和迷宫一样，用四维数组做的，后来发现参数实在太多了，光敲一个位置就要 mem[i0][i1][i2][i3] 这样来一遍，实在有点头皮发麻，改用 String 和 Map 来做记忆化了。\n还是当作迷宫来解，因此思想是 BFS ，因为入口和出口都是唯一确定的，前后都可以作为 BFS 的起点，因此可以通过双向 BFS 来收缩搜索范围。\n首先把 deadends 存到一个 HashSet 里，方便查验。BFS 需要前后两个队列，分别维护一个记忆化搜索表，记录到 key 位置的步长。\nDeque\u0026lt;String\u0026gt; d1 = new ArrayDeque\u0026lt;\u0026gt;(), d2 = new ArrayDeque\u0026lt;\u0026gt;(); Map\u0026lt;String, Integer\u0026gt; m1 = new HashMap\u0026lt;\u0026gt;(), m2 = new HashMap\u0026lt;\u0026gt;(); d1.addLast(s); m1.put(s, 0); d2.addLast(t); m2.put(t, 0); 然后就是 BFS 了，一直搜到队列空为止。为了尽量收缩双向 BFS 的搜索范围，每次从更小的队列取元素进行搜索。\nwhile (!d1.isEmpty() \u0026amp;\u0026amp; !d2.isEmpty()) { int t = -1; if (d1.size() \u0026lt;= d2.size()) { t = update(d1, m1, m2); } else { t = update(d2, m2, m1); } if (t != -1) return t; } 每次搜索要搜相邻的八个位置，也就是每一位的前后两个数字。原数字是 char[i] 的话，以十为模加一或加九就行了——(char) ('0' + ((chars[i] - '0' + offset) % 10)) 。\n新状态的检查包括这样一些原则——\n 新位置不能是 deadend 新位置不能已经去过（在同一队列中），同一队列两次经过同一位置步长一定不会变短，也就不需要考虑了 在满足前两个前提下，如果能在反向记忆中找到相同状态，那一定是最短路径，直接输出 不在反向记忆中，就加入到当前记忆队列中，从而引起下一轮 BFS  char ori = chars[i]; chars[i] = (char) (\u0026#39;0\u0026#39; + ((chars[i] - \u0026#39;0\u0026#39; + offset) % 10)); String go = String.valueOf(chars); chars[i] = ori; if (this.deadEnds.contains(go)) continue; if (fs_map.containsKey(go)) continue; if (ot_map.containsKey(go)) { this.res = step + 1 + ot_map.get(go); return true; } fs_map.put(go, step + 1); fs.addLast(go); 完整代码\nint res; int[] offset = {1, 9}; Set\u0026lt;String\u0026gt; deadEnds; public int openLock_remastered(String[] dead, String target) { if (target.equals(\u0026#34;0000\u0026#34;)) return 0; this.deadEnds = new HashSet\u0026lt;\u0026gt;(); // 虽然这里 IDE 会推荐让 Arrays 来把 String[] 转换成 Collection,但这样做对速度没有好处。  // IDE 上测出来差别不大，但到了 LeetCode 上居然能让整题多耗将近一倍时间，百思不得其解。  for (String str: dead) deadEnds.add(str); if (deadEnds.contains(\u0026#34;0000\u0026#34;)) return -1; Deque\u0026lt;String\u0026gt; front = new ArrayDeque\u0026lt;\u0026gt;(); Map\u0026lt;String, Integer\u0026gt; front_map = new HashMap\u0026lt;\u0026gt;(); Deque\u0026lt;String\u0026gt; back = new ArrayDeque\u0026lt;\u0026gt;(); Map\u0026lt;String, Integer\u0026gt; back_map = new HashMap\u0026lt;\u0026gt;(); front.addLast(\u0026#34;0000\u0026#34;); front_map.put(\u0026#34;0000\u0026#34;, 0); back.addLast(target); back_map.put(target, 0); while (!front.isEmpty() \u0026amp;\u0026amp; !back.isEmpty()) { if (front.size() \u0026lt; back.size()) { if (update(front, front_map, back_map)) return this.res; } else { if (update(back, back_map, front_map)) return this.res; } } return -1; } private boolean update(Deque\u0026lt;String\u0026gt; fs, Map\u0026lt;String, Integer\u0026gt; fs_map, Map\u0026lt;String, Integer\u0026gt; ot_map) { String cur = fs.pollFirst(); char[] chars = cur.toCharArray(); int step = fs_map.get(cur); for (int i = 0; i \u0026lt; 4; ++i) { for (int offset : this.offset) { char ori = chars[i]; // 在原 char[] 上改了，取完 String 再转回去，  // 会比 clone() 新的要快很多 \tchars[i] = (char) (\u0026#39;0\u0026#39; + ((chars[i] - \u0026#39;0\u0026#39; + offset) % 10)); String go = String.valueOf(chars); chars[i] = ori;\tif (this.deadEnds.contains(go)) continue; if (fs_map.containsKey(go)) continue; if (ot_map.containsKey(go)) { this.res = step + 1 + ot_map.get(go); return true; } fs_map.put(go, step + 1); fs.addLast(go); } } return false; }  题解 AStar 算法 作者：AC_OIer 链接：https://leetcode-cn.com/problems/open-the-lock/solution/gong-shui-san-xie-yi-ti-shuang-jie-shuan-wyr9/\n可以直接根据本题规则来设计 A* 的「启发式函数」。\n比如对于两个状态 a 和 b 可直接计算出「理论最小转换次数」：不同字符的转换成本之和 。\n需要注意的是：由于我们衡量某个字符 str 的估值是以目标字符串 target 为基准，因此我们只能确保 target 出队时为「距离最短」，而不能确保中间节点出队时「距离最短」，因此我们不能单纯根据某个节点是否「曾经入队」而决定是否入队，还要结合当前节点的「最小距离」是否被更新而决定是否入队。\n这一点十分关键，在代码层面上体现在 map.get(str).step \u0026gt; poll.step + 1 的判断上。\n注意：本题用 A* 过了，但通常我们需要先「确保有解」，A* 的启发搜索才会发挥真正价值。而本题，除非 t 本身在 deadends 中，其余情况我们无法很好提前判断「是否有解」。对于无解的情况 A* 效果不如「双向 BFS」。\n源码\nclass Solution { class Node { String str; int val, step; /** * str : 对应字符串 * val : 估值（与目标字符串 target 的最小转换成本） * step: 对应字符串是经过多少步转换而来 */ Node(String _str, int _val, int _step) { str = _str; val = _val; step = _step; } } int f(String str) { int ans = 0; for (int i = 0; i \u0026lt; 4; i++) { int cur = str.charAt(i) - \u0026#39;0\u0026#39;, target = t.charAt(i) - \u0026#39;0\u0026#39;; int a = Math.min(cur, target), b = Math.max(cur, target); // 在「正向转」和「反向转」之间取 min  int min = Math.min(b - a, a + 10 - b); ans += min; } return ans; } String s, t; Set\u0026lt;String\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); public int openLock(String[] ds, String _t) { s = \u0026#34;0000\u0026#34;; t = _t; if (s.equals(t)) return 0; for (String d : ds) set.add(d); if (set.contains(s)) return -1; PriorityQueue\u0026lt;Node\u0026gt; q = new PriorityQueue\u0026lt;\u0026gt;((a,b)-\u0026gt;a.val-b.val); Map\u0026lt;String, Node\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); Node root = new Node(s, f(s), 0); q.add(root); map.put(s, root); while (!q.isEmpty()) { Node poll = q.poll(); char[] pcs = poll.str.toCharArray(); int step = poll.step; if (poll.str.equals(t)) return step; for (int i = 0; i \u0026lt; 4; i++) { for (int j = -1; j \u0026lt;= 1; j++) { if (j == 0) continue; int cur = pcs[i] - \u0026#39;0\u0026#39;; int next = (cur + j) % 10; if (next == -1) next = 9; char[] clone = pcs.clone(); clone[i] = (char)(next + \u0026#39;0\u0026#39;); String str = String.valueOf(clone); if (set.contains(str)) continue; // 如果 str 还没搜索过，或者 str 的「最短距离」被更新，则入队  if (!map.containsKey(str) || map.get(str).step \u0026gt; step + 1) { Node node = new Node(str, step + 1 + f(str), step + 1); map.put(str, node); q.add(node); } } } } return -1; } } ","date":"2021-06-24T00:00:00Z","permalink":"https://winterorch.github.io/p/leetcode-752-%E6%89%93%E5%BC%80%E8%BD%AC%E7%9B%98%E9%94%81/","title":"LeetCode 752 - 打开转盘锁"},{"content":"Spring 支持的依赖注入有 @Autowired @Resource @Inject 三种\n@Autowired 来自 org.springframwork.beans.factory.annotation.Autowired ，装配顺序为：\n 按 type 在上下文中查找匹配的 bean 如果有多个 bean，则按照 name 进行匹配  如有 @Qualifier ，则按指定的 name 进行匹配 如没有，则按变量名进行匹配   匹配不到就报错  @Autowired(required=false) 则注入失败不抛异常\n@Inject Spring 环境下和 @Autowired 相同，都依赖 AutowiredAnnotationBeanPostProcess 进行处理，但不能 (required=false)。@Inject 由 JSR-330 定义，可以切换到谷歌的 DI 框架——Guice。\n@Inject 在 Java EE 包内，SE 环境需要单独引入。\n@Resource JSR-250 定义。在 CommonAnnotationBeanPostProcessor 实现处理。同样有 name 和 type。装配顺序：\n 如同时指定 name 和 type ，从上下文找到唯一匹配 bean 进行装配，找不到抛异常 如指定 name ，则到上下文找 id 匹配的 bean 进行装配，找不到抛异常 如指定 type ，则到上下文找类型匹配的唯一 bean 进行装配，找不到或找到不唯一都会抛异常 如果都没有指定，则默认按 byName 方式装配，找不到再按 byType 进行装配   IDEA 使用 @Autowired 时很常见警告 Field injection is not recommended。\nSpring 团队建议永远使用构造方法，也就是 c-args 进行依赖注入。IDEA 对这一警告的默认修改方式也是——创建一个构造器进行依赖注入。并且，跟据 Spring 团队建议，对必须的依赖，应当使用断言进行确认\nAssert.notNull(svc, \u0026#34;svc must not be null\u0026#34;); 为什么不能用成员依赖注入呢？\nfield 注入虽然简洁，但存在问题：\n 由于添加依赖过于简单（加个注释），我们很容易无意识地向一个类注入大量依赖，这违反了单一职责原理，因为我们过去通过构造器进行注入，而要是你的构造器出现大量入参，那很容易意识到自己的代码结构不对劲。打个比方——原本要数着钞票买东西的，一下子变成移动支付，点一下付钱了，就容易到了月底为账单发愁，因为我们金钱意识变薄弱了。解决方法就是——继续用构造器注入，因此对于强制依赖，Spring推荐用 c-args 注入。 依赖注入与容器本身耦合了，即——类唯一的正常工作方式就是通过容器反射进行实例化，这就像是集成测试一样，不像个健康的类，就像一个人原本你把饭给他就能自己吃，现在非要注射进去一样。为了让类能在容器外使用，自然还是要用 c-args 和 s-args。 属性注入不能用来注入 final 变量。   因此 Spring 给出建议：constructor-based 和 setter-based DI 可以混用，\n  强制依赖就用 constructor-based\n很好理解，类离开强制依赖就无法工作，这和构造方法职能相吻合，也能注入 final 变量。构造器可以保证这些变量的值不会是 null 。\n  可选、可变依赖用 setter-based\nsetter 值应被用于注入非必须依赖，这些依赖可以很方便地被改变或重新注入，否则会需要大量的 null 检查。\n  ","date":"2021-06-24T00:00:00Z","image":"https://winterorch.github.io/images/feature/scenes/Arctic.jpg","permalink":"https://winterorch.github.io/p/spring-%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%8C%BA%E5%88%86/","title":"Spring - 依赖注入注解的区分"},{"content":"剑指 Offer 56 - I. 数组中数字出现的次数 一个整型数组 nums 里除两个数字之外，其他数字都出现了两次。请写程序找出这两个只出现一次的数字。要求时间复杂度是O(n)，空间复杂度是O(1)。\n示例 1：\n 输入：nums = [4,1,4,6] 输出：[1,6] 或 [6,1]\n 示例 2：\n 输入：nums = [1,2,10,4,1,4,3,3] 输出：[2,10] 或 [10,2]\n 限制：\n 2 \u0026lt;= nums.length \u0026lt;= 10000\n  题解 时空复杂度已经很明显提示了，要用位运算，异或消除掉出现过两次的数字\nfor(int num : nums) n ^= num; 如果只有一个出现一次的数字，那答案已经出来了。然而这题有两个数字 x, y，得到的 n 是两者的异或 n = x ^ y 。因为 x != y ，n 必定有至少一个非零位，接下来肯定得围绕着这个非零位作文章。\n而这个非零位有什么用呢？它告诉我们，x 和 y 中有一个 (x) 在该比特位上非零，另一个 (y) 为零。前面知道，通过异或只能得出唯一一个出现一次的数字，而现在有两个数字，那思路应当是——把这两个数字区分开来，分成具有不同特点的两组，这样就能分别求出这两个数字了。而现在，这个用来区分的特点有了——在 n 最低非零位上是否为零。\n因此，接下来要做的就是——再遍历一遍原数组，在 n 最低非零位上跟据是否为零放到两个 int 上去异或。\n完整答案\npublic int[] singleNumbers(int[] nums) { int x = 0, y = 0, n = 0, m = 1; for(int num : nums) // 1. 遍历异或  n ^= num; while((n \u0026amp; m) == 0) // 2. 循环左移，计算 m  m \u0026lt;\u0026lt;= 1; for(int num: nums) { // 3. 遍历 nums 分组  if((num \u0026amp; m) != 0) x ^= num; // 4. 当 num \u0026amp; m != 0  else y ^= num; // 4. 当 num \u0026amp; m == 0  } return new int[] {x, y}; // 5. 返回出现一次的数字 } ","date":"2021-06-20T00:00:00Z","permalink":"https://winterorch.github.io/p/%E5%89%91%E6%8C%87-offer-56-i.-%E6%95%B0%E7%BB%84%E4%B8%AD%E6%95%B0%E5%AD%97%E5%87%BA%E7%8E%B0%E7%9A%84%E6%AC%A1%E6%95%B0/","title":"剑指 Offer 56 - I. 数组中数字出现的次数"},{"content":"首先，在 Spring 4.X 之后（不用 Spring Boot 的话）使用注释需要添加 aop 依赖。虽然不需要这么做了，还是有助于了解 Spring Boot 到底为我们做了什么。\n\u0026lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-aop --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-aop\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;{springframework.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 而且需要在 XML 中添加约束并在 context 中配置扫描范围。\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\u0026#34;\u0026gt; \u0026lt;context:annotation-config/\u0026gt; \u0026lt;/beans\u0026gt; 配置扫描范围\n\u0026lt;!--指定注解扫描包--\u0026gt; \u0026lt;context:component-scan base-package=\u0026#34;com.yourpackage\u0026#34;/\u0026gt; 接下来按类别整理一些最常用的注释。\nBean 的扫描   @ComponentScan\n   @ComponentScan：通过注释方式配置扫描范围，将其下的 @Component 组件（包括@Controller、@Service、@Repository）纳入 IOC 容器. 只能作用于配置类，且 Spring Boot 的入口类不能被纳入到扫描范围中.\n Spring Boot 默认的扫描范围是启动类所在包开始，当前包及子包下的所有文件\n @Configuration @ComponentScan(\u0026#34;cc.mrbird.demo\u0026#34;) public class WebConfig { }  可以通过 excludeFilters 来排除一些组件的扫描，通过 @Filter 注释完成\n@Configuration @ComponentScan(value = \u0026#34;cc.mrbird.demo\u0026#34;, excludeFilters = { // 将注解为 Controller 和 Repository 的类排除  @Filter(type = FilterType.ANNOTATION, classes = {Controller.class, Repository.class}), // 排除所有 User 类（及子类、实现类）  @Filter(type = FilterType.ASSIGNABLE_TYPE, classes = User.class) }) public class WebConfig { } 如上所示，可以跟据注释或直接指定排除相应类型（包括其子类、实现类）\nincludeFilters的作用和excludeFilters相反，其指定的是哪些组件需要被扫描：\n@Configuration @ComponentScan(value = \u0026#34;cc.mrbird.demo\u0026#34;, includeFilters = { // 仅纳入注释为 Service 的类  @Filter(type = FilterType.ANNOTATION, classes = Service.class) }, useDefaultFilters = false) public class WebConfig { } 通过实现 org.springframework.core.type.filter.TypeFilter接口可以自定义扫描策略，通过实现 match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) 方法，返回 true 说明匹配成功。\n   Bean 的注册   @Bean, @Component\n   @Bean：通过注解向 IOC 容器注册默认为方法名的 Bean，也可以通过 @Bean(\u0026quot;{name}\u0026quot;) 来重新命名\n@Configuration public class WebConfig { @Bean() public User user() { return new User(\u0026#34;mrbirdy\u0026#34;, 18); } }  实现了 FactoryBean\u0026lt;T\u0026gt; 接口的 Bean 是一类特殊的 Bean\npublic class CherryFactoryBean implements FactoryBean\u0026lt;Cherry\u0026gt; { @Override public Cherry getObject() { return new Cherry(); } @Override public Class\u0026lt;?\u0026gt; getObjectType() { return Cherry.class; } @Override public boolean isSingleton() { return false; } } 如果 isSingleton() 为 false ，则每次会调用 getObject() 从中获取 Bean。\n通过加上前缀 \u0026amp; 从工厂中取出对应的 Bean\nObject cherryFactoryBean = context.getBean(\u0026#34;\u0026amp;cherryFactoryBean\u0026#34;);    @Component：component-scan 指定的扫描路径下所有被@Controller、@Service、@Repository和@Component注解标注的类都会被纳入IOC容器中\n@Component(\u0026#34;user\u0026#34;) // 相当于配置文件中 \u0026lt;bean id=\u0026#34;user\u0026#34; class=\u0026#34;当前注解的类\u0026#34;/\u0026gt; public class User { public String name = ... } 说明该类被Spring管理。Component 类的有参构造方法会被默认用作依赖注入，所以相比在成员变量上加 @Autowire 来注入依赖，更合适的方法是通过构造方法注入。\n衍生注解：按照MVC三层架构分层\n @Repository：用于DAO层，数据库操作 @Service：用于Service层，复杂逻辑 @Controller：用于Controller层，接收用户请求并调用Service层返回数据  连同@Component，四个注解功能一样，都代表将某个类注册到Spring中\n  Bean 的加载   @Scope, @Lazy, @Conditional\n   @Scope：改变组件的作用域（默认 singleton）\n singleton：单实例（默认）,在Spring IOC容器启动的时候会调用方法创建对象然后纳入到IOC容器中，以后每次获取都是直接从IOC容器中获取（map.get()）； prototype：多实例，IOC容器启动的时候并不会去创建对象，而是在每次获取的时候才会去调用方法创建对象； request：一个请求对应一个实例； session：同一个session对应一个实例。    @Lazy：懒加载（针对 singleton ）\n懒加载的单例不会马上调用方法创建对象并注册，只有当第一次被使用时才会调用方法创建对象并加入容器中。\n  @Conditional：条件加载，类似于前面 @ComponentScan 中的 Filter\n使用@Conditional注解我们可以指定组件注册的条件，即满足特定条件才将组件纳入到 IOC 容器中。\n在使用该注解之前，我们需要创建一个类，实现Condition接口：\npublic class MyCondition implements Condition {\r@Override\rpublic boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) {\rreturn false;\r}\r}\r该接口包含一个matches方法，包含两个入参:\n ConditionContext：上下文信息； AnnotatedTypeMetadata：注解信息。  简单完善一下这个实现类:\npublic class MyCondition implements Condition { @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { String osName = context.getEnvironment().getProperty(\u0026#34;os.name\u0026#34;); return osName != null \u0026amp;\u0026amp; osName.contains(\u0026#34;Windows\u0026#34;); } } 接着将这个条件添加到User Bean注册的地方：\n@Bean @Conditional(MyCondition.class) public User user() { return new User(\u0026#34;mrbird\u0026#34;, 18); } 在Windows环境下，User这个组件将被成功注册，如果是别的操作系统，这个组件将不会被注册到IOC容器中。\n  属性注入   @Value, @ConfigurationProperties, @PropertySource\n   @Value:\tProperty注入\n可以直接用在成员变量上，也可以用在Setter上\n 需要注意的是 @value这种方式是不被推荐的，Spring 比较建议的是下面几种读取配置信息的方式。\n   @ConfigurationProperties: Properties 读取并与 bean 绑定\n LibraryProperties 类上加了 @Component 注解，我们可以像使用普通 bean 一样将其注入到类中使用。\n import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; import org.springframework.stereotype.Component; import java.util.List; @Component @ConfigurationProperties(prefix = \u0026#34;library\u0026#34;) class LibraryProperties { private String location; private List\u0026lt;Book\u0026gt; books; static class Book { String name; String description; } } 相应的配置文件内容\nlibrary:\rlocation: 湖北武汉加油中国加油\rbooks:\r- name: 天才基本法\rdescription: 二十二岁的林朝夕在父亲确诊阿尔茨海默病这天，得知自己暗恋多年的校园男神裴之即将出国深造的消息——对方考取的学校，恰是父亲当年为她放弃的那所。\r- name: 时间的秩序\rdescription: 为什么我们记得过去，而非未来？时间“流逝”意味着什么？是我们存在于时间之内，还是时间存在于我们之中？卡洛·罗韦利用诗意的文字，邀请我们思考这一亘古难题——时间的本质。\r- name: 了不起的我\rdescription: 如何养成一个新习惯？如何让心智变得更成熟？如何拥有高质量的关系？ 如何走出人生的艰难时刻？\r然后就可以通过 private final LibraryProperties library 注入 Property 对象了。\n题外话：InitializingBean 接口下的 afterPropertiesSet() 方法可以作为一个 Property 注入后的 AOP 使用，如下所示：\n@SpringBootApplication public class ReadConfigPropertiesApplication implements InitializingBean { private final LibraryProperties library; public ReadConfigPropertiesApplication(LibraryProperties library) { this.library = library; } public static void main(String[] args) { SpringApplication.run(ReadConfigPropertiesApplication.class, args); } @Override public void afterPropertiesSet() { System.out.println(library.getLocation()); System.out.println(library.getBooks()); } }  如果 Property类上不加 Component ，就需要在 SpringBootApplication 上加 @EnableConfigurationProperties 来注册 Bean ，如下所示：\n@SpringBootApplication @EnableConfigurationProperties(ProfileProperties.class) public class ReadConfigPropertiesApplication implements InitializingBean { private final ProfileProperties profileProperties; public ReadConfigPropertiesApplication(ProfileProperties profileProperties) { this.profileProperties = profileProperties; } public static void main(String[] args) { SpringApplication.run(ReadConfigPropertiesApplication.class, args); } @Override public void afterPropertiesSet() { System.out.println(profileProperties.toString()); } }    @PropertySource: 有单独文件的 properties 可以通过 @PropertySource 来读取\nimport org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.PropertySource; import org.springframework.stereotype.Component; @Component @PropertySource(\u0026#34;classpath:website.properties\u0026#34;) class WebSite { @Value(\u0026#34;${url}\u0026#34;) private String url; }   校验注解  这里可以参考 Spring Boot 指南\n  JSR 提供的校验注解:\n @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式  public class Person { @NotNull(message = \u0026#34;classId 不能为空\u0026#34;) private String classId; @Size(max = 33) @NotNull(message = \u0026#34;name 不能为空\u0026#34;) private String name; @Pattern(regexp = \u0026#34;((^Man$|^Woman$|^UGM$))\u0026#34;, message = \u0026#34;sex 值不在可选范围\u0026#34;) @NotNull(message = \u0026#34;sex 不能为空\u0026#34;) private String sex; @Email(message = \u0026#34;email 格式不正确\u0026#34;) @NotNull(message = \u0026#34;email 不能为空\u0026#34;) private String email; } Hibernate Validator 提供的校验注解：\n @NotBlank(message =) 验证字符串非 null，且长度必须大于 0 @Email 被注释的元素必须是电子邮箱地址 @Length(min=,max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内  自动装配   @Autowired, @Resource\n  @Autowired  自动装配，先byType再byName，如果不能唯一自动装配，则需要@Qualifier(value=\u0026quot;xxx\u0026quot;).\n在成员变量上实现：\npublic class User { @Autowired private Cat cat; @Autowired private Dog dog; private String str; public Cat getCat() { return cat; } public Dog getDog() { return dog; } public String getStr() { return str; } } 然后在XML中配置Bean\n\u0026lt;context:annotation-config/\u0026gt; \u0026lt;bean id=\u0026#34;dog\u0026#34; class=\u0026#34;com.kuang.pojo.Dog\u0026#34;/\u0026gt; \u0026lt;bean id=\u0026#34;cat\u0026#34; class=\u0026#34;com.kuang.pojo.Cat\u0026#34;/\u0026gt; \u0026lt;bean id=\u0026#34;user\u0026#34; class=\u0026#34;com.kuang.pojo.User\u0026#34;/\u0026gt;   @Qualifer()：如果bean名字不为类的默认名字，则要加@Qualifer\n@Autowired @Qualifier(value = \u0026#34;cat2\u0026#34;) private Cat cat; @Autowired @Qualifier(value = \u0026#34;dog2\u0026#34;) private Dog dog;    \u0026lt;/br\u0026gt;\r- #### `@Resource`\r自动装配，先`byName`再`byType`，如果`name`属性指定，则只会按照名称进行装配.\r默认按照名称进行装配，名称可以通过name属性进行指定。如果没有指定name属性，当注解写在字段上时，默认取字段名进行按照名称查找，如果注解写在setter方法上默认取属性名进行装配\r```java\rpublic class User {\r//如果允许对象为null，设置required = false,默认为true\r@Resource(name = \u0026quot;cat2\u0026quot;)\rprivate Cat cat;\r@Resource\rprivate Dog dog;\rprivate String str;\r}\r事务   @Transactional\n   @Transactional\n在 Service 的实现类中使用，将方法标注为 SQL 事务.\n首先需要在入口类上加入 @EnableTransactionManagement 注解以开启事务：\n@EnableTransactionManagement @SpringBootApplication public class TransactionApplication { public static void main(String[] args) throws Exception { SpringApplication.run(TransactionApplication.class, args); } } 然后再 @Service 中标注事务：\n@Service public class UserServiceImpl implements UserService { private final UserMapper userMapper; public UserServiceImpl(UserMapper userMapper) { this.userMapper = userMapper; } @Transactional @Override public void saveUser(User user) { userMapper.save(user); // 测试事务回滚  if (!StringUtils.hasText(user.getUsername())) { throw new RuntimeException(\u0026#34;username不能为空\u0026#34;); } } } 如果生效，当用户名为空（这里用的是 org.springframework.util 包下的 hasText() 方法，要求字符串不为 null 、长度大于0、不全为空），则会捕获到异常而进行回滚。\n @Transactional 同样利用的是 Spring 的 AOP 机制, 这里有两个坑.\n注意点一\n如果抛出的异常不是 RuntimeException 或者 Error ，也不是 @Transactional 注解指定的回滚异常类型，则不会进行事务回滚。所以在自定义需要回滚的异常时，要么继承 RuntimeException ，要么直接在注释上标出来：\n@Transactional(rollbackFor = Exception.class) @Override public void saveUser(User user) throws Exception { userMapper.save(user); // 测试事务回滚  if (!StringUtils.hasText(user.getUsername())) { throw new Exception(\u0026#34;username不能为空\u0026#34;); } } 注意点二\n如果我们在相同 Service 下的非事务方法中，对事务方法进行调用，事务同样不会生效。如下：\n@Service public class UserServiceImpl implements UserService { private final UserMapper userMapper; public UserServiceImpl(UserMapper userMapper) { this.userMapper = userMapper; } @Override public void saveUserTest(User user) { this.saveUser(user); } @Transactional @Override public void saveUser(User user) { userMapper.save(user); // 测试事务回滚  if (!StringUtils.hasText(user.getUsername())) { throw new ParamInvalidException(\u0026#34;username不能为空\u0026#34;); } } } 因为 Spring 事务控制通过 AOP 代理实现，通过代理目标对象来增强目标方法，而如果用 this 调用方法，this 绕过了代理类（实际上是代理类绕过原类，this 无视了代理类），直接用了类本身，从而没有触发事务。\n要让代理类重新生效有两种方法\n1、 从 IOC 中获取 Bean 后再调用：\n@Override public void saveUserTest(User user) { UserService userService = context.getBean(UserService.class); userService.saveUser(user); } 2、 直接从 AOP 上下文取代理对象进行调用（需要引入 AOP Starter 依赖），且需要再在 SpringBoot 入口类中通过注解@EnableAspectJAutoProxy(exposeProxy = true)将当前代理对象暴露到 AOP 上下文中（通过 AopContext 的 ThreadLocal 实现）\n@Override public void saveUserTest(User user) { UserService userService = (UserService) AopContext.currentProxy(); userService.saveUser(user); } 总之是有种为了舍近求远又额外兜了一大圈的感觉，个人认为写事务就不要代入编程优雅方面的考虑了，没必要在方法单一职责上那么较真。\n   ","date":"2021-06-16T00:00:00Z","image":"https://winterorch.github.io/images/feature/scenes/Fancy1.jpg","permalink":"https://winterorch.github.io/p/spring-%E5%B8%B8%E7%94%A8%E6%B3%A8%E9%87%8A/","title":"Spring - 常用注释"},{"content":"先简单过一下接口语法中的注意点。\n注意点   接口中的变量隐式指定为 public static final\n  接口中的方法会被隐式指定为 public abstract （JDK 1.9 后允许 private，其它修饰符会报错）\n 这也决定了接口中所有方法都必须被实现，当然这一要求有两种特殊的满足方式——抽象类实现接口，那么接口方法不一定要实现，可以由抽象类的子类实现；JDK 1.8 后有默认实现的接口方法也不必被实现类显式实现。\n   接口不能有构造方法\n  JDK 1.8 后，接口可以有静态方法和方法体\n  JDK 1.8 后，接口方法可以有默认方法，用 default 关键字修饰\n  与抽象类语法上的区别   一个类可以实现多个接口\n  一个接口可以继承多个其它接口\nJava 接口是对行为的抽象，一个行为本身可以看作多个行为的耦合\npublic interface Hockey extends Sports, Event    接口与抽象类区别 接口和抽象类语法上的不同在之前两个文档中都已经接释清楚了，这里主要看两者思想上的不同。\n摘取一些《Effective Java》中的说法\n 接口是对行为的抽象，达到 API 定义与实现分类 的目的，因此支持多实现。甚至可以用没有任何方法的接口，作为 Marker Interface，目的仅仅是进行声明。但是用接口导出常量是不合适的使用，接口应当尽量减少细节泄露，常量应当由类保管。\n相较之下，抽象类的主要目的是 代码重用，本质是不能实例化的类。\n 重点有两个——抽象类和接口的本质、目的都不同。\n本质 抽象类本质是类，因此不能多继承。C++ 允许多继承而 Java 不允许，这体现两者多态思想上的差别。我们知道 Java 继承其实叫 extends ，严格来讲不叫“继承”，因为在 Java 中，继承首先是一种 is-a 关系，即 Student 要继承 Person ，首先要满足 “Student is a Person” 。这很好理解，按照里氏替换原则 (Liskov Substitution)，进行继承关系抽象时，凡是可以用父类或者基类的地方，都可以用子类进行替换。因此这显然不是中文里面继承的语义，因为中文里“儿子继承父亲”，但儿子不可能是父亲，两者有本质区别。\n然后，Java 为什么只允许单继承就很好理解了。如果我想让 A 同时继承 B 和 C，那说明 A is B, A is C，那 B 和 C 之间自然应当满足某种继承关系，三者应当是一个继承链的关系而非继承树的关系，通过单继承也可以表示清楚，并不需要让 A 同时继承 B 和 C。更不用说 C++ 为了实现多继承，其实也带来菱形继承问题，可能造成内存浪费和数据冗余。\n C++中因为允许多继承，可能会因为菱形继承造成内存浪费和数据冗余（如两个类BC分别继承同一基类A，再从这两个类派生出一个类D时会有冗余成员），因此最好使用虚继承。虚继承下，D实例内存地址中，BC虚继承来的A部分会通过一个指针分别指向一张虚基表（准确来讲是指向其中的虚基表偏移指针的存储地址，然后通过该指针取出偏移量），从虚基表中取出从基类A虚继承来成员在D内存中的偏移地址。\n 曾看到有博客认为 C++ 多继承机制较为合理，给出的理由是“人可以有父母，那类也应当可以多继承”。结合前文内容，这个理由显然没有什么道理，但是我认为却很好地反映了 Java 中接口的思想。我们知道，对于生物而言，父和母显然是不等价的，母完成了作为母的职责，父完成了作为父的职责，然后才有“子”，因此与其类比为继承，不如类比为接口实现更妥当，因为父、母实际上在这里归根结底是行为的抽象，父类必须实现接口 CanBeFather，母类必须实现接口 CanBeMother，这是一种行为关系。这一接口在使用过程中屏蔽了其它底层细节，无论父母是什么学历、有什么资产，这一过程中都不关注，也没有影响，这便是类功能上的解耦，通过一个用来将行为抽象化的接口完成了。\n目的 目的上面其实也说了，《Effective Java》总结的很到位，接口是对行为的抽象，达到 API 定义与实现分类 的目的。如果一个类可以有多个行为、实现多个功能，那它当然可以实现多个接口。\n而抽象类更多还是用来减少冗余代码，换句话说——提高代码质量、提高可读性、降低维护难度……\n Java 继承与里氏替换原则 Java中子类重写父类方法时不能抛出父类中没有抛出的异常，编译会不过，不抛是完全可以的。同时，该方法在子类中的访问级别也不能低于超类中的访问级别。这两项规则确保可使用超类实例的地方也能使用子类实例，符合里氏替换原则。\n 变量只能被隐藏（静态及非静态），不能被覆盖 静态方法只能被隐藏，不能覆盖 静态方法只能用静态方法隐藏，非静态方法只能用非静态方法覆盖（否则编译不过） 最终方法不能覆盖。私有方法（private）实际会被隐式指定为 final ，所以同样不能覆盖。 抽象方法必须覆盖  同时要注意的是关于构造方法的内容\n 子类实例化对象时，如果子类构造方法没有显式调用父类构造方法，默认调用 super() 子类要使用父类有参构造方法，使用 super(...) 形式，且 super() 必须是子类构造方法中第一行语句 父类没有不带参构造方法，子类构造方法中必须显示调用父类其它构造方法，否则编译不过  ","date":"2021-06-02T20:04:58+01:30","image":"https://winterorch.github.io/images/feature/abyss/05.jpg","permalink":"https://winterorch.github.io/p/java-%E6%8E%A5%E5%8F%A3%E4%B8%8E%E6%8A%BD%E8%B1%A1%E7%B1%BB%E7%9A%84%E5%8C%BA%E5%88%AB/","title":"Java - 接口与抽象类的区别"},{"content":"网络层只把分组发送到目的主机，但是真正通信的并不是主机而是主机中的进程。传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。\n TCP 与 UDP 协议区别     连接 传输可靠性 传输形式 传输效率 所需资源 应用场景 首部字节     TCP 面向连接 可靠 字节流 低 多 要求数据可靠性 20 - 60   UDP 无连接 不可靠 数据报文段 高 少 要求通信效率 8     TCP（Transmission Control Protocol） TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。\n\r\n  序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。\n  确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。\n  数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。\n  确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。\n  同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。\n  终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。\n  窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。\n  一、TCP 三次握手和四次挥手 可靠，TCP 协议的设计都是为了可靠无误\n1.1 三次握手 \n 客户端–发送带有 SYN 标志的数据包–一次握手–服务端 服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端 客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端  为什么这么设计，可以从三次握手后双方获得的信息入手，对于发送方而言：\n    自己发送正常 自己接收正常 对方发送正常 对方接收正常     第一次 未知 未知 未知 未知   第二次 确认 确认 确认 确认   第三次 - - - -    对于接收方而言：\n    自己发送正常 自己接收正常 对方发送正常 对方接收正常     第一次 未知 确认 确认 未知   第二次 未知 - - 未知   第三次 确认 确认 确认 确认    要接收双方都能完整确认双方接收功能正常，三次握手缺一不可。\n 第2次握手传回了ACK，为什么还要传回SYN？\n接收端传回发送端所发送的ACK是为了告诉客户端，我接收到的信息确实就是你所发送的信号了，这表明从客户端到服务端的通信是正常的。而回传SYN则是为了建立并确认从服务端到客户端的通信。”\n  客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。\n 1.2 四次挥手 \r\n断开一个 TCP 连接则需要“四次挥手”：\n  客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送\n 客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态\n   服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加1 。和 SYN 一样，一个 FIN 将占用一个序号\n  服务器-关闭与客户端的连接，发送一个FIN给客户端\n TIME_WAIT\n客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：\n  确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。\n  等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。\n     客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加1\n      传达信息     A: FIN A：我没有数据要传了   B：ack B：我知道你没数据要传了   B：FIN B：我没有数据要传了   A：ack A：我知道你没数据要传了    二、TCP 如何保证可靠传输  **分块：**应用数据被分割成 TCP 认为最适合发送的数据块。 **有序：**TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 **去重：**TCP 的接收端会丢弃重复的数据。 流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制） 拥塞控制： 当网络拥塞时，减少数据的发送。 ARQ协议： 通过确认和超时机制实现可靠信息传输。 超时重传： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。  2.1 ARQ 自动重传请求（Automatic Repeat-reQuest，ARQ）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议。\n停止等待ARQ协议 每发完一个分组就停止发送，等待对方确认（回复ACK）。如果超时还没有收到 ACK 确认，需要重新发送，直到收到确认后再发下一个分组。若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。\n 优点： 简单 缺点： 信道利用率低，等待时间长  连续ARQ协议 连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。\n 优点： 信道利用率高，容易实现，即使确认丢失，也不必重传。 缺点： 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。  2.2 滑动窗口和流量控制 窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。\nTCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。\n2.3 拥塞控制 拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。\n为了进行拥塞控制，TCP 发送方要维持一个 拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接收窗口中较小的一个。\n TCP 窗口基于字节，但这里拥塞窗口的大小单位是报文段。\n TCP的拥塞控制采用了四种算法，即 慢开始 、 拥塞避免 、快重传 和 快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生。\n 当然，谈论拥塞控制的前提是不会发生流量控制，即接收方有足够大的接收缓存。\n \r\n  慢开始： 为防止立即注入大量数据导致拥塞，先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍。\n 如果在慢开始阶段出现超时，将令 ssthresh = cwnd / 2 并重新执行慢开始\n   拥塞避免： 拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间RTT就把发送方的 cwnd 加 1。\n  快重传与快恢复： 在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定下一个报文段丢失，立即重传丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。\n例如收到三个 M2，则 M3丢失，立即重传 M3。\n 这种情况下，丢失个别报文段不认作网络拥塞，因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh ，此时直接进入拥塞避免。\n 当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。\n   慢开始和快恢复的快慢，指的是 cwnd 的起始值而非增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。\n  UDP（User Datagram Protocol） 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。\n\r\n首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。\n","date":"2021-06-02T00:00:00Z","image":"https://winterorch.github.io/images/feature/abyss/09.jpg","permalink":"https://winterorch.github.io/p/computer_network-transport_layer/","title":"计算机网络 - 传输层"},{"content":"剑指 Offer 59 - I. 滑动窗口的最大值 给定一个数组 nums 和滑动窗口的大小 k，请找出所有滑动窗口里的最大值。\n示例 1：\n 输入: nums = [1,3,-1,-3,5,3,6,7], 和 k = 3 输出: [3,3,5,5,6,7] 解释:\n滑动窗口的位置 最大值\n [1 3 -1] -3 5 3 6 7 3 1 [3 -1 -3] 5 3 6 7 3 1 3 [-1 -3 5] 3 6 7 5 1 3 -1 [-3 5 3] 6 7 5 1 3 -1 -3 [5 3 6] 7 6 1 3 -1 -3 5 [3 6 7] 7\n 提示：\n你可以假设 k 总是有效的，在输入数组不为空的情况下，1 ≤ k ≤ 输入数组的大小。\n 题解一 单调队列 要求滑动窗口内的最大值，首先想到的是双向队列，一边推窗一边保持最大元素在队首。由于要确保窗口长度，队列中存的是下标。\npublic int[] maxSlidingWindow(int[] nums, int k) { int[] res = new int[nums.length - k + 1]; Deque\u0026lt;Integer\u0026gt; deque = new ArrayDeque\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; nums.length; ++i) { if (!deque.isEmpty() \u0026amp;\u0026amp; deque.peekFirst() == i - k) { deque.removeFirst(); } while (!deque.isEmpty() \u0026amp;\u0026amp; nums[deque.peekLast()] \u0026lt; nums[i]) { deque.removeLast(); } deque.addLast(i); if (i \u0026gt;= k - 1) { res[i - k + 1] = nums[deque.peekFirst()]; } } return res; } 题解二 双向遍历 如果通过固定队列长度可以来限制搜索范围，通过双向遍历也可以。不依靠队列的话有个问题，最大值会不断传播，如果 [0] 处是数组最大值，这一最大值可以一直传播到队尾。那我们必须进行适当的划分，让最大值最远传播 k 个数字（包含自己）。\n我们直接将队列分成一段段长为 k 的区间，每一段区间中，第一次遍历取得前半段（[0.. i % k]）上的最大值。\nfor (int i = 0; i \u0026lt; n; ++i) { if (i % k == 0) { prefixMax[i] = nums[i]; } else { prefixMax[i] = Math.max(prefixMax[i - 1], nums[i]); } } 然后从后向前进行一次遍历，取得后半段（[i % k .. k - 1]）上的最大值。\nfor (int i = n - 1; i \u0026gt;= 0; --i) { if (i == n - 1 || (i + 1) % k == 0) { suffixMax[i] = nums[i]; } else { suffixMax[i] = Math.max(suffixMax[i + 1], nums[i]); } } 然后，我们要取以 i 为起点长度为 k 的窗口的最大值，实际要取的就是当前区间上 [i % k .. k - 1] 上的最大值，和下一区间 [0 .. (i - 1 + k) % k] 上的最大值。\n完整答案\npublic int[] maxSlidingWindow(int[] nums, int k) { int n = nums.length; if (n == 0) { return new int[0]; } int[] prefixMax = new int[n]; int[] suffixMax = new int[n]; for (int i = 0; i \u0026lt; n; ++i) { if (i % k == 0) { prefixMax[i] = nums[i]; } else { prefixMax[i] = Math.max(prefixMax[i - 1], nums[i]); } } for (int i = n - 1; i \u0026gt;= 0; --i) { if (i == n - 1 || (i + 1) % k == 0) { suffixMax[i] = nums[i]; } else { suffixMax[i] = Math.max(suffixMax[i + 1], nums[i]); } } int[] ans = new int[n - k + 1]; for (int i = 0; i \u0026lt;= n - k; ++i) { ans[i] = Math.max(suffixMax[i], prefixMax[i + k - 1]); } return ans; } ","date":"2021-06-01T00:00:00Z","permalink":"https://winterorch.github.io/p/%E5%89%91%E6%8C%87-offer-59-i.-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E6%9C%80%E5%A4%A7%E5%80%BC/","title":"剑指 Offer 59 - I. 滑动窗口的最大值"},{"content":"常用端口及协议    应用 协议 端口号 传输层 备注     域名解析 DNS 53 UDP/TCP 长度超过 512 字节时使用 TCP   动态主机配置协议 DHCP 67/68 UDP    简单网络管理协议 SNMP 161/162 UDP    文件传送协议 FTP 20/21 TCP 控制连接 21，数据连接 20   远程终端协议 TELNET 23 TCP    超文本传送协议 HTTP 80 TCP    简单邮件传送协议 SMTP 25 TCP    邮件读取协议 POP3 110 TCP    网际报文存取协议 IMAP 143 TCP    超文本传送协议 HTTPS 443 TCP      域名系统 DNS ( Domain Name System ) 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。\n域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。\n\rDNS分层\r\nDNS 使用 UDP/TCP DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这样 DNS 服务器负载更低，响应更快，不过这要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。一般在两种情况下会使用 TCP 进行传输：\n  如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）\n  区域传送\n辅域名服务器会定时（一般三小时）向主域名服务器查询变动，如有变动则需要区域传送来同步数据，这一过程数据量很大，且对可靠性有一定要求，因此使用 TCP\n  有一种比较少见的情况——客户端可以指定向 DNS 服务器查询时用 TCP，但很多 DNS 服务器都配置为仅支持 UDP 查询。\nDNS 缓存 DNS 有多级缓存，按离浏览器距离，有浏览器缓存、系统缓存、路由器缓存、IPS服务器缓存、根域名服务器缓存、顶级域名服务器缓存、主域名服务器缓存。\n 文件传送协议 FTP ( File Transfer Protocol ) 使用 TCP 进行连接，它需要两个连接来传送一个文件：\n 控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。 数据连接：用来传送一个文件数据。  根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：\n 主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。  \r主动模式\r\n 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。  \r被动模式\r\n主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。\n 动态主机配置协议 自动配置 IP 地址等信息，DHCP ( Dynamic Host Configuration Protocol ) 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。\nDHCP 工作过程如下：\n 客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。 DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。 DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。  \rDHCP\r\n 远程登录协议 TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。\nTELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。\n 电子邮件协议 一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。\n邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。\n\r\n  SMTP\nSMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。\n  \r\n POP3\nPOP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。但最新版本的 POP3 可以不删除邮件。\n  IMAP\nIMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。\n   HTTP / HTTPS 状态码：\n    类别 原因     1XX Informational（信息性） 接收的请求正在处理   2XX Success（成功） 请求正常处理完毕   3XX Redirection（重定向） 需要进行附加操作以完成请求   4XX Client Error（客户端错误） 服务器无法处理请求   5XX Server Error（服务器错误） 服务器处理请求出错    HTTP/1.1 起默认使用长连接，用以保持连接特性，并支持请求的流水线 (Pipelining) 处理。实现长连接需要客户端和服务端都支持长连接。使用长连接的 HTTP 协议会在响应头加入这行代码：\nConnection:keep-alive 网页打开后，客户端与服务器间用于传输 HTTP 数据的 TCP 连接不会关闭，再次访问服务器时会继续使用。连接的保持时间由服务器设定。\n HTTP 本身是无状态协议，因此 Session 机制通过服务端记录用户状态。服务端为特定用户创建特定 Session 后用以标识和跟踪用户。\n大部分情况下，服务端通过在 Cookie 中附加 Session ID 来跟踪，并将 Session 存在缓存或数据库中。如果 Cookie 被禁用，也可以利用 URL 重写附在 URL 路径后面。\n不过诸如 Spring Security 等安全框架中采用 Token 认证，服务器通过Payload、Header和一个密钥(secret)创建令牌（Token）并将 Token 发送给客户端，客户端将 Token 保存在 Cookie 或者 localStorage 里面，以后客户端发出的所有请求都会携带这个令牌。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP Header 的 Authorization字段中： Authorization: Bearer Token。\n  扩展：HTTP 协议的优化\n参考阅读材料： https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A?\nHTTP1.1 引入了更多缓存控制策略，并允许对某个资源的部分请求，新增了 24 个错误状态响应码，请求和响应消息都支持 Host 头域（这使得多个主机可以共享一个IP，一台物理服务器从而可以存在多个虚拟主机），最重要的——支持了长连接和请求的流水线处理\n2012年 Google 提出 SPDY 方案，通过多路复用 (Multiplexing) 提高 TCP 连接利用率（因为浏览器一般对同一域名有最大连接数限制），为每个 Request 设置优先级（展示内容可以优先加载，优化了用户体验），加了首部压缩协议，并强制使用 HTTPS 保障安全，服务端也可以主动推动（例如客户端请求 style.css 文件时，服务端可以将相关的 style.js 也推送过去）。\nSPDY位于HTTP之下，TCP和SSL之上，这样可以轻松兼容老版本的HTTP协议(将HTTP1.x的内容封装成一种新的frame格式)，同时可以使用已有的SSL功能。\n HTTPS 运行在 SSL/TLS 上，而 SSL/TLS 运行在 TCP 上，所有传输内容都经过对称加密，对称密钥用服务器方的证书进行了非对称加密。因此 HTTPS 消耗服务器资源比 HTTP 多。\nCA ( Certification Authority ) 负责签发证书，并且能够验证域名所属——通过 DNS 记录或指定 URI 下放置的特殊文件供 CA 通过外网访问。\n 如果网站证书被 CA 私自发给了第三方，那第三方就能够利用证书实施中间人攻击了，因此 CA 信用非常重要。\n  Web 页面请求过程 也算是比较常见的面试题吧\n DHCP 配置主机信息    假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。\n  主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。\n  该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。\n  该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:FF，将广播到与交换机连接的所有设备。\n  连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。\n  该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。\n  主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。\n  ARP 解析 MAC 地址    主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。\n  主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。\n  该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。\n  该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。\n  DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。\n  主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。\n  网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。\n  DNS 解析域名    知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。\n  网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。\n  因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。\n  到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。\n  找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。\n  HTTP 请求页面 (TCP、HTTP)    有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。\n  在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。\n  HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。\n  连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。\n  HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。\n  浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。\n  ","date":"2021-05-31T00:00:00Z","image":"https://winterorch.github.io/images/feature/abyss/10.jpg","permalink":"https://winterorch.github.io/p/computer_network-application_layer/","title":"计算机网络 - 应用层"},{"content":"语法 抽象类中可以存在\n 构造方法 抽象方法 非抽象方法 成员变量 静态成员变量  总结：除了不能被实例化，抽象类几乎具有普通类的所有特性。\n 注意点   抽象类不能被实例化，如果试图实例化抽象类，编译无法通过\n  抽象类中可以有构造方法，但是构造方法不能为抽象方法，其中原因见 [为什么构造函数不能为抽象]\n 抽象类及其实现的构造方法也必须遵循一般继承中的构造方法规范，包括：\n 子类实例化对象时，如果子类构造方法没有显式调用父类构造方法，默认调用 super() 子类要使用父类有参构造方法，使用 super(...) 形式，且 super() 必须是子类构造方法中第一行语句 父类没有不带参构造方法（只定义了有参构造方法而没有定义无参的），子类构造方法中必须显示调用父类其它构造方法，否则编译不过     抽象类中的静态方法也不能为抽象方法\n  抽象类中的抽象方法只能声明，不能有具体实现，这与接口不同（接口方法在 JDK 1.8 后也可以有默认实现），具体原因见 [为什么抽象方法不能有实现而接口方法可以]\n   有端联想 抽象类总结了几个比较有嚼劲的问题\n1. 为什么构造函数不能为抽象 Java 抽象函数 和 C++ 虚函数 是等价概念，因此这里直接从 C++ 的角度找答案了。结论就是——构造函数从语言和逻辑来看都不能为虚函数。\n  从内存结构角度来看\n虚函数对应虚函数表 vtable ，表为类所有，但虚函数表指针为每个对象所有，在构造函数运行时进行空间分配，因此构造函数无法在未创建虚表指针的情况下调用虚表。\n  从语言逻辑角度来看\n构造函数目的是初始化实例，我们知道抽象类和虚基类都没有实例化的需求，将构造函数定义为虚函数是没有意义的。\n可以先回顾一下虚函数的作用过程——通过指针或者引用来调用虚函数的时候能够调用到子类的对应成员函数。而构造函数是在创建对象时自动调用的，调用这一函数的指针或引用所对应的对象还不存在，也就决定了构造函数不能是虚函数。\n  2. 为什么抽象方法不能有实现而接口方法可以 JDK 1.8 以前两者都不能有实现，这对接口的实现造成了一些麻烦，因为很多时候我们希望接口方法能有一些默认实现，从而减少其实现类中的重复代码；更多的时候，我们实现接口也并不需要用到其中所有方法，但没有默认实现导致我们不得不在实现一个接口时实现其中所有方法（因此出现了很多用于适配接口与实现类的 Adapter 类），哪怕根本不会用到。综上，JDK 1.8 以后接口也可以有默认实现了。\n 这其实让我联想到数据库设计范式对数据库粒度的苛求。按照规范来说，如果有类在实现接口过程中存在用不到的方法，那说明接口的粒度仍不够小——对行为的定义不够细，但从另一方面来讲，追求完美的接口粒度又会使代码晦涩难懂，且不够灵活。\n 但是抽象类中从一开始就不存在这个问题——因为抽象类并不只能包含抽象方法，还能包含普通方法，而 Java 中普通方法本身就是“虚函数”，允许子类重写。那么如果想要一个默认实现，直接写普通方法就行了。Java 语言设计抽象类的目的本就是方便代码重用，但在设计接口之初并没有把这一需求囊括进来。\n而抽象方法，仅用于标识子类必须实现的方法（有一种特殊情况除外，就是子类也是抽象类）。\n","date":"2021-05-30T00:00:00Z","image":"https://winterorch.github.io/images/feature/arknights/Penguin.jpg","permalink":"https://winterorch.github.io/p/java-%E6%8A%BD%E8%B1%A1%E7%B1%BB/","title":"Java - 抽象类"},{"content":"LeetCode 354. Russian Doll Envelopes You have a number of envelopes with widths and heights given as a pair of integers (w, h). One envelope can fit into another if and only if both the width and height of one envelope is greater than the width and height of the other envelope.\nWhat is the maximum number of envelopes can you Russian doll? (put one inside other)\nExample: Given envelopes = [[5,4],[6,4],[6,7],[2,3]], the maximum number of envelopes you can Russian doll is 3 ([2,3] =\u0026gt; [5,4] =\u0026gt; [6,7]).\n 大信封装小信封，为了方便DP，先进行排序，按宽度升序。出现了问题，高度怎么排呢？如果是单纯的暴力DP，那两个循环，高度其实是无所谓的，满足宽度、高度都更大就行了，怎么排都可以，如下：\nclass Solution { public: int maxEnvelopes(vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;\u0026amp; envelopes) { int res = 0, n = envelopes.size(); vector\u0026lt;int\u0026gt; dp(n, 1); sort(envelopes.begin(), envelopes.end()); for (int i = 0; i \u0026lt; n; ++i) { for (int j = 0; j \u0026lt; i; ++j) { if (envelopes[i].first \u0026gt; envelopes[j].first \u0026amp;\u0026amp; envelopes[i].second \u0026gt; envelopes[j].second) { dp[i] = max(dp[i], dp[j] + 1); } } res = max(res, dp[i]); } return res; } }; 但是其实可以优化速度。首先知道，宽度相同的一组信封肯定只能用一张。那用那张呢？应该趋向于高度尽量小的那张，这样更可能套的上宽度更大的信封。\n因为宽度已经是升序了，我们实际上只需要用一个数组按升序保存所有高度就可以了（实际上是一个大顶堆）。那问题来了，万一有很多张同一宽度不同高度的信封那不是没法区分，会全被加进来了吗？很简单，我们排序的时候加一个规则——宽度相同的信封按高度降序排。这样，首先加进来的一定是同一宽度中最高的信封，同一宽度下后加的一定是比较短的信封，自然不可能把前面的装下，也就不会出现同一宽度加多次的情况。\n但前面说了，同一宽度下我们其实最希望用最短的那张，更短的我们是希望拿来把最外面那张替掉的。那么我们拿着这张更短信封的高度在数组（堆）中二分搜索，搜索的其实是第一个大于此高度的位置，然后把这个位置上的高度替掉。如果是能满足要求（比最外层小比次外层大），那自然可以把最外面这张替掉。\n这里可能有疑问，那万一替掉的不是最外层，把里面宽度更小的替掉了呢？这里用的DP方法确实存在这样的问题，数组里存储的并不是实际可行的一个套娃方案，但是我们的信封其实并不关心里面啊，最外面一个是对的就行了，加上我们的高度是降序排列的，替也只能往前面小的替，也就是往里层替，不会影响最外层，更不会影响我们最关心的问题——能套几层。所以这一方法是完全可行的，完整代码如下：\npublic class Leet354_RussianDollEnvelopes { public int maxEnvelopes(int[][] envelopes) { //虽然Java类库用起来简单，但还是会比写lambda慢一点  //Arrays.sort(envelopes, Comparator.comparingInt((int[] array) -\u0026gt; array[0])  // .thenComparing(array -\u0026gt; -array[1]));  Arrays.sort(envelopes, (e1, e2) -\u0026gt; { if (e1[0] != e2[0]) { // 宽度升序  return e1[0] - e2[0]; } else { // 高度降序  return e2[1] - e1[1]; } }); // 由于主序是宽度，只要关注高度就可以了  List\u0026lt;Integer\u0026gt; dp = new ArrayList\u0026lt;\u0026gt;(); for (int[] envelope : envelopes) { int left = 0, right = dp.size(), t = envelope[1]; while (left \u0026lt; right) { int mid = left + (right - left) / 2; if (dp.get(mid) \u0026lt; t) left = mid + 1; else right = mid; } if (right \u0026gt;= dp.size()) dp.add(t); else dp.set(right, t); } return dp.size(); } public static void main(String[] args) { int[][] env = {{2,100},{3,200},{4,300},{5,500},{5,400},{5,250},{6,370},{6,360},{7,380}}; Leet354_RussianDollEnvelopes ins = new Leet354_RussianDollEnvelopes(); System.out.println(ins.maxEnvelopes(env)); } } 这个其实就是Leet300用的方法。\n","date":"2021-05-20T00:00:00Z","permalink":"https://winterorch.github.io/p/leetcode-354-%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/","title":"LeetCode 354 - 俄罗斯套娃信封问题"},{"content":"一、垃圾收集算法  下面这张图中存在 Permanent Space ，因此明显是基于 JDK 1.8 以前版本画的，在之后版本，元空间取代了永久代成为了 HotSpot 对方法区的实现\n \rJDK1.8以前的Java堆分代\r\n跟据 Object 生命周期分为三个层次\n Young Generation Old Generation Permanent Generation  Young Generation 包括 Eden 区和两个存活区（From 和 To），采用“停止-复制（Stop-and-copy）”清理法。大部分对象在 Eden 区域分配，一次新生代垃圾回收后如果对象还存活，则升1岁进入 s0 或 s1 ，清理 Eden 和使用过的一块 Survivor。\n HotSpot 虚拟机的 Eden 和 Survivor 大小比例默认为 8:1，保证内存利用率有 90%。\n Eden 区满时执行 Minor GC 清理可销毁对象，将不可销毁的迁移至其中一个存活区，而将另一个存活区直接清空，下一次 GC 时两个存活区角色交换，交换次数超过 15 （MaxTenuringThreshold）的进入 Old Generation。\n 复制算法（young代GC算法）\n该算法会将内存区域分为两个大小一样的区域。GC回收时，遍历当前使用区域，只将正在引用的对象复制到另一个区域，因此复制成本较低，且复制过程中还会进行内存整理，不会出现“碎片”问题。缺点就是：需要两个大小一样的内存区域和生命周期短的对象。所以该算法不适合大内存对象和长生命周期的对象，适用于young代的SO/S1\n  Hotspot 的动态年龄阈值\nHotspot遍历对象时按年龄从小到大对其所占用大小进行累积，当累积的某个年龄大小超过了 survivor 区一半，取年龄与 MaxTenuringThreshold 中更小的作为新年龄阈值\n Old Generation 通过“标记-整理”算法，标记处仍存活对象，并将所有存活对象向一端移动以保证内存连续，清理掉剩余部分内存。当进入的对象超过剩余空间大小，则触发 Full GC。“标记-整理”好处是不需要额外内存区域。\nPermanent Generation 主要存放字节码、字符串常量池、静态变量、可持久化数据等。每次发生 Full GC 时，同时也会销毁 Permanent Generation 中的可销毁对象。\n 永久代实际上是HotSpot JVM对JVM方法区的实现。由于永久代内存经常不够或发生内存泄露，造成OOM(PermGen)，从JDK8开始废弃了永久代，替换为了本地内存(native memory) 中的 Metaspace。\n 元空间与永久代最大区别在于它不在虚拟机中，而是使用本地内存。两者都是对JVM规范中方法区的实现，用于存储类的信息、常量池、方法数据、方法代码等。\n 字符串常量从JDK1.7开始由永久代转移到堆中(Java heap space)\n \r永久代的变动\r\n 二、经典垃圾收集器 \rHotSpot中的垃圾收集器\r\n HotSpot 中的安全点一般设置在方法调用、循环跳转、异常跳转等地方，只在安全点位置建立根节点枚举，强制到大安全点后才暂停，进行垃圾收集。\n HotSpot 中有7个垃圾收集器，连线表示可以配合使用。\n  Serial 串行的单线程收集器，简单高效。在 Client 场景下为默认 Young Generation 收集器，单线程收集效率高。Server 场景用于和 Parallel Scavenge 搭配使用。\n  ParNew Serial 的多线程版本。在 Server 场景下为默认 Young Generation 收集器，可以与 CMS 配合使用。\n  Parallel Scavenge 多线程。以“吞吐量”为优先考虑，即 CPU 运行用户代码的时间占总时间比值最高，CPU 用于垃圾回收的时间占总时间比值最低，而非其它垃圾收集器“尽可能缩短垃圾收集时用户线程的停顿时间”的目标，垃圾回收较为频繁。\nCPU效率更高，也适合后台运算任务，不适合对停顿和响应敏感的交互式程序。\nJVM中有配置以打开 GC 中新生代大小、Eden、S区自适应调节策略。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。\n  Serial Old 收集器 \r\nSerial 收集器的老年代版本，也是给 Client 场景下的虚拟机使用。如果用在 Server 场景下，它有两大用途：\n 在 JDK 1.5 以及之前版本（Parallel Old 诞生以前）中与 Parallel Scavenge 收集器搭配使用。 作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。    Parallel Old 收集器 \r\n是 Parallel Scavenge 收集器的老年代版本。\n在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。\n  CMS \r\nCMS（Concurrent Mark Sweep），Mark Sweep 指的是标记 - 清除算法。\n分为以下四个流程：\n 初始标记：仅仅只是标记一下 GC Roots 能直接关联（一级连接，不遍历）到的对象，同时遍历新生代可直达地老年对象，速度很快，需要停顿。 并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。 并发清除： 清理删除掉标记阶段判断已经死亡的对象，不需要停顿。  在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。\n具有以下缺点：\n 吞吐量低：对处理器资源敏感，低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。因此 CMS 适用于四核以上的处理器。 无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。 标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。    G1 G1（Garbage-First），它是一款面向服务端应用的垃圾收集器，在多 CPU 和大内存的场景下有很好的性能。HotSpot 开发团队赋予它的使命是未来可以替换掉 CMS 收集器。\n堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或者老年代，而 G1 可以直接对新生代和老年代一起回收。\n\rimg\r\nG1 把堆划分成多个大小相等的独立区域（Region），新生代和老年代不再物理隔离。\rimg\r\n通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。\n每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。\n 但是这样设计也存在副作用，region 大小固定为 1MB 到 32 MB 间的 2的幂值数，尽量能划 2048 个左右同等大小的 region 。\n    因为大小固定，和大对象很难保证一致，容易造成空间浪费，也很容易令大对象很难找到连续空间存放。\n \rimg\r\n如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤：\n 初始标记：短暂停顿线程以标记 GC Roots 直接关联到的对象，并修改 TAMS (Next Top at Mark Start) 值，让下一并发阶段能在正确 Region 中创建新对象。 并发标记：从 GC Roots 开始对堆对象进行可达性分析，递归扫描堆中的对象图，找出存活的对象，耗时长，但可以并发执行。 最终标记：为了修正在并发标记阶段遗留的因用户程序继续运作而导致变动的标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要短暂停顿线程，但是可并行执行。 筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。  具备如下特点：\n 空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。 可预测的停顿：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。   除经典垃圾收集器外还有 Shenandoah 收集器（CAS并发）、ZGC 收集器（通过染色体指针减少GC中内存屏障的使用）等低延迟垃圾收集器，见以下博客\nhttps://blog.csdn.net/qq_31709249/article/details/106711606\n  三、内存分配与回收策略 Minor GC 和 Full GC\n Minor GC：回收新生代，因为新生代对象存活时间很短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快。 Full GC：回收老年代和新生代，老年代对象其存活时间长，因此 Full GC 很少执行，执行速度会比 Minor GC 慢很多。  内存分配策略 1. 对象优先在 Eden 分配 大多数情况下，对象在新生代 Eden 上分配，当 Eden 空间不够时，发起 Minor GC。\n  -Xmx： 最大堆大小 -Xms： 最小堆大小 -Xmn： 年轻代堆大小 -XXSurvivorRatio： 年轻代中Eden区与Survivor区的大小比值   2. 大对象直接进入老年代 大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。\n经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。\n -XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 和 Survivor 之间的大量内存复制。\n 3. 长期存活的对象进入老年代 为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。\n -XX:MaxTenuringThreshold 用来定义对象进入老年期的年龄阈值。\n 4. 动态对象年龄判定 虚拟机并不是永远要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。\n5. 空间分配担保 在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。\n如果不成立的话虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 的值不允许冒险，那么就要进行一次 Full GC。\n JDK 6 Update 24 后，如果老年代连续空间大于新生代对象总大小或历次晋升的平均大小，则直接 Minor GC，否则 Full GC。\n Full GC 的触发条件 对于 Minor GC，其触发条件非常简单，当 Eden 空间满时，就将触发一次 Minor GC。而 Full GC 则相对复杂，有以下条件：\n  调用 System.gc()\n只是建议虚拟机执行 Full GC，但是虚拟机不一定真正去执行。不建议使用这种方式，而是让虚拟机管理内存。\n  老年代空间不足\n老年代空间不足的常见场景为前文所讲的大对象直接进入老年代、长期存活的对象进入老年代等。\n为了避免以上原因引起的 Full GC，应当尽量不要创建过大的对象以及数组。除此之外，可以通过 -Xmn 虚拟机参数调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。还可以通过 -XX:MaxTenuringThreshold 调大对象进入老年代的年龄，让对象在新生代多存活一段时间。\n  空间分配担保失败\n使用复制算法的 Minor GC 需要老年代的内存空间作担保，如果担保失败会执行一次 Full GC。具体内容请参考上面的第 5 小节。\n  JDK 1.7 及以前的永久代空间不足\n在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些 Class 的信息、常量、静态变量等数据。\n当系统中要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么虚拟机会抛出 java.lang.OutOfMemoryError。\n为避免以上原因引起的 Full GC，可采用的方法为增大永久代空间或转为使用 CMS GC。\n  Concurrent Mode Failure\n执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足），便会报 Concurrent Mode Failure 错误，并触发 Full GC。\n   四、可销毁对象  Java 虚拟机不使用引用计数算法，因为两个对象如果循环引用，则引用计数器永远无法为 0。\n 可达性分析 \r可达树\r\n根搜索方法，将所有 Java 对象构成“搜索树”结构，有一个根节点 root，每次从根节点触发进行搜索，遍历完后，不存在的变量成为可销毁对象。\nroot 包括所有正在运行线程栈上的引用变量、所有全局变量、所有 ClassLoader 。\n类的卸载 类卸载必须满足很多条件，最基本的有：所有实例都被回收；ClassLoader已被回收；对应的Class对象没有在任何地方被引用。\n 8u40 以后 G1 增加并默认开启 ClassUnloadingWithConcurrentMark ，在并发标记阶段结束后，JVM 直接进行类卸载。\n ","date":"2021-03-17T00:00:00Z","image":"https://winterorch.github.io/images/feature/lastofus/gamersky_04origin_07_2016715154B35.jpg","permalink":"https://winterorch.github.io/p/java-jvm-ram_and_gc/","title":"Java - JVM GC"}]